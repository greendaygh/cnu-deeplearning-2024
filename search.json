[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CNU Deep Learning",
    "section": "",
    "text": "1 CNU Cell-free & Deep learning",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "CNU Deep Learning",
    "section": "1.1 Welcome",
    "text": "1.1 Welcome\n\n2024.5 충남대학교, 기계학습 기반 서열 분석 강의 노트\nHaseong Kim (at KRIBB)\nChatGTP로 기본 contents를 만들고 검토, 보완하며 작성된 노트\n[User] 태그가 붙은 파란색 텍스트가 프롬프트이며 이 후 [ChatGTP] 태그가 GTP (4.0) 답변\nGPT에 질의한 프롬프트는 초안 수준으로 프롬프트를 정교하게 보강해서 질의할 경우 더 높은 수준의 답변을 얻을 수 있음",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "index.html#환경",
    "href": "index.html#환경",
    "title": "CNU Deep Learning",
    "section": "1.2 환경",
    "text": "1.2 환경\n\n실습 환경은 colab을 활용하며 파일 저장 등은 구글 드라이브를 활용함\n본 github repository에서 ipynb 파일을 다운로드 해서 구글 드라이브 임의의 디렉토리에 (2024-cnu-lecture) 복사 후 활용",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "cnu_introduction.html",
    "href": "cnu_introduction.html",
    "title": "2  Introduction",
    "section": "",
    "text": "2.1 [User]\nI want to learn python and use it for molecular biology research such as design of library sequence, design of experiments, read high-throughput sequencing file, apply deep learning algorithm. What topics do i need to learn?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "cnu_introduction.html#chatgpt",
    "href": "cnu_introduction.html#chatgpt",
    "title": "2  Introduction",
    "section": "2.2 [ChatGPT]",
    "text": "2.2 [ChatGPT]\nLearning Python for molecular biology research involves a blend of general programming skills and domain-specific knowledge. Here’s a structured guide on the topics you need to cover:\n\n2.2.1 Table of Contents\n\n2.2.1.1 Basic Python Programming\n\nPython Syntax and Semantics: Learn basic syntax, data types (strings, lists, dictionaries), control structures (if statements, loops), functions, and error handling.\nModules and Packages: Understand how to import and use standard libraries and third-party packages.\nFile I/O: Learn how to read from and write to files.\n\n\n\n2.2.1.2 Data Handling and Analysis\n\nNumPy: For numerical operations and handling arrays.\nPandas: For data manipulation and analysis, essential for handling tabular data, such as gene expression matrices.\nMatplotlib/Seaborn: For data visualization to generate plots and graphs.\n\n\n\n2.2.1.3 Bioinformatics Libraries\n\nBiopython: Essential for biological computation. Learn how to read/write sequence files, perform sequence analysis, and interact with biological databases.\nScikit-bio: For biological analysis including sequence alignment, biodiversity analysis, etc.\n\n\n\n2.2.1.4 Sequence Analysis\n\nFASTA/FASTQ Parsing: Learn how to parse sequence files.\nSequence Alignment: Understand the basics of sequence alignment (global and local), and tools like BLAST.\nMotif Finding: Learn how to identify sequence motifs.\n\n\n\n2.2.1.5 High-Throughput Sequencing Data\n\nHTSeq: For reading and analyzing high-throughput sequencing data.\nPySAM: For reading and manipulating SAM/BAM files (aligned sequencing reads).\nSeqIO: Part of Biopython for input/output of sequence data.\n\n\n\n2.2.1.6 Experimental Design\n\nPrimer Design: Understand the principles of primer design and tools available (like Primer3) and their Python interfaces.\nGolden Gate Assembly and Gibson Assembly: Learn the principles and how to design experiments programmatically.\n\n\n\n2.2.1.7 Statistical Analysis\n\nSciPy: For scientific and technical computing.\nStatsmodels: For statistical modeling.\nR Integration: Learn how to use R from Python (via rpy2) if you need to use specific R packages for statistical analysis.\n\n\n\n2.2.1.8 Machine Learning and Deep Learning\n\nScikit-learn: For machine learning algorithms.\nTensorFlow/Keras or PyTorch: For deep learning.\nBioinformatics-specific models: Learn about models specific to bioinformatics, such as predicting protein structures or gene expression levels.\n\n\n\n2.2.1.9 Workflow Automation\n\nSnakemake: For workflow management.\nNextflow: Another workflow management tool, useful for reproducible research.\n\n\n\n2.2.1.10 Advanced Topics\n\nData Integration: Integrating different types of biological data (genomic, transcriptomic, proteomic).\nNetwork Biology: Understanding biological networks (e.g., protein-protein interaction networks).\nStructural Bioinformatics: Analyzing protein structures using tools like PyMOL.\n\n\n\n2.2.1.11 Learning Resources\n\nBooks\n\n“Python for Biologists” by Martin Jones\n“Bioinformatics Programming Using Python” by Mitchell L. Model\n\nOnline Courses\n\nCoursera: “Python for Genomic Data Science” by Johns Hopkins University\nedX: “Python for Data Science” by Microsoft\nBiostars: Online forum for bioinformatics questions and tutorials.\n\nTutorials and Documentation\n\nBiopython Tutorial and Cookbook: Comprehensive guide to using Biopython.\nNumPy and Pandas documentation: Essential for data manipulation.\nScikit-learn and TensorFlow/Keras documentation: For machine learning and deep learning.\n\n\nBy following this structured guide, you’ll be able to leverage Python effectively for molecular biology research.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "cnu_introduction.html#user-1",
    "href": "cnu_introduction.html#user-1",
    "title": "2  Introduction",
    "section": "2.3 [User]",
    "text": "2.3 [User]\n I’ll learn it using google colab. can you let me know how to setup the colab environment for this learning",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "cnu_introduction.html#chatgpt-1",
    "href": "cnu_introduction.html#chatgpt-1",
    "title": "2  Introduction",
    "section": "2.4 [ChatGPT]",
    "text": "2.4 [ChatGPT]\nCertainly! Google Colab is an excellent platform for learning and running Python code, especially for bioinformatics. It provides a cloud-based Jupyter notebook environment that comes pre-configured with many scientific libraries. Here’s how to set up and use Google Colab for learning bioinformatics with Python:\n\n2.4.1 Step-by-Step Guide to Setting Up Google Colab\n\n2.4.1.1 Access Google Colab\n\nGo to Google Colab in your web browser.\nSign in with your Google account.\n\n\n\n2.4.1.2 Create a New Notebook\n\nClick on File -&gt; New Notebook to create a new notebook.\n\n\n\n2.4.1.3 Install Required Libraries\nGoogle Colab comes with many libraries pre-installed, but you might need to install some additional ones, such as biopython and scikit-bio. You can do this using the !pip install command directly in a cell.\n\n!pip install biopython scikit-bio\n\n\n\n2.4.1.4 Import Libraries and Verify Installation\nIn a new code cell, import the libraries to ensure they are installed correctly.\n\n# Importing necessary libraries\nimport Bio\nimport skbio\n\nprint(\"Biopython version:\", Bio.__version__)\nprint(\"scikit-bio version:\", skbio.__version__)\n\nBiopython version: 1.83\nscikit-bio version: 0.6.0\n\n\n\n\n2.4.1.5 Upload Files to Colab\n\n구글 드라이브에 2024-cnu-lecture 폴더를 만들기\n다운로드 하거나 공유된 (ipynb) 파일을 2024-cnu-lecture 폴더에 복사후 colab으로 open\n분석을 위한 ganbank 파일 ncbi에서 다운로드\n구글 드라이브의 위 디렉토리에 genbank 파일 복사 또는 다음 코드로 로컬 파일을 업로드 가능\n현재 작업 디렉토리 확인\n\n\n!pwd\n\n\n현재 작업 디렉토리를 위 생성한 디렉토리로 변경\n\n\nimport os\nos.chdir('drive/MyDrive/2024-cnu-lecture')\n\n\n!pwd\n\n\n분석을 위한 genbank 등의 파일을 ncbi에서 다운로드 후 위 폴더에 복사\n또는 아래 코드를 이용해서 현재 작업 디렉토리에 업로드\n\n\nfrom google.colab import files\n\nuploaded = files.upload()\n\n# Listing the uploaded files\nfor filename in uploaded.keys():\n    print(filename)\n\n\n\n\nimage.png\n\n\n\n\n2.4.1.6 Example: Reading a GenBank File and Analyzing Sequences\n\nHere’s an example workflow that reads a GenBank file, performs sequence analysis with Biopython, and aligns sequences with scikit-bio:\n위에서 다운로드 받은 genbank 파일을 egfp.gb 이름으로 변경 후 업로드\n아래 예시 코드는 단백질 서열을 읽고 비교하는 코드임\n\n\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\nfrom skbio import Protein\nfrom skbio.alignment import global_pairwise_align_protein\n\n# Assuming the uploaded GenBank file is named 'example.gb'\ngenbank_file = 'data/egfp.gb'\n\n# Read a protein sequence from a GenBank file\nrecord = SeqIO.read(genbank_file, \"genbank\")\nprint(len(record.seq))\n\nprotein_seq = record.seq.translate()\nprint(protein_seq)\n\n# Perform alignment with another protein sequence\nseq1 = Protein(str(protein_seq))\nseq2 = Protein(\"MKVLYNLKDG\")\n\nalignment, score, start_end_positions = global_pairwise_align_protein(seq1, seq2)\n\nprint(\"Alignment:\\n\", alignment)\nprint(\"Score:\", score)\nprint(\"Start-End Positions:\", start_end_positions)\n\n1150\nMSRVSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKQHDFFKSAMPEGYVQEVDLCILLS*EVELFPFCVLQLQMEIHRDTRGFCLVLSFVLVVN*KFIHLQEINSLLFKSKGLTYVSVKHWIPKNSKMR*GIFNLVWTSNRLG*PPVKLQQDCLLTQCLRSDVQ*LVLFHFALDFLFANELCF*WFSLFWCVENHLLQGRRQLQDPRRGEVRGRHPGEPHRAEGHRLQGGRQHPGAQAGVQLQQPQRLYHGRQAEERHQGELQDPPQHRGRQRAARRPLPAEHPHRRRPRAAARQPLPEHPVRPEQRPQREARSHGPAGVRDRRRDHSRHGRAVQV\nAlignment:\n TabularMSA[Protein]\n-----------------------------------------------------------------------\nStats:\n    sequence count: 2\n    position count: 384\n-----------------------------------------------------------------------\nMSRVSKGEELFTGVVPILVEL-DGDVNGHKFSV ... PEQRPQREARSHGPAGVRDRRRDHSRHGRAVQV\n--------------MKVLYNLKDG--------- ... ---------------------------------\nScore: 18.0\nStart-End Positions: [(0, 382), (0, 9)]\n\n\n/home/haseong/anaconda3/envs/biopy/lib/python3.11/site-packages/Bio/Seq.py:2880: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n  warnings.warn(\n/home/haseong/anaconda3/envs/biopy/lib/python3.11/site-packages/skbio/alignment/_pairwise.py:538: EfficiencyWarning: You're using skbio's python implementation of Needleman-Wunsch alignment. This is known to be very slow (e.g., thousands of times slower than a native C implementation). We'll be adding a faster version soon (see https://github.com/scikit-bio/scikit-bio/issues/254 to track progress on this).\n  warn(\n\n\n\n\n2.4.1.7 Saving Your Work\nYou can save your notebook to Google Drive:\n\nClick on File -&gt; Save a copy in Drive.\n\n\n\n2.4.1.8 Sharing Your Notebook\nYou can share your notebook with others by clicking on the Share button in the top right corner and setting the appropriate sharing permissions.\n\n\n2.4.1.9 Example Colab Notebook\nHere’s a more comprehensive example notebook that includes reading files, sequence analysis, and visualization: (다음 코드 참고)\nThis notebook covers: - Installing and importing bioinformatics libraries. - Uploading and reading files. - Performing sequence analysis. - Visualizing data.\nBy following these steps and examples, you’ll be well-prepared to use Google Colab for your bioinformatics learning and research.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Example data for visualization\ndata = {\n    'Sequence': ['Seq1', 'Seq2', 'Seq3'],\n    'GC_Content': [50, 55, 45],\n    'Length': [20, 22, 18]\n}\n\n# Visualize using Seaborn\ndf = pd.DataFrame(data)\nsns.histplot(df['GC_Content'], kde=True)\nplt.title('GC Content Distribution')\nplt.xlabel('GC Content (%)')\nplt.show()\n\nsns.boxplot(x=df['Length'])\nplt.title('Sequence Length Distribution')\nplt.xlabel('Length (bp)')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html",
    "href": "cnu_basic.html",
    "title": "3  Python Basics",
    "section": "",
    "text": "3.1 구글 드라이브 연결\n!pwd\nfrom google.colab import drive\nimport os\n\ndrive.mount('/content/drive')\nos.chdir('drive/MyDrive/2024-cnu-lecture')\n!pwd",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#구글-드라이브-연결",
    "href": "cnu_basic.html#구글-드라이브-연결",
    "title": "3  Python Basics",
    "section": "",
    "text": "세션이 다시 시작 될 때에도 실행 필요",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#user",
    "href": "cnu_basic.html#user",
    "title": "3  Python Basics",
    "section": "3.2 [User]",
    "text": "3.2 [User]\n Okay, I’ll learn “1. Basic Python Programming”. Can you teach me with a brief explanation and examples",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#chatgpt",
    "href": "cnu_basic.html#chatgpt",
    "title": "3  Python Basics",
    "section": "3.3 [ChatGPT]",
    "text": "3.3 [ChatGPT]\nAbsolutely! Let’s start with the basics of Python programming. I’ll cover fundamental concepts with brief explanations and examples to get you started.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#python-syntax-and-semantics",
    "href": "cnu_basic.html#python-syntax-and-semantics",
    "title": "3  Python Basics",
    "section": "3.4 Python Syntax and Semantics",
    "text": "3.4 Python Syntax and Semantics\n\n3.4.1 Hello World\nThe simplest Python program:\n\nprint(\"Hello, World!\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#variables-and-data-types",
    "href": "cnu_basic.html#variables-and-data-types",
    "title": "3  Python Basics",
    "section": "3.5 Variables and Data Types",
    "text": "3.5 Variables and Data Types\nPython supports various data types including integers, floats, strings, and booleans.\n\n# Integer\na = 10\n\n# Float\nb = 3.14\n\n# String\nc = \"Hello, Python\"\n\n# Boolean\nd = True\n\nprint(a, b, c, d)\n\n10 3.14 Hello, Python True",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#control-structures",
    "href": "cnu_basic.html#control-structures",
    "title": "3  Python Basics",
    "section": "3.6 Control Structures",
    "text": "3.6 Control Structures\n\n3.6.1 If-Else Statements\nUsed for decision making.\n\nx = 10\nif x &gt; 5:\n    print(\"x is greater than 5\")\nelse:\n    print(\"x is 5 or less\")\n\nx is greater than 5\n\n\n\n\n3.6.2 Loops\nFor repeating tasks.\n\nfor i in range(5):\n    print(i)\n\n0\n1\n2\n3\n4\n\n\n\ni = 0\nwhile i &lt; 5:\n    print(i)\n    i += 1\n\n0\n1\n2\n3\n4\n\n\n\n\n3.6.3 Functions\n\n3.6.3.1 Defining Functions\nReusable blocks of code.\n\ndef greet(name):\n    return f\"Hello, {name}\"\n\nprint(greet(\"Alice\"))\n\nHello, Alice\n\n\n\nnames = [\"Alice\", \"Bob\", \"Charlie\"]\n\nfor name in names:\n  print (\"My name is \", name)\n\nMy name is  Alice\nMy name is  Bob\nMy name is  Charlie\n\n\n\n리스트 값 평균 리턴하는 함수\n\n\ndef average(input):\n    if len(input) == 0:\n        return None\n    return sum(input) / len(input)\n\nx = [1,2,3,4,5,6,7,8,9,10]\nprint(average(x))\n\n5.5\n\n\n\n함수에 대한 개념 이해 중요\n실습과 예제를 통해 이해 필요 (마지막 예제에서 실습)\n\n\n\n3.6.3.2 f-string\n\nf와 {} 조합으로 표현할 수 있으며 출력이 고정된 문자열 맨 앞에 f를 붙여주고, 출력하고 싶은 변수값 등은 중괄호로 표현\n\n\nname = \"Alice\"\nmystr = f\"My name is {name}\"\n\nprint(mystr)\n\nMy name is Alice\n\n\n\nnames = [\"Alice\", \"Alisa\", \"Alister\"]\nmystr = f\"My name is {names}\"\n\nprint(mystr)\n\nMy name is ['Alice', 'Alisa', 'Alister']\n\n\n\nnames = [\"Alice\", \"Alisa\", \"Alister\"]\n\nfor name in names:\n  mystr = f\"My name is {name}\"\n  print(mystr)\n\nMy name is Alice\nMy name is Alisa\nMy name is Alister",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#lists-and-dictionaries",
    "href": "cnu_basic.html#lists-and-dictionaries",
    "title": "3  Python Basics",
    "section": "3.7 Lists and Dictionaries",
    "text": "3.7 Lists and Dictionaries\n\n리스트나 딕셔너리는 파이썬에서 데이터를 저장하는 변수의 자료형임\n여러 종류의 데이터를 효율적으로 활용하기 위한 자료 구조임\n\n\n3.7.1 Lists (리스트)\n\nOrdered, mutable collections.\n\n\nfruits = [\"apple\", \"banana\", \"cherry\"]\nprint(fruits[0])  # Accessing elements\nfruits.append(\"date\")  # Adding an element\nprint(fruits)\n\napple\n['apple', 'banana', 'cherry', 'date']\n\n\n\n인덱싱은 값 자체 (1은 두 번째값)\n슬라이싱은 값 사이 경계선 (1은 첫 번째 값과 두 번째 값 사이)\n아래 그림과 여러 실습 예제를 통한 이해 필요\n\n\n\n\nindexing\n\n\n\ngeneids = [x for x in range(10)] # 리스트 컴프리헨션\nprint(geneids)\nprint(geneids[0])\nprint(geneids[-1])\nprint(geneids[2:5])\nprint(geneids[2:-3])\nprint(geneids[:])\nprint(geneids[:-1])\nprint(geneids[1:])\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n0\n9\n[2, 3, 4]\n[2, 3, 4, 5, 6]\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n[0, 1, 2, 3, 4, 5, 6, 7, 8]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n리스트 데이터 삽입 삭제\n\n\ngeneids = [1, 2, 3]\nprint(geneids)\ngeneids.append(4)\nprint(geneids)\nprint(\"length: %d\" % len(geneids))\ngeneids[len(geneids):] = [5]\nprint(geneids)\nprint(geneids.pop())\nprint(geneids)\n\n[1, 2, 3]\n[1, 2, 3, 4]\nlength: 4\n[1, 2, 3, 4, 5]\n5\n[1, 2, 3, 4]\n\n\n\n\n3.7.2 Tuple (튜플)\n\n리스트와 같은 기능이지만 ‘(’, ’)’를 사용하고 원소를 변경할 수 없음\n\n리스트보다 빠른 속도, 리스트와 동일한 인덱싱 방법\n\n\ngeneids = (1, 2, 3)\nprint(geneids[0:2])\n#geneids[0] = 4 ## error\n\n(1, 2)\n\n\n\n반복문에서 리스트 또는 튜플 활용\n\n\ngeneids = ['123', '456', '789']\nfor geneid in geneids:\n  print(f\"geneid: {geneid}\")\n\ngeneid: 123\ngeneid: 456\ngeneid: 789\n\n\n\n\n3.7.3 Dictionaries (딕셔너리)\n\nKey-value pairs, unordered.\n\n\nperson = {\"name\": \"Alice\", \"age\": 25}\nprint(person[\"name\"])\nperson[\"age\"] = 26  # Updating value\nprint(person)\n\nAlice\n{'name': 'Alice', 'age': 26}\n\n\n\n키(key)와 값(value)을 쌍으로 저장, ‘{’와’}’를 사용\n\n\ngene_expr = {}\ngene_expr['A'] = 0.5\nprint(gene_expr)\ngene_expr['B'] = 1.2\nprint(gene_expr)\nprint(len(gene_expr))\n\n{'A': 0.5}\n{'A': 0.5, 'B': 1.2}\n2\n\n\n\n인덱싱은 ‘[’, ’]’ 사용, 키 값으로 인덱싱, 정수값 인덱싱 불가\n\n\nprint(gene_expr['A'])\n## gene_expr[0] # error\n\n0.5\n\n\n\n데이터 추가는 key값 value값으로 수행, 삭제는 del 함수 이용\n\n\ngene_expr['C'] = 0.3\nprint(gene_expr)\ndel gene_expr['C']\nprint(gene_expr)\n\n{'A': 0.5, 'B': 1.2, 'C': 0.3}\n{'A': 0.5, 'B': 1.2}\n\n\n\nkey 값과 value 값 구하기\n\n\ngene_expr_keys = list(gene_expr.keys())\nprint(\"keys:\", gene_expr_keys)\ngene_expr_values = list(gene_expr.values())\nprint(\"values:\", gene_expr_values)\n\nkeys: ['A', 'B']\nvalues: [0.5, 1.2]\n\n\n\nin 활용 키 값 탐색\n\n\nprint('D' in gene_expr_keys)\nprint('D' in gene_expr)\nprint('A' in gene_expr)\n\nFalse\nFalse\nTrue\n\n\n\n반복문에서 딕셔너리 활용 items()\n\n\ngene_expr = {'A':0.5, 'B':1.2, 'C':0.3, 'D':3.2}\nfor key, val in gene_expr.items():\n  print(f\"{key} expression value is {val}\")\n  #print(\"%s expression value is %s\" %(geneid, expval))\n\nA expression value is 0.5\nB expression value is 1.2\nC expression value is 0.3\nD expression value is 3.2",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#modules-and-packages",
    "href": "cnu_basic.html#modules-and-packages",
    "title": "3  Python Basics",
    "section": "3.8 Modules and Packages",
    "text": "3.8 Modules and Packages\n\n3.8.1 Importing Modules\nUsing standard libraries.\n\nimport math\n\nprint(math.sqrt(16))\n\n4.0\n\n\n\n\n3.8.2 Importing Specific Functions\n\nfrom math import sqrt\n\nprint(sqrt(25))\n\n5.0\n\n\n\n위 average 함수를 mystat.py 라는 이름의 파일로 저장, 모듈로 활용\n\n\n#import mystat\n#x = list(range(10))\n#print(mystat.average(x))\n\n\n모듈 직접 실행시 모듈 내 test 코드 실행 (name == main, True)\n\n\n#%run mystat\n\n\n모듈 임포트\n\n\nimport os\nos.getcwd()\n\n'/home/haseong/lecture/cnu-deeplearning-2024'\n\n\n\nfrom os import getcwd\ngetcwd()\n\n'/home/haseong/lecture/cnu-deeplearning-2024'",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#file-io",
    "href": "cnu_basic.html#file-io",
    "title": "3  Python Basics",
    "section": "3.9 File I/O",
    "text": "3.9 File I/O\n\n3.9.1 Writing to a File\n\nwith open('example.txt', 'w') as file:\n    file.write(\"Hello, World!\")\n\n\n\n3.9.2 Reading from a File\n\n\nwith open('example.txt', 'r') as file:\n    content = file.read()\n    print(content)\n\n\n\n3.9.3 Example: Basic DNA Sequence Manipulation\nLet’s put some of these concepts together with a simple example that manipulates a DNA sequence.\n\n# Define a DNA sequence\ndna_seq = \"ATGCGTACGTAGCTAGCTAG\"\n\n# Function to compute GC content\ndef gc_content(seq):\n    gc_count = seq.count('G') + seq.count('C')\n    return gc_count / len(seq) * 100\n\n# Function to get the reverse complement of the sequence\ndef reverse_complement(seq):\n    complement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n    return ''.join(complement[base] for base in reversed(seq))\n\n# Compute GC content\ngc = gc_content(dna_seq)\nprint(f\"GC Content: {gc:.2f}%\")\n\n# Get reverse complement\nrev_comp = reverse_complement(dna_seq)\nprint(f\"Reverse Complement: {rev_comp}\")\n\nGC Content: 50.00%\nReverse Complement: CTAGCTAGCTACGTACGCAT\n\n\n\n\n3.9.4 String join (문자열 붙이기)\n\nseq1 = \"ATGC\"\nseq2 = \"TAGC\"\ndna_seq = seq1 + seq2\n\nfor base in dna_seq:\n  print(base)\n\nprint(type(dna_seq))\n\nA\nT\nG\nC\nT\nA\nG\nC\n&lt;class 'str'&gt;\n\n\n\ncomplement = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C'}\n\nfor base in dna_seq:\n  print(complement [base])\n\ndna_seq_list = []\nfor base in dna_seq:\n  dna_seq_list.append(complement[base])\n\nprint(dna_seq_list)\nprint(type(dna_seq_list))\n\ndna_seq_comp = \"\".join (dna_seq_list)\nprint(dna_seq_comp)\nprint(type(dna_seq_comp))\n\nT\nA\nC\nG\nA\nT\nC\nG\n['T', 'A', 'C', 'G', 'A', 'T', 'C', 'G']\n&lt;class 'list'&gt;\nTACGATCG\n&lt;class 'str'&gt;\n\n\n\ndna_seq_list = [complement[base] for base in dna_seq]\nprint(dna_seq_list)\n\ndna_seq_comp = \"\".join(dna_seq_list)\nprint(dna_seq_comp)\n\nprint(\"\".join([complement[base] for base in dna_seq]))\nprint(\"\".join([complement[base] for base in dna_seq if base == \"A\" or base == \"T\"]))\n\n['T', 'A', 'C', 'G', 'A', 'T', 'C', 'G']\nTACGATCG\nTACGATCG\nTAAT",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#클래스",
    "href": "cnu_basic.html#클래스",
    "title": "3  Python Basics",
    "section": "3.10 클래스",
    "text": "3.10 클래스\n\nGene, Strain class 생성 연습\nGene attribute: name, chromosomal location, length\n\nStrain attribute (변수): name, length of chromosome\n\nStrain method (함수): compute average length of the genes\n\n\nimport statistics\nclass ORF:\n    def __init__(self, location, length, seq):\n        self.location = location\n        self.length = length\n        self.sequence = seq\n\nclass Strain:\n    def __init__(self, name, chrlength):\n        self.name = name\n        self.chr_length = chrlength\n        self.orfs = []\n    def add_orf(self, location, length, seq):\n        self.orfs.append(ORF(location, length, seq))\n    def orf_length_average(self):\n        return statistics.mean([s.length for s in self.orfs])\n\n\necoli = Strain(\"ecoli\", 5000000)\necoli.add_orf(1, 1000, \"ATG\")\necoli.add_orf(1001, 2000, \"CCT\")\necoli.add_orf(2001, 3000, \"ATC\")\n\n\nprint([g.location for g in ecoli.orfs])\nprint([g.sequence for g in ecoli.orfs])\necoli.orf_length_average()\n\n[1, 1001, 2001]\n['ATG', 'CCT', 'ATC']\n\n\n2000\n\n\n\n상속\n\n\nclass Gene(ORF):\n    def add_protein(self, prot_name, prot_seq):\n        self.prot_name = prot_name\n        self.prot_sequence = prot_seq\n        \n\n\ngene1 = Gene(1, 1000, \"ATG\")\nprint(gene1.location)\ngene1.add_protein(\"myprotein\", \"M\")\nprint(gene1.prot_name)\n\n1\nmyprotein",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#example-synonymous-mutant-library-generation",
    "href": "cnu_basic.html#example-synonymous-mutant-library-generation",
    "title": "3  Python Basics",
    "section": "3.11 Example: Synonymous Mutant Library Generation",
    "text": "3.11 Example: Synonymous Mutant Library Generation\n\n3.11.1 [User]\n I want to generate mutant library of a protein. I have a nucleotide genbank file for the target protein. I wan to generate all the mutants by changing synonymous codons for each residue. can you give me the python code?\n\n\n\n3.11.2 [ChatGPT]\nCertainly! To generate a mutant library by changing synonymous codons for each residue of a protein, we’ll need to:\n\nRead the nucleotide sequence from a GenBank file.\nTranslate the nucleotide sequence to a protein sequence.\nIdentify synonymous codons for each amino acid.\nGenerate all possible synonymous mutants for the target protein.\n\nHere is the Python code that accomplishes these tasks:\n\n이 예제는 위 프롬프트로 ChatGPT가 만든 코드입니다\n\n\n3.11.2.1 Install Necessary Libraries\nMake sure you have Biopython installed:\n\n!pip install biopython\n\n\n\n3.11.2.2 Python Script to Generate Synonymous Mutant Library\n\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\nfrom itertools import product\n\n# Synonymous codon table\nsynonymous_codons = {\n    'F': ['TTT', 'TTC'],\n    'L': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'],\n    'I': ['ATT', 'ATC', 'ATA'],\n    'M': ['ATG'],\n    'V': ['GTT', 'GTC', 'GTA', 'GTG'],\n    'S': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'],\n    'P': ['CCT', 'CCC', 'CCA', 'CCG'],\n    'T': ['ACT', 'ACC', 'ACA', 'ACG'],\n    'A': ['GCT', 'GCC', 'GCA', 'GCG'],\n    'Y': ['TAT', 'TAC'],\n    'H': ['CAT', 'CAC'],\n    'Q': ['CAA', 'CAG'],\n    'N': ['AAT', 'AAC'],\n    'K': ['AAA', 'AAG'],\n    'D': ['GAT', 'GAC'],\n    'E': ['GAA', 'GAG'],\n    'C': ['TGT', 'TGC'],\n    'W': ['TGG'],\n    'R': ['CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'],\n    'G': ['GGT', 'GGC', 'GGA', 'GGG'],\n    '*': ['TAA', 'TAG', 'TGA']\n}\n\n# Function to read the GenBank file and extract the coding sequence\ndef read_cds_from_genbank(file_path):\n    record = SeqIO.read(file_path, \"genbank\")\n    for feature in record.features:\n        if feature.type == \"CDS\":\n            return feature.location.extract(record).seq\n    raise ValueError(\"No CDS found in the GenBank file.\")\n\n# Function to generate synonymous mutants\ndef generate_synonymous_mutants(cds_seq):\n    protein_seq = cds_seq.translate()\n    codon_options = []\n\n    for aa in protein_seq[:5]:\n        codons = synonymous_codons.get(aa, [])\n        if not codons:\n            raise ValueError(f\"Unknown amino acid {aa} encountered.\")\n        codon_options.append(codons)\n\n    # Generate all combinations of synonymous codons\n    all_mutants = list(product(*codon_options))\n    return [''.join(mutant) for mutant in all_mutants]\n\n# Main function\ndef main(genbank_file, output_file):\n    cds_seq = read_cds_from_genbank(genbank_file)\n    mutants = generate_synonymous_mutants(cds_seq)\n\n    # Write the mutants to a FASTA file\n    with open(output_file, 'w') as f:\n        for i, mutant in enumerate(mutants):\n            f.write(f\"&gt;Mutant_{i+1}\\n{mutant}\\n\")\n\n# Example usage\ngenbank_file = 'data/egfp.gb'  # Replace with your GenBank file path\noutput_file = 'mutant_library.fasta'\nmain(genbank_file, output_file)\n\n\n위 코드를 두 개의 파일로 나누어 (함수모음 파일, 실행 파일) 모듈 실습 가능",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_data_handling.html",
    "href": "cnu_data_handling.html",
    "title": "4  Data handling",
    "section": "",
    "text": "구글 드라이브 연결\n\n!pwd\n\n/home/haseong/lecture/cnu-deeplearning-2024\n\n\n\nfrom google.colab import drive\nimport os\n\ndrive.mount('/content/drive')\nos.chdir('drive/MyDrive/2024-cnu-lecture')\n\n\n!pwd\n\n\n4.0.1 [User]\n I want to learn “2. Data Handling and Analysis”. can you explain me a brief explanation and examples? \n\n\n4.0.2 [ChatGPT]\nSure! Data handling and analysis are essential skills in Python, especially for tasks like manipulating datasets, performing statistical analyses, and creating visualizations. We’ll focus on the key libraries used for these purposes: NumPy, Pandas, and Matplotlib/Seaborn.\n\n\n4.0.3 1. NumPy\nNumPy is a powerful library for numerical operations and handling arrays.\n\n4.0.3.1 Basics of NumPy\nInstallation:\n!pip install numpy\n\nimport numpy as np\n\n\n# Creating a 1D array\narr1 = np.array([1, 2, 3, 4, 5])\n\n# Creating a 2D array\narr2 = np.array([[1, 2, 3], [4, 5, 6]])\n\nprint(arr1)\nprint(arr2)\n\n\n# Element-wise operations\narr3 = arr1 * 2\nprint(arr3)\n\n# Mathematical functions\nprint(np.sqrt(arr1))\n\n[1 2 3 4 5]\n[[1 2 3]\n [4 5 6]]\n[ 2  4  6  8 10]\n[1.         1.41421356 1.73205081 2.         2.23606798]\n\n\n\n\n4.0.3.2 Numpy 자료구조 ndarray\n\n행렬이나 다차원 배열 처리용 파이썬 라이브러리\n같은 타입의 데이터만 허용\n리스트에 비해 20배 이상 빠른 속도\n\n\n\n\nfrom https://www.oreilly.com/library/view/elegant-scipy/9781491922927/ch01.html\n\n\n\nnumpy 객체 만들기\n\n\nimport numpy as np\n\narr = [1, 2, 3]\nprint(arr)\nprint(type(arr))\n\na = np.array([1,2,3])\nprint(a)\nprint(a.dtype)\nprint(a.shape)\nprint(type(a))\n\n[1, 2, 3]\n&lt;class 'list'&gt;\n[1 2 3]\nint64\n(3,)\n&lt;class 'numpy.ndarray'&gt;\n\n\n\narr2 = np.array([[1,2,3], [4,5,6]])\nprint(arr2)\nprint(type(arr2))\nprint(arr2.shape)\nprint(arr2.dtype)\n\n[[1 2 3]\n [4 5 6]]\n&lt;class 'numpy.ndarray'&gt;\n(2, 3)\nint64\n\n\n\nnumpy 자료형\n\n부호가 있는 정수 int(8, 16, 32, 64)\n부호가 없는 정수 uint(8 ,16, 32, 54)\n실수 float(16, 32, 64, 128)\n복소수 complex(64, 128, 256)\n불리언 bool\n문자열 string_\n파이썬 오프젝트 object\n유니코드 unicode_\n\nnp.zeros(), np.ones(), np.arange()\n행렬 연산 지원\n\n\na = np.arange(1, 10).reshape(3,3) # [1, 10)\nprint(a)\na = np.ones((3,4), dtype=np.int16)\nb = np.ones((3,4), dtype=np.int16)\nprint(a)\nprint(b)\nprint(a+b)\nprint(a-b)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n[[1 1 1 1]\n [1 1 1 1]\n [1 1 1 1]]\n[[1 1 1 1]\n [1 1 1 1]\n [1 1 1 1]]\n[[2 2 2 2]\n [2 2 2 2]\n [2 2 2 2]]\n[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\n\n\n\nnumpy 함수\n\nnp.sqrt()\nnp.log()\nnp.square()\nnp.log()\nnp.ceil()\nnp.floor()\nnp.isnan()\nnp.sum()\nnp.mean()\nnp.std()\nnp.min()\n\n\n\ndir(np)\n\n\n\n\n4.0.4 2. Pandas\nPandas is a powerful library for data manipulation and analysis. It provides data structures like DataFrame, which is similar to tables in databases or spreadsheets.\n\n4.0.4.1 Installation\npip install pandas\n\nPandas의 Series는 1차원, DataFrame은 2차원 데이터를 다루는 자료구조\nDataFrames are the primary data structure in pandas, representing tabular data with rows and columns.\nindex, column, values 로 이루어짐\n리스트와 딕셔너리로부터 생성 가능\n숫자형, 문자형, 범주형 등의 다양한 데이터 입력 가능\n\n\n\n\nalt text\n\n\n\nfrom pandas import Series, DataFrame\n\n\ngenes = Series([0.1, 0.2, 1.4, 0.6, 1.1])\nprint(genes)\n\n0    0.1\n1    0.2\n2    1.4\n3    0.6\n4    1.1\ndtype: float64\n\n\n\ngenes = Series([0.1, 0.2, 1.4, 0.6, 1.1], index=['A', 'B', 'C', 'D', 'E'])\nprint(genes)\n\nA    0.1\nB    0.2\nC    1.4\nD    0.6\nE    1.1\ndtype: float64\n\n\n\n\n4.0.4.2 Make a DataFrame\n\nCreate from a list\n\n\nimport pandas as pd\n\ndf = pd.DataFrame([[0, 4, 5], [0, 6, 7], [20, 30, 40]],\n                  index=[1, 2, 3], columns=['P', 'Q', 'R'])\n\nprint(df)\n\n    P   Q   R\n1   0   4   5\n2   0   6   7\n3  20  30  40\n\n\n\nCreate dataframe from a dictionary\n\n\n\n\nalt text\n\n\n\nimport pandas as pd\n\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'Height': [5.5, 6.0, 5.8]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\nCreate from a list of dictionary\n\n\n\n\nalt text\n\n\n\ndata = [\n    {'Name': 'Alice', 'Age': 25, 'Height': 5.5},\n    {'Name': 'Bob', 'Age': 30, 'Height': 6.0},\n    {'Name': 'Charlie', 'Age': 35, 'Height': 5.8}\n]\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\nCreate from Series\n\n\ngenes = {'A': [0.5, 0.1, 0.3],\n         'B': [0.8, 0.9, 0.4]}\nprint(genes)\ngenes_df = DataFrame(genes)\nprint(genes_df)\nprint(genes_df['A'])\nprint(type(genes_df['A']))\n\n\ngenes_df = DataFrame(genes, columns=['B', 'A'], index=['day1', 'day2', 'day3'])\nprint(genes_df)\n\n{'A': [0.5, 0.1, 0.3], 'B': [0.8, 0.9, 0.4]}\n     A    B\n0  0.5  0.8\n1  0.1  0.9\n2  0.3  0.4\n0    0.5\n1    0.1\n2    0.3\nName: A, dtype: float64\n&lt;class 'pandas.core.series.Series'&gt;\n        B    A\nday1  0.8  0.5\nday2  0.9  0.1\nday3  0.4  0.3\n\n\n\n\n4.0.4.3 Dataframe operations\n\ndata = [\n    {'Name': 'Alice', 'Age': 25, 'Height': 5.5},\n    {'Name': 'Bob', 'Age': 30, 'Height': 6.0},\n    {'Name': 'Charlie', 'Age': 35, 'Height': 5.8}\n]\n\ndf = pd.DataFrame(data)\nprint(df)\n\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\n# Selecting columns\nages = df['Age']\nprint(ages)\n\n# Filtering rows\nadults = df[df['Age'] &gt; 18]\nprint(adults)\n\n# Adding a new column\ndf['Weight'] = [65, 70, 75]\nprint(df)\n\n# Grouping and Aggregating\ngrouped = df.groupby('Name').mean()\nprint(grouped)\n\n0    25\n1    30\n2    35\nName: Age, dtype: int64\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n      Name  Age  Height  Weight\n0    Alice   25     5.5      65\n1      Bob   30     6.0      70\n2  Charlie   35     5.8      75\n          Age  Height  Weight\nName                         \nAlice    25.0     5.5    65.0\nBob      30.0     6.0    70.0\nCharlie  35.0     5.8    75.0\n\n\n\n인덱스 자동 정렬, 행렬 연산\n\n\ngenes1 = Series([0.1, 0.2, 1.4, 0.6, 1.1], index=['A', 'B', 'C', 'D', 'E'])\ngenes2 = Series([0.1, 0.2, 1.4, 0.6, 1.1], index=['B', 'C', 'D', 'E', 'A'])\ngenes1 + genes2\n\nA    1.2\nB    0.3\nC    1.6\nD    2.0\nE    1.7\ndtype: float64\n\n\n\nprint(genes2.sort_values())\nprint(genes2.sort_index())\n\nB    0.1\nC    0.2\nE    0.6\nA    1.1\nD    1.4\ndtype: float64\nA    1.1\nB    0.1\nC    0.2\nD    1.4\nE    0.6\ndtype: float64\n\n\n\ngenes = {'A': [0.5, 0.1, 0.3],\n         'B': [0.8, 0.9, 0.4]}\n\ngenes_df = DataFrame(genes, columns=['B', 'A'], index=['day1', 'day2', 'day3'])\nprint(genes)\nprint(genes_df)\n\n{'A': [0.5, 0.1, 0.3], 'B': [0.8, 0.9, 0.4]}\n        B    A\nday1  0.8  0.5\nday2  0.9  0.1\nday3  0.4  0.3\n\n\n\nprint(genes_df['A'])\nprint(genes_df.loc['day1'])\nprint(genes_df.index)\nprint(list(genes_df.columns))\n\nday1    0.5\nday2    0.1\nday3    0.3\nName: A, dtype: float64\nB    0.8\nA    0.5\nName: day1, dtype: float64\nIndex(['day1', 'day2', 'day3'], dtype='object')\n['B', 'A']\n\n\n\n\n\n4.0.5 3. Matplotlib/Seaborn\nMatplotlib is a plotting library for creating static, animated, and interactive visualizations. Seaborn is built on top of Matplotlib and provides a high-level interface for drawing attractive statistical graphics.\nInstallation:\npip install matplotlib seaborn\n\nimport matplotlib.pyplot as plt\n\n# Line plot\nplt.plot([1, 2, 3, 4], [1, 4, 9, 16])\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.title('Line Plot')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = [\n    {'Name': 'Alice', 'Age': 25, 'Height': 5.5},\n    {'Name': 'Bob', 'Age': 30, 'Height': 6.0},\n    {'Name': 'Charlie', 'Age': 35, 'Height': 5.8}\n]\n\ndf = pd.DataFrame(data)\nprint(df)\n\n# Scatter plot with Seaborn\nsns.scatterplot(x='Age', y='Height', data=df)\nplt.title('Age vs Height')\nplt.show()\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\n\n\n\n\n\n\n\ndir(sns)\n\n\n\n4.0.6 Example: Analyzing and Visualizing DNA Sequence Data\n\n\n\nalt text\n\n\n\n\n\nalt text\n\n\n\n4.0.6.1 [User]\n I have downloaded a fasta file containing 800 esterase nucleotide sequences. the file is saved at “data/esterase.fa”. can you provide a python code that can read the sequences and compute their length and GC contents ratio? \n\n\n4.0.6.2 [ChatGPT]\nCertainly! To read a FASTA file containing 800 esterase nucleotide sequences and compute their lengths and GC content ratios, you can use the Biopython library. Here is a Python script that accomplishes this:\nInstallation\nFirst, make sure you have Biopython installed:\npip install biopython\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Function to compute sequence length and GC content\ndef compute_sequence_stats(seq):\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    return length, gc_content\n\n# Read the FASTA file and process each sequence\ndef process_fasta_file(file_path):\n    records = SeqIO.parse(file_path, \"fasta\")\n    esterase_stats = []\n\n    for record in records:\n        length, gc_content = compute_sequence_stats(record.seq)\n        esterase_stats.append({\n            \"ID\": record.id,\n            \"Length\": length,\n            \"GC_Content\": gc_content\n        })\n\n    return esterase_stats\n\n# Example usage\nfasta_file = 'data/esterases.fasta'  # Replace with your FASTA file path\nesterase_stats = process_fasta_file(fasta_file)\n\n# Print the results\nfor esterase in esterase_stats:\n    print(f\"ID: {esterase['ID']}, Length: {esterase['Length']} bp, GC Content: {esterase['GC_Content']:.2f}%\")\n\n\n\n4.0.6.3 [User]\n I want to store the result above in a file with json csv format. Than I need a code to read the file and convert the data in a DataFrame format. \n\n\n4.0.6.4 [ChatGPT]\nSure! Let’s modify the script to store the results in both JSON and CSV formats. Then, we’ll write a separate script to read these files and convert the data into a Pandas DataFrame.\n\nimport json\nimport csv\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Function to compute sequence length and GC content\ndef compute_sequence_stats(seq):\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    return length, gc_content\n\n# Read the FASTA file and process each sequence\ndef process_fasta_file(file_path):\n    records = SeqIO.parse(file_path, \"fasta\")\n    esterase_stats = []\n\n    for record in records:\n        length, gc_content = compute_sequence_stats(record.seq)\n        esterase_stats.append({\n            \"ID\": record.id,\n            \"Length\": length,\n            \"GC_Content\": gc_content\n        })\n\n    return esterase_stats\n\n# Save results to JSON and CSV\ndef save_results(esterase_stats, json_file, csv_file):\n    # Save to JSON\n    with open(json_file, 'w') as jf:\n        json.dump(esterase_stats, jf, indent=4)\n\n    # Save to CSV\n    with open(csv_file, 'w', newline='') as cf:\n        writer = csv.DictWriter(cf, fieldnames=['ID', 'Length', 'GC_Content'])\n        writer.writeheader()\n        for esterase in esterase_stats:\n            writer.writerow(esterase)\n\n# Example usage\nfasta_file = 'data/esterases.fasta'  # Replace with your FASTA file path\njson_file = 'data/esterase_stats.json'\ncsv_file = 'data/esterase_stats.csv'\n\nesterase_stats = process_fasta_file(fasta_file)\nsave_results(esterase_stats, json_file, csv_file)\n\nprint(f\"Results saved to {json_file} and {csv_file}\")\n\nResults saved to data/esterase_stats.json and data/esterase_stats.csv\n\n\n\nimport pandas as pd\nimport json\n\n# Load data from JSON file\nwith open('data/esterase_stats.json', 'r') as jf:\n    esterase_stats_json = json.load(jf)\n\n# Convert to DataFrame\ndf_json = pd.DataFrame(esterase_stats_json)\nprint(\"DataFrame from JSON file:\")\nprint(df_json.head())\n\n# Load data from CSV file\ndf_csv = pd.read_csv('data/esterase_stats.csv')\nprint(\"DataFrame from CSV file:\")\nprint(df_csv.head())\n\nDataFrame from JSON file:\n                     ID  Length  GC_Content\n0            EU240725.1     240   50.833333\n1  NZ_JBBEZD010000544.1     387   48.062016\n2  NZ_JADOYP010000246.1     234   55.982906\n3  NZ_JAJAQZ010000712.1     252   52.777778\n4  NZ_JABFYM010000640.1     769   52.405722\nDataFrame from CSV file:\n                     ID  Length  GC_Content\n0            EU240725.1     240   50.833333\n1  NZ_JBBEZD010000544.1     387   48.062016\n2  NZ_JADOYP010000246.1     234   55.982906\n3  NZ_JAJAQZ010000712.1     252   52.777778\n4  NZ_JABFYM010000640.1     769   52.405722\n\n\n\n\n4.0.6.5 [User]\n I want a python code that display the statistics of the GC distribution and boxplot of the length. \n\n\n4.0.6.6 [ChatGPT]\nSure! Let’s create a Python script that reads the data from the previously saved JSON or CSV file, computes statistics for the GC content distribution, and generates a boxplot for the sequence lengths using Pandas and Matplotlib.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load data from CSV file\ndf = pd.read_csv('data/esterase_stats.csv')\n\n# Compute statistics for GC content distribution\ngc_stats = df['GC_Content'].describe()\nprint(\"GC Content Distribution Statistics:\")\nprint(gc_stats)\n\n# Generate a histogram for GC content distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(df['GC_Content'], bins=30, kde=True)\nplt.title('GC Content Distribution')\nplt.xlabel('GC Content (%)')\nplt.ylabel('Frequency')\nplt.show()\n\n# Generate a boxplot for sequence lengths\nplt.figure(figsize=(10, 6))\nsns.boxplot(x=df['Length'])\nplt.title('Boxplot of Sequence Lengths')\nplt.xlabel('Sequence Length (bp)')\nplt.show()\n\nGC Content Distribution Statistics:\ncount    355.000000\nmean      51.362399\nstd        5.551809\nmin       29.739777\n25%       50.052780\n50%       51.901566\n75%       54.322222\nmax       75.683891\nName: GC_Content, dtype: float64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScript\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\n\nfor record in results:\n    print(record.id)\n    print(record.seq)\n    print(gc_fraction(record.seq))\n\nprint(results)\n\n\nCalculate\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\n\nfor record in results:\n    seq = record.seq\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    print(f\"ID: {record.id}, Length: {length} bp, GC Content: {gc_content:.2f}%\")\n    \n\n\nstore in a list\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\nimport pandas as pd\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\nesterase_stats = []\n\nfor record in results:\n    seq = record.seq\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    esterase_stats.append({\n        \"ID\": record.id,\n        \"Length\": length,\n        \"GC_Content\": gc_content\n    })\n\nprint(esterase_stats) \npd.DataFrame(esterase_stats)\n\n\nmake a function\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\nimport pandas as pd\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\nesterase_stats = []\n\n# Function to compute sequence length and GC content\ndef compute_sequence_stats(seq):\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    return length, gc_content\n\n\nfor record in results:\n    seq = record.seq\n    length, gc_content = compute_sequence_stats(seq)\n    esterase_stats.append({\n        \"ID\": record.id,\n        \"Length\": length,\n        \"GC_Content\": gc_content\n    })\n\nprint(esterase_stats) \npd.DataFrame(esterase_stats)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data handling</span>"
    ]
  },
  {
    "objectID": "cnu_bioinformatics.html",
    "href": "cnu_bioinformatics.html",
    "title": "5  Bioinformatics",
    "section": "",
    "text": "5.1 [User]\nI want to learn about “3. Bioinformatics Libraries”. Can you explain it with example codes?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bioinformatics</span>"
    ]
  },
  {
    "objectID": "cnu_bioinformatics.html#chatgpt",
    "href": "cnu_bioinformatics.html#chatgpt",
    "title": "5  Bioinformatics",
    "section": "5.2 [ChatGPT]",
    "text": "5.2 [ChatGPT]\nCertainly! Bioinformatics libraries in Python, such as Biopython and scikit-bio, provide tools and functions to handle biological data, including sequence analysis, structure analysis, and more. Here’s a brief introduction to these libraries with example codes.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bioinformatics</span>"
    ]
  },
  {
    "objectID": "cnu_bioinformatics.html#biopython",
    "href": "cnu_bioinformatics.html#biopython",
    "title": "5  Bioinformatics",
    "section": "5.3 Biopython",
    "text": "5.3 Biopython\nBiopython is one of the most widely used libraries for bioinformatics in Python. It provides tools for reading and writing different bioinformatics file formats, performing sequence analysis, and interacting with biological databases.\n\nfrom google.colab import drive\nimport os\n\ndrive.mount('/content/drive')\nos.chdir('drive/MyDrive/2024-cnu-lecture')\n\nMounted at /content/drive\n\n\n\n5.3.1 Installation\n\n!pip install biopython\n\nCollecting biopython\n  Downloading biopython-1.83-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 13.3 MB/s eta 0:00:00\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\nInstalling collected packages: biopython\nSuccessfully installed biopython-1.83\n\n\n\n\n5.3.2 Sequence objects\n\nfrom Bio.Seq import Seq\nmy_seq = Seq(\"AGTACACTGGT\")\nmy_seq\n\nSeq('AGTACACTGGT')\n\n\n\nfor index, letter in enumerate(my_seq):\n    print(\"%i %s \" % (index, letter))\n\n0 A \n1 G \n2 T \n3 A \n4 C \n5 A \n6 C \n7 T \n8 G \n9 G \n10 T \n\n\n\nx = [1, 4, 5, 7, 8]\nfor i in enumerate(x):\n    print(i)\n\nfor i in x:\n    print(i)\n\n(0, 1)\n(1, 4)\n(2, 5)\n(3, 7)\n(4, 8)\n1\n4\n5\n7\n8\n\n\n\nprint(my_seq)\nprint(my_seq[0:3])\nprint(my_seq[0::2])\nprint(str(my_seq))\nprint(my_seq + \"ATG\")\nprint(my_seq==\"ATG\")\nprint(\"AGT\" in my_seq)\n\nAGTACACTGGT\nAGT\nATCCGT\nAGTACACTGGT\nAGTACACTGGTATG\nFalse\nTrue\n\n\n\nmy_seq_low = my_seq.lower()\nprint(my_seq_low)\nprint(my_seq_low.upper())\nprint(my_seq.complement())\nprint(my_seq.reverse_complement())\n\nagtacactggt\nAGTACACTGGT\nTCATGTGACCA\nACCAGTGTACT\n\n\n\nTranscription, Translation\n\n\nmrna = my_seq.transcribe()\nprint(mrna)\nprot = mrna.translate() ## truncated\nprint(prot)\nprint(my_seq.translate())\n\nAGUACACUGGU\nSTL\nSTL\n\n\n/home/haseong/anaconda3/envs/biopy/lib/python3.11/site-packages/Bio/Seq.py:2880: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n  warnings.warn(\n\n\n\nfrom Bio.Data import CodonTable\nstandard_table = CodonTable.unambiguous_dna_by_id[1]\nprint(standard_table)\nprint(standard_table.start_codons)\nprint(standard_table.stop_codons)\nprint(type(standard_table))\n\nTable 1 Standard, SGC0\n\n  |  T      |  C      |  A      |  G      |\n--+---------+---------+---------+---------+--\nT | TTT F   | TCT S   | TAT Y   | TGT C   | T\nT | TTC F   | TCC S   | TAC Y   | TGC C   | C\nT | TTA L   | TCA S   | TAA Stop| TGA Stop| A\nT | TTG L(s)| TCG S   | TAG Stop| TGG W   | G\n--+---------+---------+---------+---------+--\nC | CTT L   | CCT P   | CAT H   | CGT R   | T\nC | CTC L   | CCC P   | CAC H   | CGC R   | C\nC | CTA L   | CCA P   | CAA Q   | CGA R   | A\nC | CTG L(s)| CCG P   | CAG Q   | CGG R   | G\n--+---------+---------+---------+---------+--\nA | ATT I   | ACT T   | AAT N   | AGT S   | T\nA | ATC I   | ACC T   | AAC N   | AGC S   | C\nA | ATA I   | ACA T   | AAA K   | AGA R   | A\nA | ATG M(s)| ACG T   | AAG K   | AGG R   | G\n--+---------+---------+---------+---------+--\nG | GTT V   | GCT A   | GAT D   | GGT G   | T\nG | GTC V   | GCC A   | GAC D   | GGC G   | C\nG | GTA V   | GCA A   | GAA E   | GGA G   | A\nG | GTG V   | GCG A   | GAG E   | GGG G   | G\n--+---------+---------+---------+---------+--\n['TTG', 'CTG', 'ATG']\n['TAA', 'TAG', 'TGA']\n&lt;class 'Bio.Data.CodonTable.NCBICodonTableDNA'&gt;\n\n\n\nMutableSeq objects\n\n\nfrom Bio.Seq import Seq\nmy_seq = Seq(\"AGTACACTGGT\")\nmy_seq[5] = \"G\"\n\nTypeError: 'Seq' object does not support item assignment\n\n\n\nfrom Bio.Seq import MutableSeq\n\nmutable_seq = MutableSeq(my_seq)\nmutable_seq\n\nmutable_seq[5] = \"G\"\nmutable_seq\n\nnew_seq = Seq(mutable_seq)\nnew_seq\n\nSeq('AGTACGCTGGT')\n\n\n\nFinding subsequence\n\n\nseq = Seq(\"GCCATTGTAATGGGCCGCTGAAAGGGTGCCCGA\")\nprint(seq.index(\"ATG\"))\nprint(seq.find(\"ATG\"))\nprint(seq.find(\"AAAAA\"))\n\n9\n9\n-1\n\n\n\n\n5.3.3 SeqRecord\n\nSequence annotation objects\n특정 서열의 identifier나 feature 정보 포함\n\n\nfrom Bio.Seq import Seq\nfrom Bio.SeqRecord import SeqRecord\n\nsimple_seq = Seq(\"GATC\")\nsimple_seq_r = SeqRecord(simple_seq)\n\n\nhelp(SeqRecord)\n\nHelp on class SeqRecord in module Bio.SeqRecord:\n\nclass SeqRecord(builtins.object)\n |  SeqRecord(seq: Union[ForwardRef('Seq'), ForwardRef('MutableSeq'), NoneType], id: Optional[str] = '&lt;unknown id&gt;', name: str = '&lt;unknown name&gt;', description: str = '&lt;unknown description&gt;', dbxrefs: Optional[List[str]] = None, features: Optional[List[ForwardRef('SeqFeature')]] = None, annotations: Optional[Dict[str, Union[str, int]]] = None, letter_annotations: Optional[Dict[str, Sequence[Any]]] = None) -&gt; None\n |  \n |  A SeqRecord object holds a sequence and information about it.\n |  \n |  Main attributes:\n |   - id          - Identifier such as a locus tag (string)\n |   - seq         - The sequence itself (Seq object or similar)\n |  \n |  Additional attributes:\n |   - name        - Sequence name, e.g. gene name (string)\n |   - description - Additional text (string)\n |   - dbxrefs     - List of database cross references (list of strings)\n |   - features    - Any (sub)features defined (list of SeqFeature objects)\n |   - annotations - Further information about the whole sequence (dictionary).\n |     Most entries are strings, or lists of strings.\n |   - letter_annotations - Per letter/symbol annotation (restricted\n |     dictionary). This holds Python sequences (lists, strings\n |     or tuples) whose length matches that of the sequence.\n |     A typical use would be to hold a list of integers\n |     representing sequencing quality scores, or a string\n |     representing the secondary structure.\n |  \n |  You will typically use Bio.SeqIO to read in sequences from files as\n |  SeqRecord objects.  However, you may want to create your own SeqRecord\n |  objects directly (see the __init__ method for further details):\n |  \n |  &gt;&gt;&gt; from Bio.Seq import Seq\n |  &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |  &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |  ...                    id=\"YP_025292.1\", name=\"HokC\",\n |  ...                    description=\"toxic membrane protein\")\n |  &gt;&gt;&gt; print(record)\n |  ID: YP_025292.1\n |  Name: HokC\n |  Description: toxic membrane protein\n |  Number of features: 0\n |  Seq('MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF')\n |  \n |  If you want to save SeqRecord objects to a sequence file, use Bio.SeqIO\n |  for this.  For the special case where you want the SeqRecord turned into\n |  a string in a particular file format there is a format method which uses\n |  Bio.SeqIO internally:\n |  \n |  &gt;&gt;&gt; print(record.format(\"fasta\"))\n |  &gt;YP_025292.1 toxic membrane protein\n |  MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |  &lt;BLANKLINE&gt;\n |  \n |  You can also do things like slicing a SeqRecord, checking its length, etc\n |  \n |  &gt;&gt;&gt; len(record)\n |  44\n |  &gt;&gt;&gt; edited = record[:10] + record[11:]\n |  &gt;&gt;&gt; print(edited.seq)\n |  MKQHKAMIVAIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |  &gt;&gt;&gt; print(record.seq)\n |  MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |  \n |  Methods defined here:\n |  \n |  __add__(self, other: Union[ForwardRef('SeqRecord'), ForwardRef('Seq'), ForwardRef('MutableSeq'), str]) -&gt; 'SeqRecord'\n |      Add another sequence or string to this sequence.\n |      \n |      The other sequence can be a SeqRecord object, a Seq object (or\n |      similar, e.g. a MutableSeq) or a plain Python string. If you add\n |      a plain string or a Seq (like) object, the new SeqRecord will simply\n |      have this appended to the existing data. However, any per letter\n |      annotation will be lost:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      \n |      &gt;&gt;&gt; new = record + \"ACT\"\n |      &gt;&gt;&gt; print(\"%s %s\" % (new.id, new.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNNACT\n |      &gt;&gt;&gt; print(list(new.letter_annotations))\n |      []\n |      \n |      The new record will attempt to combine the annotation, but for any\n |      ambiguities (e.g. different names) it defaults to omitting that\n |      annotation.\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; with open(\"GenBank/pBAD30.gb\") as handle:\n |      ...     plasmid = SeqIO.read(handle, \"gb\")\n |      &gt;&gt;&gt; print(\"%s %i\" % (plasmid.id, len(plasmid)))\n |      pBAD30 4923\n |      \n |      Now let's cut the plasmid into two pieces, and join them back up the\n |      other way round (i.e. shift the starting point on this plasmid, have\n |      a look at the annotated features in the original file to see why this\n |      particular split point might make sense):\n |      \n |      &gt;&gt;&gt; left = plasmid[:3765]\n |      &gt;&gt;&gt; right = plasmid[3765:]\n |      &gt;&gt;&gt; new = right + left\n |      &gt;&gt;&gt; print(\"%s %i\" % (new.id, len(new)))\n |      pBAD30 4923\n |      &gt;&gt;&gt; str(new.seq) == str(right.seq + left.seq)\n |      True\n |      &gt;&gt;&gt; len(new.features) == len(left.features) + len(right.features)\n |      True\n |      \n |      When we add the left and right SeqRecord objects, their annotation\n |      is all consistent, so it is all conserved in the new SeqRecord:\n |      \n |      &gt;&gt;&gt; new.id == left.id == right.id == plasmid.id\n |      True\n |      &gt;&gt;&gt; new.name == left.name == right.name == plasmid.name\n |      True\n |      &gt;&gt;&gt; new.description == plasmid.description\n |      True\n |      &gt;&gt;&gt; new.annotations == left.annotations == right.annotations\n |      True\n |      &gt;&gt;&gt; new.letter_annotations == plasmid.letter_annotations\n |      True\n |      &gt;&gt;&gt; new.dbxrefs == left.dbxrefs == right.dbxrefs\n |      True\n |      \n |      However, we should point out that when we sliced the SeqRecord,\n |      any annotations dictionary or dbxrefs list entries were lost.\n |      You can explicitly copy them like this:\n |      \n |      &gt;&gt;&gt; new.annotations = plasmid.annotations.copy()\n |      &gt;&gt;&gt; new.dbxrefs = plasmid.dbxrefs[:]\n |  \n |  __bool__(self) -&gt; bool\n |      Boolean value of an instance of this class (True).\n |      \n |      This behaviour is for backwards compatibility, since until the\n |      __len__ method was added, a SeqRecord always evaluated as True.\n |      \n |      Note that in comparison, a Seq object will evaluate to False if it\n |      has a zero length sequence.\n |      \n |      WARNING: The SeqRecord may in future evaluate to False when its\n |      sequence is of zero length (in order to better match the Seq\n |      object behaviour)!\n |  \n |  __bytes__(self) -&gt; bytes\n |  \n |  __contains__(self, char: str) -&gt; bool\n |      Implement the 'in' keyword, searches the sequence.\n |      \n |      e.g.\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/sweetpea.nu\", \"fasta\")\n |      &gt;&gt;&gt; \"GAATTC\" in record\n |      False\n |      &gt;&gt;&gt; \"AAA\" in record\n |      True\n |      \n |      This essentially acts as a proxy for using \"in\" on the sequence:\n |      \n |      &gt;&gt;&gt; \"GAATTC\" in record.seq\n |      False\n |      &gt;&gt;&gt; \"AAA\" in record.seq\n |      True\n |      \n |      Note that you can also use Seq objects as the query,\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; Seq(\"AAA\") in record\n |      True\n |      \n |      See also the Seq object's __contains__ method.\n |  \n |  __eq__(self, other: object) -&gt; NoReturn\n |      Define the equal-to operand (not implemented).\n |  \n |  __format__(self, format_spec: str) -&gt; str\n |      Return the record as a string in the specified file format.\n |      \n |      This method supports the Python format() function and f-strings.\n |      The format_spec should be a lower case string supported by\n |      Bio.SeqIO as a text output file format. Requesting a binary file\n |      format raises a ValueError. e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |      ...                    id=\"YP_025292.1\", name=\"HokC\",\n |      ...                    description=\"toxic membrane protein\")\n |      ...\n |      &gt;&gt;&gt; format(record, \"fasta\")\n |      '&gt;YP_025292.1 toxic membrane protein\\nMKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\\n'\n |      &gt;&gt;&gt; print(f\"Here is {record.id} in FASTA format:\\n{record:fasta}\")\n |      Here is YP_025292.1 in FASTA format:\n |      &gt;YP_025292.1 toxic membrane protein\n |      MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |      &lt;BLANKLINE&gt;\n |      \n |      See also the SeqRecord's format() method.\n |  \n |  __ge__(self, other: Any) -&gt; NoReturn\n |      Define the greater-than-or-equal-to operand (not implemented).\n |  \n |  __getitem__(self, index)\n |      Return a sub-sequence or an individual letter.\n |      \n |      Slicing, e.g. my_record[5:10], returns a new SeqRecord for\n |      that sub-sequence with some annotation preserved as follows:\n |      \n |      * The name, id and description are kept as-is.\n |      * Any per-letter-annotations are sliced to match the requested\n |        sub-sequence.\n |      * Unless a stride is used, all those features which fall fully\n |        within the subsequence are included (with their locations\n |        adjusted accordingly). If you want to preserve any truncated\n |        features (e.g. GenBank/EMBL source features), you must\n |        explicitly add them to the new SeqRecord yourself.\n |      * With the exception of any molecule type, the annotations\n |        dictionary and the dbxrefs list are not used for the new\n |        SeqRecord, as in general they may not apply to the\n |        subsequence. If you want to preserve them, you must explicitly\n |        copy them to the new SeqRecord yourself.\n |      \n |      Using an integer index, e.g. my_record[5] is shorthand for\n |      extracting that letter from the sequence, my_record.seq[5].\n |      \n |      For example, consider this short protein and its secondary\n |      structure as encoded by the PDB (e.g. H for alpha helices),\n |      plus a simple feature for its histidine self phosphorylation\n |      site:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; from Bio.SeqFeature import SeqFeature, SimpleLocation\n |      &gt;&gt;&gt; rec = SeqRecord(Seq(\"MAAGVKQLADDRTLLMAGVSHDLRTPLTRIRLAT\"\n |      ...                     \"EMMSEQDGYLAESINKDIEECNAIIEQFIDYLR\"),\n |      ...                 id=\"1JOY\", name=\"EnvZ\",\n |      ...                 description=\"Homodimeric domain of EnvZ from E. coli\")\n |      &gt;&gt;&gt; rec.letter_annotations[\"secondary_structure\"] = \"  S  SSSSSSHHHHHTTTHHHHHHHHHHHHHHHHHHHHHHTHHHHHHHHHHHHHHHHHHHHHTT  \"\n |      &gt;&gt;&gt; rec.features.append(SeqFeature(SimpleLocation(20, 21),\n |      ...                     type = \"Site\"))\n |      \n |      Now let's have a quick look at the full record,\n |      \n |      &gt;&gt;&gt; print(rec)\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 1\n |      Per letter annotation for: secondary_structure\n |      Seq('MAAGVKQLADDRTLLMAGVSHDLRTPLTRIRLATEMMSEQDGYLAESINKDIEE...YLR')\n |      &gt;&gt;&gt; rec.letter_annotations[\"secondary_structure\"]\n |      '  S  SSSSSSHHHHHTTTHHHHHHHHHHHHHHHHHHHHHHTHHHHHHHHHHHHHHHHHHHHHTT  '\n |      &gt;&gt;&gt; print(rec.features[0].location)\n |      [20:21]\n |      \n |      Now let's take a sub sequence, here chosen as the first (fractured)\n |      alpha helix which includes the histidine phosphorylation site:\n |      \n |      &gt;&gt;&gt; sub = rec[11:41]\n |      &gt;&gt;&gt; print(sub)\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 1\n |      Per letter annotation for: secondary_structure\n |      Seq('RTLLMAGVSHDLRTPLTRIRLATEMMSEQD')\n |      &gt;&gt;&gt; sub.letter_annotations[\"secondary_structure\"]\n |      'HHHHHTTTHHHHHHHHHHHHHHHHHHHHHH'\n |      &gt;&gt;&gt; print(sub.features[0].location)\n |      [9:10]\n |      \n |      You can also of course omit the start or end values, for\n |      example to get the first ten letters only:\n |      \n |      &gt;&gt;&gt; print(rec[:10])\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 0\n |      Per letter annotation for: secondary_structure\n |      Seq('MAAGVKQLAD')\n |      \n |      Or for the last ten letters:\n |      \n |      &gt;&gt;&gt; print(rec[-10:])\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 0\n |      Per letter annotation for: secondary_structure\n |      Seq('IIEQFIDYLR')\n |      \n |      If you omit both, then you get a copy of the original record (although\n |      lacking the annotations and dbxrefs):\n |      \n |      &gt;&gt;&gt; print(rec[:])\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 1\n |      Per letter annotation for: secondary_structure\n |      Seq('MAAGVKQLADDRTLLMAGVSHDLRTPLTRIRLATEMMSEQDGYLAESINKDIEE...YLR')\n |      \n |      Finally, indexing with a simple integer is shorthand for pulling out\n |      that letter from the sequence directly:\n |      \n |      &gt;&gt;&gt; rec[5]\n |      'K'\n |      &gt;&gt;&gt; rec.seq[5]\n |      'K'\n |  \n |  __gt__(self, other: Any) -&gt; NoReturn\n |      Define the greater-than operand (not implemented).\n |  \n |  __init__(self, seq: Union[ForwardRef('Seq'), ForwardRef('MutableSeq'), NoneType], id: Optional[str] = '&lt;unknown id&gt;', name: str = '&lt;unknown name&gt;', description: str = '&lt;unknown description&gt;', dbxrefs: Optional[List[str]] = None, features: Optional[List[ForwardRef('SeqFeature')]] = None, annotations: Optional[Dict[str, Union[str, int]]] = None, letter_annotations: Optional[Dict[str, Sequence[Any]]] = None) -&gt; None\n |      Create a SeqRecord.\n |      \n |      Arguments:\n |       - seq         - Sequence, required (Seq or MutableSeq)\n |       - id          - Sequence identifier, recommended (string)\n |       - name        - Sequence name, optional (string)\n |       - description - Sequence description, optional (string)\n |       - dbxrefs     - Database cross references, optional (list of strings)\n |       - features    - Any (sub)features, optional (list of SeqFeature objects)\n |       - annotations - Dictionary of annotations for the whole sequence\n |       - letter_annotations - Dictionary of per-letter-annotations, values\n |         should be strings, list or tuples of the same length as the full\n |         sequence.\n |      \n |      You will typically use Bio.SeqIO to read in sequences from files as\n |      SeqRecord objects.  However, you may want to create your own SeqRecord\n |      objects directly.\n |      \n |      Note that while an id is optional, we strongly recommend you supply a\n |      unique id string for each record.  This is especially important\n |      if you wish to write your sequences to a file.\n |      \n |      You can create a 'blank' SeqRecord object, and then populate the\n |      attributes later.\n |  \n |  __iter__(self) -&gt; Iterable[Union[ForwardRef('Seq'), ForwardRef('MutableSeq')]]\n |      Iterate over the letters in the sequence.\n |      \n |      For example, using Bio.SeqIO to read in a protein FASTA file:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/loveliesbleeding.pro\", \"fasta\")\n |      &gt;&gt;&gt; for amino in record:\n |      ...     print(amino)\n |      ...     if amino == \"L\": break\n |      X\n |      A\n |      G\n |      L\n |      &gt;&gt;&gt; print(record.seq[3])\n |      L\n |      \n |      This is just a shortcut for iterating over the sequence directly:\n |      \n |      &gt;&gt;&gt; for amino in record.seq:\n |      ...     print(amino)\n |      ...     if amino == \"L\": break\n |      X\n |      A\n |      G\n |      L\n |      &gt;&gt;&gt; print(record.seq[3])\n |      L\n |      \n |      Note that this does not facilitate iteration together with any\n |      per-letter-annotation.  However, you can achieve that using the\n |      python zip function on the record (or its sequence) and the relevant\n |      per-letter-annotation:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; rec = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (rec.id, rec.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(rec.letter_annotations))\n |      ['solexa_quality']\n |      &gt;&gt;&gt; for nuc, qual in zip(rec, rec.letter_annotations[\"solexa_quality\"]):\n |      ...     if qual &gt; 35:\n |      ...         print(\"%s %i\" % (nuc, qual))\n |      A 40\n |      C 39\n |      G 38\n |      T 37\n |      A 36\n |      \n |      You may agree that using zip(rec.seq, ...) is more explicit than using\n |      zip(rec, ...) as shown above.\n |  \n |  __le__(self, other: Any) -&gt; NoReturn\n |      Define the less-than-or-equal-to operand (not implemented).\n |  \n |  __len__(self) -&gt; int\n |      Return the length of the sequence.\n |      \n |      For example, using Bio.SeqIO to read in a FASTA nucleotide file:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/sweetpea.nu\", \"fasta\")\n |      &gt;&gt;&gt; len(record)\n |      309\n |      &gt;&gt;&gt; len(record.seq)\n |      309\n |  \n |  __lt__(self, other: Any) -&gt; NoReturn\n |      Define the less-than operand (not implemented).\n |  \n |  __ne__(self, other: object) -&gt; NoReturn\n |      Define the not-equal-to operand (not implemented).\n |  \n |  __radd__(self, other: Union[ForwardRef('Seq'), ForwardRef('MutableSeq'), str]) -&gt; 'SeqRecord'\n |      Add another sequence or string to this sequence (from the left).\n |      \n |      This method handles adding a Seq object (or similar, e.g. MutableSeq)\n |      or a plain Python string (on the left) to a SeqRecord (on the right).\n |      See the __add__ method for more details, but for example:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      \n |      &gt;&gt;&gt; new = \"ACT\" + record\n |      &gt;&gt;&gt; print(\"%s %s\" % (new.id, new.seq))\n |      slxa_0001_1_0001_01 ACTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(new.letter_annotations))\n |      []\n |  \n |  __repr__(self) -&gt; str\n |      Return a concise summary of the record for debugging (string).\n |      \n |      The python built in function repr works by calling the object's __repr__\n |      method.  e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; rec = SeqRecord(Seq(\"MASRGVNKVILVGNLGQDPEVRYMPNGGAVANITLATSESWRDKAT\"\n |      ...                     \"GEMKEQTEWHRVVLFGKLAEVASEYLRKGSQVYIEGQLRTRKWTDQ\"\n |      ...                     \"SGQDRYTTEVVVNVGGTMQMLGGRQGGGAPAGGNIGGGQPQGGWGQ\"\n |      ...                     \"PQQPQGGNQFSGGAQSRPQQSAPAAPSNEPPMDFDDDIPF\"),\n |      ...                 id=\"NP_418483.1\", name=\"b4059\",\n |      ...                 description=\"ssDNA-binding protein\",\n |      ...                 dbxrefs=[\"ASAP:13298\", \"GI:16131885\", \"GeneID:948570\"])\n |      &gt;&gt;&gt; print(repr(rec))\n |      SeqRecord(seq=Seq('MASRGVNKVILVGNLGQDPEVRYMPNGGAVANITLATSESWRDKATGEMKEQTE...IPF'), id='NP_418483.1', name='b4059', description='ssDNA-binding protein', dbxrefs=['ASAP:13298', 'GI:16131885', 'GeneID:948570'])\n |      \n |      At the python prompt you can also use this shorthand:\n |      \n |      &gt;&gt;&gt; rec\n |      SeqRecord(seq=Seq('MASRGVNKVILVGNLGQDPEVRYMPNGGAVANITLATSESWRDKATGEMKEQTE...IPF'), id='NP_418483.1', name='b4059', description='ssDNA-binding protein', dbxrefs=['ASAP:13298', 'GI:16131885', 'GeneID:948570'])\n |      \n |      Note that long sequences are shown truncated. Also note that any\n |      annotations, letter_annotations and features are not shown (as they\n |      would lead to a very long string).\n |  \n |  __str__(self) -&gt; str\n |      Return a human readable summary of the record and its annotation (string).\n |      \n |      The python built in function str works by calling the object's __str__\n |      method.  e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |      ...                    id=\"YP_025292.1\", name=\"HokC\",\n |      ...                    description=\"toxic membrane protein, small\")\n |      &gt;&gt;&gt; print(str(record))\n |      ID: YP_025292.1\n |      Name: HokC\n |      Description: toxic membrane protein, small\n |      Number of features: 0\n |      Seq('MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF')\n |      \n |      In this example you don't actually need to call str explicitly, as the\n |      print command does this automatically:\n |      \n |      &gt;&gt;&gt; print(record)\n |      ID: YP_025292.1\n |      Name: HokC\n |      Description: toxic membrane protein, small\n |      Number of features: 0\n |      Seq('MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF')\n |      \n |      Note that long sequences are shown truncated.\n |  \n |  count(self, sub, start=None, end=None)\n |      Return the number of non-overlapping occurrences of sub in seq[start:end].\n |      \n |      Optional arguments start and end are interpreted as in slice notation.\n |      This method behaves as the count method of Python strings.\n |  \n |  format(self, format: str) -&gt; str\n |      Return the record as a string in the specified file format.\n |      \n |      The format should be a lower case string supported as an output\n |      format by Bio.SeqIO, which is used to turn the SeqRecord into a\n |      string.  e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |      ...                    id=\"YP_025292.1\", name=\"HokC\",\n |      ...                    description=\"toxic membrane protein\")\n |      &gt;&gt;&gt; record.format(\"fasta\")\n |      '&gt;YP_025292.1 toxic membrane protein\\nMKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\\n'\n |      &gt;&gt;&gt; print(record.format(\"fasta\"))\n |      &gt;YP_025292.1 toxic membrane protein\n |      MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |      &lt;BLANKLINE&gt;\n |      \n |      The Python print function automatically appends a new line, meaning\n |      in this example a blank line is shown.  If you look at the string\n |      representation you can see there is a trailing new line (shown as\n |      slash n) which is important when writing to a file or if\n |      concatenating multiple sequence strings together.\n |      \n |      Note that this method will NOT work on every possible file format\n |      supported by Bio.SeqIO (e.g. some are for multiple sequences only,\n |      and binary formats are not supported).\n |  \n |  islower(self)\n |      Return True if all ASCII characters in the record's sequence are lowercase.\n |      \n |      If there are no cased characters, the method returns False.\n |  \n |  isupper(self)\n |      Return True if all ASCII characters in the record's sequence are uppercase.\n |      \n |      If there are no cased characters, the method returns False.\n |  \n |  lower(self) -&gt; 'SeqRecord'\n |      Return a copy of the record with a lower case sequence.\n |      \n |      All the annotation is preserved unchanged. e.g.\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/aster.pro\", \"fasta\")\n |      &gt;&gt;&gt; print(record.format(\"fasta\"))\n |      &gt;gi|3298468|dbj|BAA31520.1| SAMIPF\n |      GGHVNPAVTFGAFVGGNITLLRGIVYIIAQLLGSTVACLLLKFVTNDMAVGVFSLSAGVG\n |      VTNALVFEIVMTFGLVYTVYATAIDPKKGSLGTIAPIAIGFIVGANI\n |      &lt;BLANKLINE&gt;\n |      &gt;&gt;&gt; print(record.lower().format(\"fasta\"))\n |      &gt;gi|3298468|dbj|BAA31520.1| SAMIPF\n |      gghvnpavtfgafvggnitllrgivyiiaqllgstvaclllkfvtndmavgvfslsagvg\n |      vtnalvfeivmtfglvytvyataidpkkgslgtiapiaigfivgani\n |      &lt;BLANKLINE&gt;\n |      \n |      To take a more annotation rich example,\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; old = SeqIO.read(\"EMBL/TRBG361.embl\", \"embl\")\n |      &gt;&gt;&gt; len(old.features)\n |      3\n |      &gt;&gt;&gt; new = old.lower()\n |      &gt;&gt;&gt; len(old.features) == len(new.features)\n |      True\n |      &gt;&gt;&gt; old.annotations[\"organism\"] == new.annotations[\"organism\"]\n |      True\n |      &gt;&gt;&gt; old.dbxrefs == new.dbxrefs\n |      True\n |  \n |  reverse_complement(self, id: bool = False, name: bool = False, description: bool = False, features: bool = True, annotations: bool = False, letter_annotations: bool = True, dbxrefs: bool = False) -&gt; 'SeqRecord'\n |      Return new SeqRecord with reverse complement sequence.\n |      \n |      By default the new record does NOT preserve the sequence identifier,\n |      name, description, general annotation or database cross-references -\n |      these are unlikely to apply to the reversed sequence.\n |      \n |      You can specify the returned record's id, name and description as\n |      strings, or True to keep that of the parent, or False for a default.\n |      \n |      You can specify the returned record's features with a list of\n |      SeqFeature objects, or True to keep that of the parent, or False to\n |      omit them. The default is to keep the original features (with the\n |      strand and locations adjusted).\n |      \n |      You can also specify both the returned record's annotations and\n |      letter_annotations as dictionaries, True to keep that of the parent,\n |      or False to omit them. The default is to keep the original\n |      annotations (with the letter annotations reversed).\n |      \n |      To show what happens to the pre-letter annotations, consider an\n |      example Solexa variant FASTQ file with a single entry, which we'll\n |      read in as a SeqRecord:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      &gt;&gt;&gt; print(record.letter_annotations[\"solexa_quality\"])\n |      [40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -1, -2, -3, -4, -5]\n |      \n |      Now take the reverse complement, here we explicitly give a new\n |      identifier (the old identifier with a suffix):\n |      \n |      &gt;&gt;&gt; rc_record = record.reverse_complement(id=record.id + \"_rc\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (rc_record.id, rc_record.seq))\n |      slxa_0001_1_0001_01_rc NNNNNNACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\n |      \n |      Notice that the per-letter-annotations have also been reversed,\n |      although this may not be appropriate for all cases.\n |      \n |      &gt;&gt;&gt; print(rc_record.letter_annotations[\"solexa_quality\"])\n |      [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n |      \n |      Now for the features, we need a different example. Parsing a GenBank\n |      file is probably the easiest way to get an nice example with features\n |      in it...\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; with open(\"GenBank/pBAD30.gb\") as handle:\n |      ...     plasmid = SeqIO.read(handle, \"gb\")\n |      &gt;&gt;&gt; print(\"%s %i\" % (plasmid.id, len(plasmid)))\n |      pBAD30 4923\n |      &gt;&gt;&gt; plasmid.seq\n |      Seq('GCTAGCGGAGTGTATACTGGCTTACTATGTTGGCACTGATGAGGGTGTCAGTGA...ATG')\n |      &gt;&gt;&gt; len(plasmid.features)\n |      13\n |      \n |      Now, let's take the reverse complement of this whole plasmid:\n |      \n |      &gt;&gt;&gt; rc_plasmid = plasmid.reverse_complement(id=plasmid.id+\"_rc\")\n |      &gt;&gt;&gt; print(\"%s %i\" % (rc_plasmid.id, len(rc_plasmid)))\n |      pBAD30_rc 4923\n |      &gt;&gt;&gt; rc_plasmid.seq\n |      Seq('CATGGGCAAATATTATACGCAAGGCGACAAGGTGCTGATGCCGCTGGCGATTCA...AGC')\n |      &gt;&gt;&gt; len(rc_plasmid.features)\n |      13\n |      \n |      Let's compare the first CDS feature - it has gone from being the\n |      second feature (index 1) to the second last feature (index -2), its\n |      strand has changed, and the location switched round.\n |      \n |      &gt;&gt;&gt; print(plasmid.features[1])\n |      type: CDS\n |      location: [1081:1960](-)\n |      qualifiers:\n |          Key: label, Value: ['araC']\n |          Key: note, Value: ['araC regulator of the arabinose BAD promoter']\n |          Key: vntifkey, Value: ['4']\n |      &lt;BLANKLINE&gt;\n |      &gt;&gt;&gt; print(rc_plasmid.features[-2])\n |      type: CDS\n |      location: [2963:3842](+)\n |      qualifiers:\n |          Key: label, Value: ['araC']\n |          Key: note, Value: ['araC regulator of the arabinose BAD promoter']\n |          Key: vntifkey, Value: ['4']\n |      &lt;BLANKLINE&gt;\n |      \n |      You can check this new location, based on the length of the plasmid:\n |      \n |      &gt;&gt;&gt; len(plasmid) - 1081\n |      3842\n |      &gt;&gt;&gt; len(plasmid) - 1960\n |      2963\n |      \n |      Note that if the SeqFeature annotation includes any strand specific\n |      information (e.g. base changes for a SNP), this information is not\n |      amended, and would need correction after the reverse complement.\n |      \n |      Note trying to reverse complement a protein SeqRecord raises an\n |      exception:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; protein_rec = SeqRecord(Seq(\"MAIVMGR\"), id=\"Test\",\n |      ...                         annotations={\"molecule_type\": \"protein\"})\n |      &gt;&gt;&gt; protein_rec.reverse_complement()\n |      Traceback (most recent call last):\n |         ...\n |      ValueError: Proteins do not have complements!\n |      \n |      If you have RNA without any U bases, it must be annotated as RNA\n |      otherwise it will be treated as DNA by default with A mapped to T:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; rna1 = SeqRecord(Seq(\"ACG\"), id=\"Test\")\n |      &gt;&gt;&gt; rna2 = SeqRecord(Seq(\"ACG\"), id=\"Test\", annotations={\"molecule_type\": \"RNA\"})\n |      &gt;&gt;&gt; print(rna1.reverse_complement(id=\"RC\", description=\"unk\").format(\"fasta\"))\n |      &gt;RC unk\n |      CGT\n |      &lt;BLANKLINE&gt;\n |      &gt;&gt;&gt; print(rna2.reverse_complement(id=\"RC\", description=\"RNA\").format(\"fasta\"))\n |      &gt;RC RNA\n |      CGU\n |      &lt;BLANKLINE&gt;\n |      \n |      Also note you can reverse complement a SeqRecord using a MutableSeq:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import MutableSeq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; rec = SeqRecord(MutableSeq(\"ACGT\"), id=\"Test\")\n |      &gt;&gt;&gt; rec.seq[0] = \"T\"\n |      &gt;&gt;&gt; print(\"%s %s\" % (rec.id, rec.seq))\n |      Test TCGT\n |      &gt;&gt;&gt; rc = rec.reverse_complement(id=True)\n |      &gt;&gt;&gt; print(\"%s %s\" % (rc.id, rc.seq))\n |      Test ACGA\n |  \n |  translate(self, table: str = 'Standard', stop_symbol: str = '*', to_stop: bool = False, cds: bool = False, gap: Optional[str] = None, id: bool = False, name: bool = False, description: bool = False, features: bool = False, annotations: bool = False, letter_annotations: bool = False, dbxrefs: bool = False) -&gt; 'SeqRecord'\n |      Return new SeqRecord with translated sequence.\n |      \n |      This calls the record's .seq.translate() method (which describes\n |      the translation related arguments, like table for the genetic code),\n |      \n |      By default the new record does NOT preserve the sequence identifier,\n |      name, description, general annotation or database cross-references -\n |      these are unlikely to apply to the translated sequence.\n |      \n |      You can specify the returned record's id, name and description as\n |      strings, or True to keep that of the parent, or False for a default.\n |      \n |      You can specify the returned record's features with a list of\n |      SeqFeature objects, or False (default) to omit them.\n |      \n |      You can also specify both the returned record's annotations and\n |      letter_annotations as dictionaries, True to keep that of the parent\n |      (annotations only), or False (default) to omit them.\n |      \n |      e.g. Loading a FASTA gene and translating it,\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; gene_record = SeqIO.read(\"Fasta/sweetpea.nu\", \"fasta\")\n |      &gt;&gt;&gt; print(gene_record.format(\"fasta\"))\n |      &gt;gi|3176602|gb|U78617.1|LOU78617 Lathyrus odoratus phytochrome A (PHYA) gene, partial cds\n |      CAGGCTGCGCGGTTTCTATTTATGAAGAACAAGGTCCGTATGATAGTTGATTGTCATGCA\n |      AAACATGTGAAGGTTCTTCAAGACGAAAAACTCCCATTTGATTTGACTCTGTGCGGTTCG\n |      ACCTTAAGAGCTCCACATAGTTGCCATTTGCAGTACATGGCTAACATGGATTCAATTGCT\n |      TCATTGGTTATGGCAGTGGTCGTCAATGACAGCGATGAAGATGGAGATAGCCGTGACGCA\n |      GTTCTACCACAAAAGAAAAAGAGACTTTGGGGTTTGGTAGTTTGTCATAACACTACTCCG\n |      AGGTTTGTT\n |      &lt;BLANKLINE&gt;\n |      \n |      And now translating the record, specifying the new ID and description:\n |      \n |      &gt;&gt;&gt; protein_record = gene_record.translate(table=11,\n |      ...                                        id=\"phya\",\n |      ...                                        description=\"translation\")\n |      &gt;&gt;&gt; print(protein_record.format(\"fasta\"))\n |      &gt;phya translation\n |      QAARFLFMKNKVRMIVDCHAKHVKVLQDEKLPFDLTLCGSTLRAPHSCHLQYMANMDSIA\n |      SLVMAVVVNDSDEDGDSRDAVLPQKKKRLWGLVVCHNTTPRFV\n |      &lt;BLANKLINE&gt;\n |  \n |  upper(self) -&gt; 'SeqRecord'\n |      Return a copy of the record with an upper case sequence.\n |      \n |      All the annotation is preserved unchanged. e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"acgtACGT\"), id=\"Test\",\n |      ...                    description = \"Made up for this example\")\n |      &gt;&gt;&gt; record.letter_annotations[\"phred_quality\"] = [1, 2, 3, 4, 5, 6, 7, 8]\n |      &gt;&gt;&gt; print(record.upper().format(\"fastq\"))\n |      @Test Made up for this example\n |      ACGTACGT\n |      +\n |      \"#$%&'()\n |      &lt;BLANKLINE&gt;\n |      \n |      Naturally, there is a matching lower method:\n |      \n |      &gt;&gt;&gt; print(record.lower().format(\"fastq\"))\n |      @Test Made up for this example\n |      acgtacgt\n |      +\n |      \"#$%&'()\n |      &lt;BLANKLINE&gt;\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  letter_annotations\n |      Dictionary of per-letter-annotation for the sequence.\n |      \n |      For example, this can hold quality scores used in FASTQ or QUAL files.\n |      Consider this example using Bio.SeqIO to read in an example Solexa\n |      variant FASTQ file as a SeqRecord:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      &gt;&gt;&gt; print(record.letter_annotations[\"solexa_quality\"])\n |      [40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -1, -2, -3, -4, -5]\n |      \n |      The letter_annotations get sliced automatically if you slice the\n |      parent SeqRecord, for example taking the last ten bases:\n |      \n |      &gt;&gt;&gt; sub_record = record[-10:]\n |      &gt;&gt;&gt; print(\"%s %s\" % (sub_record.id, sub_record.seq))\n |      slxa_0001_1_0001_01 ACGTNNNNNN\n |      &gt;&gt;&gt; print(sub_record.letter_annotations[\"solexa_quality\"])\n |      [4, 3, 2, 1, 0, -1, -2, -3, -4, -5]\n |      \n |      Any python sequence (i.e. list, tuple or string) can be recorded in\n |      the SeqRecord's letter_annotations dictionary as long as the length\n |      matches that of the SeqRecord's sequence.  e.g.\n |      \n |      &gt;&gt;&gt; len(sub_record.letter_annotations)\n |      1\n |      &gt;&gt;&gt; sub_record.letter_annotations[\"dummy\"] = \"abcdefghij\"\n |      &gt;&gt;&gt; len(sub_record.letter_annotations)\n |      2\n |      \n |      You can delete entries from the letter_annotations dictionary as usual:\n |      \n |      &gt;&gt;&gt; del sub_record.letter_annotations[\"solexa_quality\"]\n |      &gt;&gt;&gt; sub_record.letter_annotations\n |      {'dummy': 'abcdefghij'}\n |      \n |      You can completely clear the dictionary easily as follows:\n |      \n |      &gt;&gt;&gt; sub_record.letter_annotations = {}\n |      &gt;&gt;&gt; sub_record.letter_annotations\n |      {}\n |      \n |      Note that if replacing the record's sequence with a sequence of a\n |      different length you must first clear the letter_annotations dict.\n |  \n |  seq\n |      The sequence itself, as a Seq or MutableSeq object.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __annotations__ = {'annotations': typing.Dict[str, typing.Union[str, i...\n |  \n |  __hash__ = None\n\n\n\n\nclass 개념 이해 필요\n\n\nsimple_seq_r.id = \"AC12345\"\nsimple_seq_r.description = \"Made up sequence I wish I could write a paper about\"\nprint(simple_seq_r.description)\nprint(simple_seq_r.seq)\n\nMade up sequence I wish I could write a paper about\nGATC\n\n\n\nRead fasta file\nhttps://www.ncbi.nlm.nih.gov/nuccore/MW015936.1\nZika virus isolate Zika virus/H.sapiens-tc/THA/2006/CVD_06-020, complete genome\n\n\n\n\nalt text\n\n\n\n인용구 추가\n\n\nfrom Bio import SeqIO\nrecord = SeqIO.read(\"data/MW015936.gb\", \"gb\")\n\n\nprint(record)\nhelp(record)\n\nID: MW015936.1\nName: MW015936\nDescription: Zika virus isolate Zika virus/H.sapiens-tc/THA/2006/CVD_06-020, complete genome\nNumber of features: 17\n/molecule_type=RNA\n/topology=linear\n/data_file_division=VRL\n/date=12-OCT-2020\n/accessions=['MW015936']\n/sequence_version=1\n/keywords=['']\n/source=Zika virus\n/organism=Zika virus\n/taxonomy=['Viruses', 'Riboviria', 'Orthornavirae', 'Kitrinoviricota', 'Flasuviricetes', 'Amarillovirales', 'Flaviviridae', 'Orthoflavivirus', 'Orthoflavivirus zikaense']\n/references=[Reference(title='Complete genome sequence of the Zika virus used for development of live-attenuated Zika virus strain', ...), Reference(title='Direct Submission', ...)]\n/structured_comment=defaultdict(&lt;class 'dict'&gt;, {'Assembly-Data': {'Sequencing Technology': 'Sanger dideoxy sequencing'}})\nSeq('AGTTGTTGATCTGTGTGAATCAGACTGCGACAGTTCGAGTTTGAAGCGAAAGCT...TCT')\nHelp on SeqRecord in module Bio.SeqRecord object:\n\nclass SeqRecord(builtins.object)\n |  SeqRecord(seq: Union[ForwardRef('Seq'), ForwardRef('MutableSeq'), NoneType], id: Optional[str] = '&lt;unknown id&gt;', name: str = '&lt;unknown name&gt;', description: str = '&lt;unknown description&gt;', dbxrefs: Optional[List[str]] = None, features: Optional[List[ForwardRef('SeqFeature')]] = None, annotations: Optional[Dict[str, Union[str, int]]] = None, letter_annotations: Optional[Dict[str, Sequence[Any]]] = None) -&gt; None\n |  \n |  A SeqRecord object holds a sequence and information about it.\n |  \n |  Main attributes:\n |   - id          - Identifier such as a locus tag (string)\n |   - seq         - The sequence itself (Seq object or similar)\n |  \n |  Additional attributes:\n |   - name        - Sequence name, e.g. gene name (string)\n |   - description - Additional text (string)\n |   - dbxrefs     - List of database cross references (list of strings)\n |   - features    - Any (sub)features defined (list of SeqFeature objects)\n |   - annotations - Further information about the whole sequence (dictionary).\n |     Most entries are strings, or lists of strings.\n |   - letter_annotations - Per letter/symbol annotation (restricted\n |     dictionary). This holds Python sequences (lists, strings\n |     or tuples) whose length matches that of the sequence.\n |     A typical use would be to hold a list of integers\n |     representing sequencing quality scores, or a string\n |     representing the secondary structure.\n |  \n |  You will typically use Bio.SeqIO to read in sequences from files as\n |  SeqRecord objects.  However, you may want to create your own SeqRecord\n |  objects directly (see the __init__ method for further details):\n |  \n |  &gt;&gt;&gt; from Bio.Seq import Seq\n |  &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |  &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |  ...                    id=\"YP_025292.1\", name=\"HokC\",\n |  ...                    description=\"toxic membrane protein\")\n |  &gt;&gt;&gt; print(record)\n |  ID: YP_025292.1\n |  Name: HokC\n |  Description: toxic membrane protein\n |  Number of features: 0\n |  Seq('MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF')\n |  \n |  If you want to save SeqRecord objects to a sequence file, use Bio.SeqIO\n |  for this.  For the special case where you want the SeqRecord turned into\n |  a string in a particular file format there is a format method which uses\n |  Bio.SeqIO internally:\n |  \n |  &gt;&gt;&gt; print(record.format(\"fasta\"))\n |  &gt;YP_025292.1 toxic membrane protein\n |  MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |  &lt;BLANKLINE&gt;\n |  \n |  You can also do things like slicing a SeqRecord, checking its length, etc\n |  \n |  &gt;&gt;&gt; len(record)\n |  44\n |  &gt;&gt;&gt; edited = record[:10] + record[11:]\n |  &gt;&gt;&gt; print(edited.seq)\n |  MKQHKAMIVAIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |  &gt;&gt;&gt; print(record.seq)\n |  MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |  \n |  Methods defined here:\n |  \n |  __add__(self, other: Union[ForwardRef('SeqRecord'), ForwardRef('Seq'), ForwardRef('MutableSeq'), str]) -&gt; 'SeqRecord'\n |      Add another sequence or string to this sequence.\n |      \n |      The other sequence can be a SeqRecord object, a Seq object (or\n |      similar, e.g. a MutableSeq) or a plain Python string. If you add\n |      a plain string or a Seq (like) object, the new SeqRecord will simply\n |      have this appended to the existing data. However, any per letter\n |      annotation will be lost:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      \n |      &gt;&gt;&gt; new = record + \"ACT\"\n |      &gt;&gt;&gt; print(\"%s %s\" % (new.id, new.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNNACT\n |      &gt;&gt;&gt; print(list(new.letter_annotations))\n |      []\n |      \n |      The new record will attempt to combine the annotation, but for any\n |      ambiguities (e.g. different names) it defaults to omitting that\n |      annotation.\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; with open(\"GenBank/pBAD30.gb\") as handle:\n |      ...     plasmid = SeqIO.read(handle, \"gb\")\n |      &gt;&gt;&gt; print(\"%s %i\" % (plasmid.id, len(plasmid)))\n |      pBAD30 4923\n |      \n |      Now let's cut the plasmid into two pieces, and join them back up the\n |      other way round (i.e. shift the starting point on this plasmid, have\n |      a look at the annotated features in the original file to see why this\n |      particular split point might make sense):\n |      \n |      &gt;&gt;&gt; left = plasmid[:3765]\n |      &gt;&gt;&gt; right = plasmid[3765:]\n |      &gt;&gt;&gt; new = right + left\n |      &gt;&gt;&gt; print(\"%s %i\" % (new.id, len(new)))\n |      pBAD30 4923\n |      &gt;&gt;&gt; str(new.seq) == str(right.seq + left.seq)\n |      True\n |      &gt;&gt;&gt; len(new.features) == len(left.features) + len(right.features)\n |      True\n |      \n |      When we add the left and right SeqRecord objects, their annotation\n |      is all consistent, so it is all conserved in the new SeqRecord:\n |      \n |      &gt;&gt;&gt; new.id == left.id == right.id == plasmid.id\n |      True\n |      &gt;&gt;&gt; new.name == left.name == right.name == plasmid.name\n |      True\n |      &gt;&gt;&gt; new.description == plasmid.description\n |      True\n |      &gt;&gt;&gt; new.annotations == left.annotations == right.annotations\n |      True\n |      &gt;&gt;&gt; new.letter_annotations == plasmid.letter_annotations\n |      True\n |      &gt;&gt;&gt; new.dbxrefs == left.dbxrefs == right.dbxrefs\n |      True\n |      \n |      However, we should point out that when we sliced the SeqRecord,\n |      any annotations dictionary or dbxrefs list entries were lost.\n |      You can explicitly copy them like this:\n |      \n |      &gt;&gt;&gt; new.annotations = plasmid.annotations.copy()\n |      &gt;&gt;&gt; new.dbxrefs = plasmid.dbxrefs[:]\n |  \n |  __bool__(self) -&gt; bool\n |      Boolean value of an instance of this class (True).\n |      \n |      This behaviour is for backwards compatibility, since until the\n |      __len__ method was added, a SeqRecord always evaluated as True.\n |      \n |      Note that in comparison, a Seq object will evaluate to False if it\n |      has a zero length sequence.\n |      \n |      WARNING: The SeqRecord may in future evaluate to False when its\n |      sequence is of zero length (in order to better match the Seq\n |      object behaviour)!\n |  \n |  __bytes__(self) -&gt; bytes\n |  \n |  __contains__(self, char: str) -&gt; bool\n |      Implement the 'in' keyword, searches the sequence.\n |      \n |      e.g.\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/sweetpea.nu\", \"fasta\")\n |      &gt;&gt;&gt; \"GAATTC\" in record\n |      False\n |      &gt;&gt;&gt; \"AAA\" in record\n |      True\n |      \n |      This essentially acts as a proxy for using \"in\" on the sequence:\n |      \n |      &gt;&gt;&gt; \"GAATTC\" in record.seq\n |      False\n |      &gt;&gt;&gt; \"AAA\" in record.seq\n |      True\n |      \n |      Note that you can also use Seq objects as the query,\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; Seq(\"AAA\") in record\n |      True\n |      \n |      See also the Seq object's __contains__ method.\n |  \n |  __eq__(self, other: object) -&gt; NoReturn\n |      Define the equal-to operand (not implemented).\n |  \n |  __format__(self, format_spec: str) -&gt; str\n |      Return the record as a string in the specified file format.\n |      \n |      This method supports the Python format() function and f-strings.\n |      The format_spec should be a lower case string supported by\n |      Bio.SeqIO as a text output file format. Requesting a binary file\n |      format raises a ValueError. e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |      ...                    id=\"YP_025292.1\", name=\"HokC\",\n |      ...                    description=\"toxic membrane protein\")\n |      ...\n |      &gt;&gt;&gt; format(record, \"fasta\")\n |      '&gt;YP_025292.1 toxic membrane protein\\nMKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\\n'\n |      &gt;&gt;&gt; print(f\"Here is {record.id} in FASTA format:\\n{record:fasta}\")\n |      Here is YP_025292.1 in FASTA format:\n |      &gt;YP_025292.1 toxic membrane protein\n |      MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |      &lt;BLANKLINE&gt;\n |      \n |      See also the SeqRecord's format() method.\n |  \n |  __ge__(self, other: Any) -&gt; NoReturn\n |      Define the greater-than-or-equal-to operand (not implemented).\n |  \n |  __getitem__(self, index)\n |      Return a sub-sequence or an individual letter.\n |      \n |      Slicing, e.g. my_record[5:10], returns a new SeqRecord for\n |      that sub-sequence with some annotation preserved as follows:\n |      \n |      * The name, id and description are kept as-is.\n |      * Any per-letter-annotations are sliced to match the requested\n |        sub-sequence.\n |      * Unless a stride is used, all those features which fall fully\n |        within the subsequence are included (with their locations\n |        adjusted accordingly). If you want to preserve any truncated\n |        features (e.g. GenBank/EMBL source features), you must\n |        explicitly add them to the new SeqRecord yourself.\n |      * With the exception of any molecule type, the annotations\n |        dictionary and the dbxrefs list are not used for the new\n |        SeqRecord, as in general they may not apply to the\n |        subsequence. If you want to preserve them, you must explicitly\n |        copy them to the new SeqRecord yourself.\n |      \n |      Using an integer index, e.g. my_record[5] is shorthand for\n |      extracting that letter from the sequence, my_record.seq[5].\n |      \n |      For example, consider this short protein and its secondary\n |      structure as encoded by the PDB (e.g. H for alpha helices),\n |      plus a simple feature for its histidine self phosphorylation\n |      site:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; from Bio.SeqFeature import SeqFeature, SimpleLocation\n |      &gt;&gt;&gt; rec = SeqRecord(Seq(\"MAAGVKQLADDRTLLMAGVSHDLRTPLTRIRLAT\"\n |      ...                     \"EMMSEQDGYLAESINKDIEECNAIIEQFIDYLR\"),\n |      ...                 id=\"1JOY\", name=\"EnvZ\",\n |      ...                 description=\"Homodimeric domain of EnvZ from E. coli\")\n |      &gt;&gt;&gt; rec.letter_annotations[\"secondary_structure\"] = \"  S  SSSSSSHHHHHTTTHHHHHHHHHHHHHHHHHHHHHHTHHHHHHHHHHHHHHHHHHHHHTT  \"\n |      &gt;&gt;&gt; rec.features.append(SeqFeature(SimpleLocation(20, 21),\n |      ...                     type = \"Site\"))\n |      \n |      Now let's have a quick look at the full record,\n |      \n |      &gt;&gt;&gt; print(rec)\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 1\n |      Per letter annotation for: secondary_structure\n |      Seq('MAAGVKQLADDRTLLMAGVSHDLRTPLTRIRLATEMMSEQDGYLAESINKDIEE...YLR')\n |      &gt;&gt;&gt; rec.letter_annotations[\"secondary_structure\"]\n |      '  S  SSSSSSHHHHHTTTHHHHHHHHHHHHHHHHHHHHHHTHHHHHHHHHHHHHHHHHHHHHTT  '\n |      &gt;&gt;&gt; print(rec.features[0].location)\n |      [20:21]\n |      \n |      Now let's take a sub sequence, here chosen as the first (fractured)\n |      alpha helix which includes the histidine phosphorylation site:\n |      \n |      &gt;&gt;&gt; sub = rec[11:41]\n |      &gt;&gt;&gt; print(sub)\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 1\n |      Per letter annotation for: secondary_structure\n |      Seq('RTLLMAGVSHDLRTPLTRIRLATEMMSEQD')\n |      &gt;&gt;&gt; sub.letter_annotations[\"secondary_structure\"]\n |      'HHHHHTTTHHHHHHHHHHHHHHHHHHHHHH'\n |      &gt;&gt;&gt; print(sub.features[0].location)\n |      [9:10]\n |      \n |      You can also of course omit the start or end values, for\n |      example to get the first ten letters only:\n |      \n |      &gt;&gt;&gt; print(rec[:10])\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 0\n |      Per letter annotation for: secondary_structure\n |      Seq('MAAGVKQLAD')\n |      \n |      Or for the last ten letters:\n |      \n |      &gt;&gt;&gt; print(rec[-10:])\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 0\n |      Per letter annotation for: secondary_structure\n |      Seq('IIEQFIDYLR')\n |      \n |      If you omit both, then you get a copy of the original record (although\n |      lacking the annotations and dbxrefs):\n |      \n |      &gt;&gt;&gt; print(rec[:])\n |      ID: 1JOY\n |      Name: EnvZ\n |      Description: Homodimeric domain of EnvZ from E. coli\n |      Number of features: 1\n |      Per letter annotation for: secondary_structure\n |      Seq('MAAGVKQLADDRTLLMAGVSHDLRTPLTRIRLATEMMSEQDGYLAESINKDIEE...YLR')\n |      \n |      Finally, indexing with a simple integer is shorthand for pulling out\n |      that letter from the sequence directly:\n |      \n |      &gt;&gt;&gt; rec[5]\n |      'K'\n |      &gt;&gt;&gt; rec.seq[5]\n |      'K'\n |  \n |  __gt__(self, other: Any) -&gt; NoReturn\n |      Define the greater-than operand (not implemented).\n |  \n |  __init__(self, seq: Union[ForwardRef('Seq'), ForwardRef('MutableSeq'), NoneType], id: Optional[str] = '&lt;unknown id&gt;', name: str = '&lt;unknown name&gt;', description: str = '&lt;unknown description&gt;', dbxrefs: Optional[List[str]] = None, features: Optional[List[ForwardRef('SeqFeature')]] = None, annotations: Optional[Dict[str, Union[str, int]]] = None, letter_annotations: Optional[Dict[str, Sequence[Any]]] = None) -&gt; None\n |      Create a SeqRecord.\n |      \n |      Arguments:\n |       - seq         - Sequence, required (Seq or MutableSeq)\n |       - id          - Sequence identifier, recommended (string)\n |       - name        - Sequence name, optional (string)\n |       - description - Sequence description, optional (string)\n |       - dbxrefs     - Database cross references, optional (list of strings)\n |       - features    - Any (sub)features, optional (list of SeqFeature objects)\n |       - annotations - Dictionary of annotations for the whole sequence\n |       - letter_annotations - Dictionary of per-letter-annotations, values\n |         should be strings, list or tuples of the same length as the full\n |         sequence.\n |      \n |      You will typically use Bio.SeqIO to read in sequences from files as\n |      SeqRecord objects.  However, you may want to create your own SeqRecord\n |      objects directly.\n |      \n |      Note that while an id is optional, we strongly recommend you supply a\n |      unique id string for each record.  This is especially important\n |      if you wish to write your sequences to a file.\n |      \n |      You can create a 'blank' SeqRecord object, and then populate the\n |      attributes later.\n |  \n |  __iter__(self) -&gt; Iterable[Union[ForwardRef('Seq'), ForwardRef('MutableSeq')]]\n |      Iterate over the letters in the sequence.\n |      \n |      For example, using Bio.SeqIO to read in a protein FASTA file:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/loveliesbleeding.pro\", \"fasta\")\n |      &gt;&gt;&gt; for amino in record:\n |      ...     print(amino)\n |      ...     if amino == \"L\": break\n |      X\n |      A\n |      G\n |      L\n |      &gt;&gt;&gt; print(record.seq[3])\n |      L\n |      \n |      This is just a shortcut for iterating over the sequence directly:\n |      \n |      &gt;&gt;&gt; for amino in record.seq:\n |      ...     print(amino)\n |      ...     if amino == \"L\": break\n |      X\n |      A\n |      G\n |      L\n |      &gt;&gt;&gt; print(record.seq[3])\n |      L\n |      \n |      Note that this does not facilitate iteration together with any\n |      per-letter-annotation.  However, you can achieve that using the\n |      python zip function on the record (or its sequence) and the relevant\n |      per-letter-annotation:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; rec = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (rec.id, rec.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(rec.letter_annotations))\n |      ['solexa_quality']\n |      &gt;&gt;&gt; for nuc, qual in zip(rec, rec.letter_annotations[\"solexa_quality\"]):\n |      ...     if qual &gt; 35:\n |      ...         print(\"%s %i\" % (nuc, qual))\n |      A 40\n |      C 39\n |      G 38\n |      T 37\n |      A 36\n |      \n |      You may agree that using zip(rec.seq, ...) is more explicit than using\n |      zip(rec, ...) as shown above.\n |  \n |  __le__(self, other: Any) -&gt; NoReturn\n |      Define the less-than-or-equal-to operand (not implemented).\n |  \n |  __len__(self) -&gt; int\n |      Return the length of the sequence.\n |      \n |      For example, using Bio.SeqIO to read in a FASTA nucleotide file:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/sweetpea.nu\", \"fasta\")\n |      &gt;&gt;&gt; len(record)\n |      309\n |      &gt;&gt;&gt; len(record.seq)\n |      309\n |  \n |  __lt__(self, other: Any) -&gt; NoReturn\n |      Define the less-than operand (not implemented).\n |  \n |  __ne__(self, other: object) -&gt; NoReturn\n |      Define the not-equal-to operand (not implemented).\n |  \n |  __radd__(self, other: Union[ForwardRef('Seq'), ForwardRef('MutableSeq'), str]) -&gt; 'SeqRecord'\n |      Add another sequence or string to this sequence (from the left).\n |      \n |      This method handles adding a Seq object (or similar, e.g. MutableSeq)\n |      or a plain Python string (on the left) to a SeqRecord (on the right).\n |      See the __add__ method for more details, but for example:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      \n |      &gt;&gt;&gt; new = \"ACT\" + record\n |      &gt;&gt;&gt; print(\"%s %s\" % (new.id, new.seq))\n |      slxa_0001_1_0001_01 ACTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(new.letter_annotations))\n |      []\n |  \n |  __repr__(self) -&gt; str\n |      Return a concise summary of the record for debugging (string).\n |      \n |      The python built in function repr works by calling the object's __repr__\n |      method.  e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; rec = SeqRecord(Seq(\"MASRGVNKVILVGNLGQDPEVRYMPNGGAVANITLATSESWRDKAT\"\n |      ...                     \"GEMKEQTEWHRVVLFGKLAEVASEYLRKGSQVYIEGQLRTRKWTDQ\"\n |      ...                     \"SGQDRYTTEVVVNVGGTMQMLGGRQGGGAPAGGNIGGGQPQGGWGQ\"\n |      ...                     \"PQQPQGGNQFSGGAQSRPQQSAPAAPSNEPPMDFDDDIPF\"),\n |      ...                 id=\"NP_418483.1\", name=\"b4059\",\n |      ...                 description=\"ssDNA-binding protein\",\n |      ...                 dbxrefs=[\"ASAP:13298\", \"GI:16131885\", \"GeneID:948570\"])\n |      &gt;&gt;&gt; print(repr(rec))\n |      SeqRecord(seq=Seq('MASRGVNKVILVGNLGQDPEVRYMPNGGAVANITLATSESWRDKATGEMKEQTE...IPF'), id='NP_418483.1', name='b4059', description='ssDNA-binding protein', dbxrefs=['ASAP:13298', 'GI:16131885', 'GeneID:948570'])\n |      \n |      At the python prompt you can also use this shorthand:\n |      \n |      &gt;&gt;&gt; rec\n |      SeqRecord(seq=Seq('MASRGVNKVILVGNLGQDPEVRYMPNGGAVANITLATSESWRDKATGEMKEQTE...IPF'), id='NP_418483.1', name='b4059', description='ssDNA-binding protein', dbxrefs=['ASAP:13298', 'GI:16131885', 'GeneID:948570'])\n |      \n |      Note that long sequences are shown truncated. Also note that any\n |      annotations, letter_annotations and features are not shown (as they\n |      would lead to a very long string).\n |  \n |  __str__(self) -&gt; str\n |      Return a human readable summary of the record and its annotation (string).\n |      \n |      The python built in function str works by calling the object's __str__\n |      method.  e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |      ...                    id=\"YP_025292.1\", name=\"HokC\",\n |      ...                    description=\"toxic membrane protein, small\")\n |      &gt;&gt;&gt; print(str(record))\n |      ID: YP_025292.1\n |      Name: HokC\n |      Description: toxic membrane protein, small\n |      Number of features: 0\n |      Seq('MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF')\n |      \n |      In this example you don't actually need to call str explicitly, as the\n |      print command does this automatically:\n |      \n |      &gt;&gt;&gt; print(record)\n |      ID: YP_025292.1\n |      Name: HokC\n |      Description: toxic membrane protein, small\n |      Number of features: 0\n |      Seq('MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF')\n |      \n |      Note that long sequences are shown truncated.\n |  \n |  count(self, sub, start=None, end=None)\n |      Return the number of non-overlapping occurrences of sub in seq[start:end].\n |      \n |      Optional arguments start and end are interpreted as in slice notation.\n |      This method behaves as the count method of Python strings.\n |  \n |  format(self, format: str) -&gt; str\n |      Return the record as a string in the specified file format.\n |      \n |      The format should be a lower case string supported as an output\n |      format by Bio.SeqIO, which is used to turn the SeqRecord into a\n |      string.  e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\"),\n |      ...                    id=\"YP_025292.1\", name=\"HokC\",\n |      ...                    description=\"toxic membrane protein\")\n |      &gt;&gt;&gt; record.format(\"fasta\")\n |      '&gt;YP_025292.1 toxic membrane protein\\nMKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\\n'\n |      &gt;&gt;&gt; print(record.format(\"fasta\"))\n |      &gt;YP_025292.1 toxic membrane protein\n |      MKQHKAMIVALIVICITAVVAALVTRKDLCEVHIRTGQTEVAVF\n |      &lt;BLANKLINE&gt;\n |      \n |      The Python print function automatically appends a new line, meaning\n |      in this example a blank line is shown.  If you look at the string\n |      representation you can see there is a trailing new line (shown as\n |      slash n) which is important when writing to a file or if\n |      concatenating multiple sequence strings together.\n |      \n |      Note that this method will NOT work on every possible file format\n |      supported by Bio.SeqIO (e.g. some are for multiple sequences only,\n |      and binary formats are not supported).\n |  \n |  islower(self)\n |      Return True if all ASCII characters in the record's sequence are lowercase.\n |      \n |      If there are no cased characters, the method returns False.\n |  \n |  isupper(self)\n |      Return True if all ASCII characters in the record's sequence are uppercase.\n |      \n |      If there are no cased characters, the method returns False.\n |  \n |  lower(self) -&gt; 'SeqRecord'\n |      Return a copy of the record with a lower case sequence.\n |      \n |      All the annotation is preserved unchanged. e.g.\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Fasta/aster.pro\", \"fasta\")\n |      &gt;&gt;&gt; print(record.format(\"fasta\"))\n |      &gt;gi|3298468|dbj|BAA31520.1| SAMIPF\n |      GGHVNPAVTFGAFVGGNITLLRGIVYIIAQLLGSTVACLLLKFVTNDMAVGVFSLSAGVG\n |      VTNALVFEIVMTFGLVYTVYATAIDPKKGSLGTIAPIAIGFIVGANI\n |      &lt;BLANKLINE&gt;\n |      &gt;&gt;&gt; print(record.lower().format(\"fasta\"))\n |      &gt;gi|3298468|dbj|BAA31520.1| SAMIPF\n |      gghvnpavtfgafvggnitllrgivyiiaqllgstvaclllkfvtndmavgvfslsagvg\n |      vtnalvfeivmtfglvytvyataidpkkgslgtiapiaigfivgani\n |      &lt;BLANKLINE&gt;\n |      \n |      To take a more annotation rich example,\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; old = SeqIO.read(\"EMBL/TRBG361.embl\", \"embl\")\n |      &gt;&gt;&gt; len(old.features)\n |      3\n |      &gt;&gt;&gt; new = old.lower()\n |      &gt;&gt;&gt; len(old.features) == len(new.features)\n |      True\n |      &gt;&gt;&gt; old.annotations[\"organism\"] == new.annotations[\"organism\"]\n |      True\n |      &gt;&gt;&gt; old.dbxrefs == new.dbxrefs\n |      True\n |  \n |  reverse_complement(self, id: bool = False, name: bool = False, description: bool = False, features: bool = True, annotations: bool = False, letter_annotations: bool = True, dbxrefs: bool = False) -&gt; 'SeqRecord'\n |      Return new SeqRecord with reverse complement sequence.\n |      \n |      By default the new record does NOT preserve the sequence identifier,\n |      name, description, general annotation or database cross-references -\n |      these are unlikely to apply to the reversed sequence.\n |      \n |      You can specify the returned record's id, name and description as\n |      strings, or True to keep that of the parent, or False for a default.\n |      \n |      You can specify the returned record's features with a list of\n |      SeqFeature objects, or True to keep that of the parent, or False to\n |      omit them. The default is to keep the original features (with the\n |      strand and locations adjusted).\n |      \n |      You can also specify both the returned record's annotations and\n |      letter_annotations as dictionaries, True to keep that of the parent,\n |      or False to omit them. The default is to keep the original\n |      annotations (with the letter annotations reversed).\n |      \n |      To show what happens to the pre-letter annotations, consider an\n |      example Solexa variant FASTQ file with a single entry, which we'll\n |      read in as a SeqRecord:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      &gt;&gt;&gt; print(record.letter_annotations[\"solexa_quality\"])\n |      [40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -1, -2, -3, -4, -5]\n |      \n |      Now take the reverse complement, here we explicitly give a new\n |      identifier (the old identifier with a suffix):\n |      \n |      &gt;&gt;&gt; rc_record = record.reverse_complement(id=record.id + \"_rc\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (rc_record.id, rc_record.seq))\n |      slxa_0001_1_0001_01_rc NNNNNNACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\n |      \n |      Notice that the per-letter-annotations have also been reversed,\n |      although this may not be appropriate for all cases.\n |      \n |      &gt;&gt;&gt; print(rc_record.letter_annotations[\"solexa_quality\"])\n |      [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40]\n |      \n |      Now for the features, we need a different example. Parsing a GenBank\n |      file is probably the easiest way to get an nice example with features\n |      in it...\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; with open(\"GenBank/pBAD30.gb\") as handle:\n |      ...     plasmid = SeqIO.read(handle, \"gb\")\n |      &gt;&gt;&gt; print(\"%s %i\" % (plasmid.id, len(plasmid)))\n |      pBAD30 4923\n |      &gt;&gt;&gt; plasmid.seq\n |      Seq('GCTAGCGGAGTGTATACTGGCTTACTATGTTGGCACTGATGAGGGTGTCAGTGA...ATG')\n |      &gt;&gt;&gt; len(plasmid.features)\n |      13\n |      \n |      Now, let's take the reverse complement of this whole plasmid:\n |      \n |      &gt;&gt;&gt; rc_plasmid = plasmid.reverse_complement(id=plasmid.id+\"_rc\")\n |      &gt;&gt;&gt; print(\"%s %i\" % (rc_plasmid.id, len(rc_plasmid)))\n |      pBAD30_rc 4923\n |      &gt;&gt;&gt; rc_plasmid.seq\n |      Seq('CATGGGCAAATATTATACGCAAGGCGACAAGGTGCTGATGCCGCTGGCGATTCA...AGC')\n |      &gt;&gt;&gt; len(rc_plasmid.features)\n |      13\n |      \n |      Let's compare the first CDS feature - it has gone from being the\n |      second feature (index 1) to the second last feature (index -2), its\n |      strand has changed, and the location switched round.\n |      \n |      &gt;&gt;&gt; print(plasmid.features[1])\n |      type: CDS\n |      location: [1081:1960](-)\n |      qualifiers:\n |          Key: label, Value: ['araC']\n |          Key: note, Value: ['araC regulator of the arabinose BAD promoter']\n |          Key: vntifkey, Value: ['4']\n |      &lt;BLANKLINE&gt;\n |      &gt;&gt;&gt; print(rc_plasmid.features[-2])\n |      type: CDS\n |      location: [2963:3842](+)\n |      qualifiers:\n |          Key: label, Value: ['araC']\n |          Key: note, Value: ['araC regulator of the arabinose BAD promoter']\n |          Key: vntifkey, Value: ['4']\n |      &lt;BLANKLINE&gt;\n |      \n |      You can check this new location, based on the length of the plasmid:\n |      \n |      &gt;&gt;&gt; len(plasmid) - 1081\n |      3842\n |      &gt;&gt;&gt; len(plasmid) - 1960\n |      2963\n |      \n |      Note that if the SeqFeature annotation includes any strand specific\n |      information (e.g. base changes for a SNP), this information is not\n |      amended, and would need correction after the reverse complement.\n |      \n |      Note trying to reverse complement a protein SeqRecord raises an\n |      exception:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; protein_rec = SeqRecord(Seq(\"MAIVMGR\"), id=\"Test\",\n |      ...                         annotations={\"molecule_type\": \"protein\"})\n |      &gt;&gt;&gt; protein_rec.reverse_complement()\n |      Traceback (most recent call last):\n |         ...\n |      ValueError: Proteins do not have complements!\n |      \n |      If you have RNA without any U bases, it must be annotated as RNA\n |      otherwise it will be treated as DNA by default with A mapped to T:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; rna1 = SeqRecord(Seq(\"ACG\"), id=\"Test\")\n |      &gt;&gt;&gt; rna2 = SeqRecord(Seq(\"ACG\"), id=\"Test\", annotations={\"molecule_type\": \"RNA\"})\n |      &gt;&gt;&gt; print(rna1.reverse_complement(id=\"RC\", description=\"unk\").format(\"fasta\"))\n |      &gt;RC unk\n |      CGT\n |      &lt;BLANKLINE&gt;\n |      &gt;&gt;&gt; print(rna2.reverse_complement(id=\"RC\", description=\"RNA\").format(\"fasta\"))\n |      &gt;RC RNA\n |      CGU\n |      &lt;BLANKLINE&gt;\n |      \n |      Also note you can reverse complement a SeqRecord using a MutableSeq:\n |      \n |      &gt;&gt;&gt; from Bio.Seq import MutableSeq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; rec = SeqRecord(MutableSeq(\"ACGT\"), id=\"Test\")\n |      &gt;&gt;&gt; rec.seq[0] = \"T\"\n |      &gt;&gt;&gt; print(\"%s %s\" % (rec.id, rec.seq))\n |      Test TCGT\n |      &gt;&gt;&gt; rc = rec.reverse_complement(id=True)\n |      &gt;&gt;&gt; print(\"%s %s\" % (rc.id, rc.seq))\n |      Test ACGA\n |  \n |  translate(self, table: str = 'Standard', stop_symbol: str = '*', to_stop: bool = False, cds: bool = False, gap: Optional[str] = None, id: bool = False, name: bool = False, description: bool = False, features: bool = False, annotations: bool = False, letter_annotations: bool = False, dbxrefs: bool = False) -&gt; 'SeqRecord'\n |      Return new SeqRecord with translated sequence.\n |      \n |      This calls the record's .seq.translate() method (which describes\n |      the translation related arguments, like table for the genetic code),\n |      \n |      By default the new record does NOT preserve the sequence identifier,\n |      name, description, general annotation or database cross-references -\n |      these are unlikely to apply to the translated sequence.\n |      \n |      You can specify the returned record's id, name and description as\n |      strings, or True to keep that of the parent, or False for a default.\n |      \n |      You can specify the returned record's features with a list of\n |      SeqFeature objects, or False (default) to omit them.\n |      \n |      You can also specify both the returned record's annotations and\n |      letter_annotations as dictionaries, True to keep that of the parent\n |      (annotations only), or False (default) to omit them.\n |      \n |      e.g. Loading a FASTA gene and translating it,\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; gene_record = SeqIO.read(\"Fasta/sweetpea.nu\", \"fasta\")\n |      &gt;&gt;&gt; print(gene_record.format(\"fasta\"))\n |      &gt;gi|3176602|gb|U78617.1|LOU78617 Lathyrus odoratus phytochrome A (PHYA) gene, partial cds\n |      CAGGCTGCGCGGTTTCTATTTATGAAGAACAAGGTCCGTATGATAGTTGATTGTCATGCA\n |      AAACATGTGAAGGTTCTTCAAGACGAAAAACTCCCATTTGATTTGACTCTGTGCGGTTCG\n |      ACCTTAAGAGCTCCACATAGTTGCCATTTGCAGTACATGGCTAACATGGATTCAATTGCT\n |      TCATTGGTTATGGCAGTGGTCGTCAATGACAGCGATGAAGATGGAGATAGCCGTGACGCA\n |      GTTCTACCACAAAAGAAAAAGAGACTTTGGGGTTTGGTAGTTTGTCATAACACTACTCCG\n |      AGGTTTGTT\n |      &lt;BLANKLINE&gt;\n |      \n |      And now translating the record, specifying the new ID and description:\n |      \n |      &gt;&gt;&gt; protein_record = gene_record.translate(table=11,\n |      ...                                        id=\"phya\",\n |      ...                                        description=\"translation\")\n |      &gt;&gt;&gt; print(protein_record.format(\"fasta\"))\n |      &gt;phya translation\n |      QAARFLFMKNKVRMIVDCHAKHVKVLQDEKLPFDLTLCGSTLRAPHSCHLQYMANMDSIA\n |      SLVMAVVVNDSDEDGDSRDAVLPQKKKRLWGLVVCHNTTPRFV\n |      &lt;BLANKLINE&gt;\n |  \n |  upper(self) -&gt; 'SeqRecord'\n |      Return a copy of the record with an upper case sequence.\n |      \n |      All the annotation is preserved unchanged. e.g.\n |      \n |      &gt;&gt;&gt; from Bio.Seq import Seq\n |      &gt;&gt;&gt; from Bio.SeqRecord import SeqRecord\n |      &gt;&gt;&gt; record = SeqRecord(Seq(\"acgtACGT\"), id=\"Test\",\n |      ...                    description = \"Made up for this example\")\n |      &gt;&gt;&gt; record.letter_annotations[\"phred_quality\"] = [1, 2, 3, 4, 5, 6, 7, 8]\n |      &gt;&gt;&gt; print(record.upper().format(\"fastq\"))\n |      @Test Made up for this example\n |      ACGTACGT\n |      +\n |      \"#$%&'()\n |      &lt;BLANKLINE&gt;\n |      \n |      Naturally, there is a matching lower method:\n |      \n |      &gt;&gt;&gt; print(record.lower().format(\"fastq\"))\n |      @Test Made up for this example\n |      acgtacgt\n |      +\n |      \"#$%&'()\n |      &lt;BLANKLINE&gt;\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors defined here:\n |  \n |  __dict__\n |      dictionary for instance variables\n |  \n |  __weakref__\n |      list of weak references to the object\n |  \n |  letter_annotations\n |      Dictionary of per-letter-annotation for the sequence.\n |      \n |      For example, this can hold quality scores used in FASTQ or QUAL files.\n |      Consider this example using Bio.SeqIO to read in an example Solexa\n |      variant FASTQ file as a SeqRecord:\n |      \n |      &gt;&gt;&gt; from Bio import SeqIO\n |      &gt;&gt;&gt; record = SeqIO.read(\"Quality/solexa_faked.fastq\", \"fastq-solexa\")\n |      &gt;&gt;&gt; print(\"%s %s\" % (record.id, record.seq))\n |      slxa_0001_1_0001_01 ACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTNNNNNN\n |      &gt;&gt;&gt; print(list(record.letter_annotations))\n |      ['solexa_quality']\n |      &gt;&gt;&gt; print(record.letter_annotations[\"solexa_quality\"])\n |      [40, 39, 38, 37, 36, 35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, -1, -2, -3, -4, -5]\n |      \n |      The letter_annotations get sliced automatically if you slice the\n |      parent SeqRecord, for example taking the last ten bases:\n |      \n |      &gt;&gt;&gt; sub_record = record[-10:]\n |      &gt;&gt;&gt; print(\"%s %s\" % (sub_record.id, sub_record.seq))\n |      slxa_0001_1_0001_01 ACGTNNNNNN\n |      &gt;&gt;&gt; print(sub_record.letter_annotations[\"solexa_quality\"])\n |      [4, 3, 2, 1, 0, -1, -2, -3, -4, -5]\n |      \n |      Any python sequence (i.e. list, tuple or string) can be recorded in\n |      the SeqRecord's letter_annotations dictionary as long as the length\n |      matches that of the SeqRecord's sequence.  e.g.\n |      \n |      &gt;&gt;&gt; len(sub_record.letter_annotations)\n |      1\n |      &gt;&gt;&gt; sub_record.letter_annotations[\"dummy\"] = \"abcdefghij\"\n |      &gt;&gt;&gt; len(sub_record.letter_annotations)\n |      2\n |      \n |      You can delete entries from the letter_annotations dictionary as usual:\n |      \n |      &gt;&gt;&gt; del sub_record.letter_annotations[\"solexa_quality\"]\n |      &gt;&gt;&gt; sub_record.letter_annotations\n |      {'dummy': 'abcdefghij'}\n |      \n |      You can completely clear the dictionary easily as follows:\n |      \n |      &gt;&gt;&gt; sub_record.letter_annotations = {}\n |      &gt;&gt;&gt; sub_record.letter_annotations\n |      {}\n |      \n |      Note that if replacing the record's sequence with a sequence of a\n |      different length you must first clear the letter_annotations dict.\n |  \n |  seq\n |      The sequence itself, as a Seq or MutableSeq object.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __annotations__ = {'annotations': typing.Dict[str, typing.Union[str, i...\n |  \n |  __hash__ = None\n\n\n\n\nprint(record.id)\nprint(record.name)\nprint(record.description)\nprint(record.seq)\nprint(record.features)\n\nMW015936.1\nMW015936\nZika virus isolate Zika virus/H.sapiens-tc/THA/2006/CVD_06-020, complete genome\nAGTTGTTGATCTGTGTGAATCAGACTGCGACAGTTCGAGTTTGAAGCGAAAGCTAGCAACAGTATCAACAGGTTTTATTTTGGATTTGGAAACGAGAGTTTCTGGTCATGAAAAACCCAAAGAAGAAATCCGGAGGATTCCGGATTGTCAATATGCTAAAACGCGGAGTAGCCCGTGTGAGCCCCTTTGGGGGCTTGAAGAGGCTGCCAGCCGGACTTCTGCTGGGTCATGGGCCCATCAGGATGGTCTTGGCGATTCTAGCCTTTTTGAGATTCACGGCAATCAAGCCATCACTGGGTCTCATCAATAGATGGGGTTCAGTGGGGAAAAAAGAGGCTATGGAAATAATAAAGAAGTTCAAGAAAGATCTGGCTGCCATGCTGAGAATAATCAATGCTAGGAAGGAGAAGAAGAGACGAGGCACAGATACTAGTGTCGGAATTGTTGGCCTCCTGCTGACCACAGCCATGGCAGTGGAGGTCACTAGACGTGGGAGTGCATACTATATGTACTTGGACAGAAGTGATGCTGGGGAGGCCATATCTTTTCCAACCACACTGGGGATGAATAAGTGTTATATACAGATCATGGATCTTGGACACATGTGTGATGCCACCATGAGCTATGAATGCCCTATGCTGGATGAGGGGGTAGAACCAGATGACGTCGATTGTTGGTGCAACACGACGTCAACTTGGGTTGTGTACGGAACCTGCCACCACAAAAAAGGTGAAGCACGGAGATCTAGAAGAGCTGTGACGCTCCCCTCCCATTCCACTAGGAAGCTGCAAACGCGGTCGCAGACCTGGTTGGAATCAAGAGAATACACAAAGCACTTGATTAGAGTCGAAAATTGGATATTCAGGAACCCTGGCTTCGCGTTAGCAGCAGCTGCCATCGCTTGGCTTTTGGGAAGCTCAACGAGCCAAAAAGTCATATACTTGGTCATGATACTGCTGATTGCCCCGGCATACAGCATCAGGTGCATAGGAGTCAGCAATAGGGACTTTGTGGAAGGTATGTCAGGTGGGACTTGGGTTGATGTTGTCTTGGAACATGGAGGTTGTGTTACCGTAATGGCACAGGACAAACCGACTGTCGACATAGAGCTGGTTACAACAACAGTCAGCAACATGGCGGAGGTAAGATCCTACTGCTATGAGGCATCAATATCGGACATGGCTTCGGACAGCCGCTGCCCAACACAAGGTGAAGCCTACCTTGACAAGCAATCAGACACTCAATATGTCTGCAAAAGAACGTTAGTGGACAGAGGCTGGGGAAATGGATGTGGACTTTTTGGCAAAGGGAGCCTGGTGACATGCGCTAAGTTTGCATGCTCTAAGAAAATGACCGGGAAGAGCATCCAGCCAGAGAATCTGGAGTACCGGATAATGCTGTCAGTTCATGGCTCCCAGCACAGTGGGATGATCGTTAATGACACAGGACATGAAACTGATGAGAATAGAGCGAAGGTTGAGATAACGCCCAATTCACCAAGAGCCGAAGCCACCCTGGGGGGTTTTGGAAGCCTAGGACTTGATTGTGAACCGAGGACAGGCCTTGACTTTTCAGACTTGTATTACTTGACTATGAATAACAAGCACTGGTTGGTTCACAAGGAGTGGTTCCACGACATTCCATTACCTTGGCATGCTGGGGCAGACACCGGAACTCCACACTGGAACAACAAAGAAGCACTGGTAGAGTTCAAGGACGCACATGCCAAAAGGCAAACTGCCGTGGTTCTAGGGAGTCAAGAAGGAGCAGTTCACACGGCCCTTGCTGGAGCTCTGGAGGCTGAGATGGATGGTGCAAAGGGAAGGCTGTCCTCTGGCCACTTGAAATGTCGCCTGAAAATGGATAAACTTAGATTGAAGGGCGTGTCATACTCCTTGTGTACCGCATCGTTCACATTCACTAAGATCCCGGCTGAAACACTGCACGGGACAGTCACAGTGGAGGTACAGTACGCAGGGACAGATGGACCTTGCAAGGTTCCAGCTCAGATGGCGGTGGACATGCAAACTCTGACCCCAGTTGGGAGGTTGATAACCGCTAACCCTGTAATCACTGAAAGCACTGAGAACTCTAAGATGATGCTGGAACTTGATCCACCATTTGGGGACTCTTACATTGTCATAGGAGTCGGGGAGAAGAAGATCACCCACCACTGGCACAGGAGTGGCAGCACCATTGGAAAAGCATTTGAAGCCACTGTGAGAGGTGCCAAGAGAATGGCAGTCTTGGGAGACACAGCCTGGGACTTTGGATCAGTTGGAGGTGCTCTCAACTCACTGGGCAAGGGCATCCATCAAATTTTTGGAGCAGCTTTCAAATCATTGTTTGGAGGAATGTCCTGGTTCTCACAAATTCTCATTGGAACGTTGCTGGTGTGGTTGGGTCTGAATACAAAGAATGGATCTATTTCCCTTATGTGCTTGGCCTTAGGGGGAGTGTTGATCTTCTTATCCACAGCCGTCTCTGCTGATGTGGGGTGCTCGGTGGACTTCTCAAAGAAGGAAACGAGATGCGGTACAGGGGTGTTCGTCTATAACGACGTTGAAGCCTGGAGGGACAGGTACAAGTACCATCCTGACTCCCCTCGTAGATTGGCAGCAGCAGTCAAGCAAGCCTGGGAAGATGGGATCTGTGGGATCTCCTCTGTTTCAAGAATGGAAAACATCATGTGGAGATCAGTAGAAGGGGAGCTCAACGCAATCCTGGAAGAGAATGGAGTTCAACTGACGGTCGTTGTGGGATCTGTAAAAAACCCCATGTGGAGAGGTCCACAGAGATTGCCCGTGCCTGTGAACGAGCTGCCCCACGGCTGGAAGGCTTGGGGGAAATCGTACTTCGTCAGAGCAGCAAAGACAAATAACAGCTTTGTCGTGGATGGTGACACACTGAAGGAATGCCCACTCAAACATAGAGCATGGAACAGCTTTCTTGTGGAGGATCATGGGTTCGGGGTATTTCACACTAGTGTCTGGCTCAAGGTTAGAGAAGATTATTCATTAGAGTGTGATCCAGCCGTCATTGGAACAGCCGCTAAGGGAAAGGAGGCTGTGCACAGTGATCTAGGCTACTGGATTGAGAGTGAGAAGAACGACACATGGAGGCTGAAGAGGGCCCACCTGATCGAGATAAAAACATGTGAATGGCCGAAGTCCCACACATTGTGGACAGATGGAATAGAAGAAAGTGATCTGATCATACCCAAGTCTTTAGCTGGGCCACTCAGCCATCACAACACCAGAGAGGGCTACAGGACCCAAATGAAAGGGCCATGGCACAGTGAAGAGCTTGAAATTCGGTTTGAGGAATGCCCAGGCACTAAGGTCCACGTGGAGGAAACATGTGGAACAAGAGGACCATCTCTGAGATCAACCACTGCAAGCGGAAGGGTGATCGAGGAATGGTGCTGCAGGGAGTGCACAATGCCCCCACTGTCGTTCCGGGCTAAAGATGGTTGTTGGTATGGAATGGAGATAAGGCCCAGGAAAGAACCAGAAAGTAACTTAGTAAGGTCAATGGTGACTGCAGGATCAACTGATCACATGGATCACTTCTCCCTTGGAGTGCTTGTGATTCTGCTCATGGTGCAGGAAGGGCTGAAGAAGAGAATGACCACAAAGATCATCATAAGCACATCAATGGCAGTGCTGGTAGCTATGATCCTGGGAGGATTTTCAATGAGTGACCTGGCTAAGCTTGCAATTTTGATGGGTGCCACCTTCGCGGAAATGAACACTGGAGGAGATGTAGCTCATCTGGCGCTGATAGCGGCATTCAAAGTCAGACCTGCGTTGCTGGTATCTTTCATCTTCAGAGCTAATTGGACACCCCGTGAGAGCATGCTGCTGGCCTTGGCCTCGTGTCTTCTGCAAACTGCGATCTCCGCCTTGGAAGGCGACCTGATGGTTCTCATCAATGGTTTTGCTTTGGCCTGGTTGGCAATACGAGCGATGGTTGTTCCACGCACTGACAACATCACCTTGGCAATCCTGGCTGCTCTGACACCACTGGCCCGGGGCACACTGCTTGTGGCGTGGAGAGCAGGCCTTGCTACTTGCGGGGGGTTCATGCTCCTCTCTCTGAAGGGGAGAGGCAGTGTGAAGAAGAACTTACCATTTGTCATGGCCCTGGGACTAACCGCTGTGAGGCTGGTCGACCCCATCAACGTGGTGGGACTGCTGTTGCTCACAAGGAGTGGGAAGCGGAGCTGGCCCCCTAGTGAAGTACTCACAGCTGTTGGCCTGATATGCGCATTGGCTGGAGGGTTCGCCAAGGCGGATATAGAGATGGCTGGGCCCATAGCCGCGGTCGGTCTGCTAATTGTCAGTTACGTGGTCTCAGGAAAGAGTGTGGACATGTACATTGAAAGAGCAGGTGACATCACATGGGAAAAAGATGCGGAAGTCACTGGAAACAGTCCCCGGCTCGATGTGGCACTAGATGAGAGTGGTGATTTCTCCCTAGTGGAGGATGATGGTCCCCCCATGAGAGAGATCATACTCAAAGTGGTCCTGATGGCCATCTGTGGCATGAACCCAATAGCCATACCCTTTGCAGCTGGAGCGTGGTACGTGTATGTGAAGACTGGAAAAAGGAGTGGTGCTCTATGGGATGTGCCTGCTCCCAAGGAAGTAAAAAAGGGGGAGACCACAGATGGAGTGTACAGAGTAATGACTCGCAGACTGCTAGGTTCAACACAAGTTGGAGTGGGAGTCATGCAAGAGGGGGTCTTCCACACTATGTGGCACGTCACAAAAGGATCCGCGCTGAGAAGCGGTGAAGGGAGACTTGATCCATACTGGGGAGATGTCAAGCAGGATCTGGTGTCATACTGTGGTCCATGGAAGCTAGATGCCGCCTGGGACGGGCACAGCGAGGTGCAGCTCTTGGCCGTGCCCCCCGGAGAGAGAGCGAGGAACATCCAGACTCTGCCCGGAATATTTAAGACAAAGGATGGGGACATTGGAGCAGTTGCGCTGGACTACCCAGCAGGAACTTCAGGATCTCCAATCCTAGATAAGTGTGGGAGAGTGATAGGACTCTATGGTAATGGGGTCGTGATCAAAAATGGGAGTTATGTTAGTGCCATCACCCAAGGGAGGAGGGAGGAAGAGACTCCTGTTGAGTGCTTCGAGCCTTCGATGCTGAAGAAGAAGCAGCTAACTGTCTTAGACTTGCATCCTGGAGCTGGGAAAACCAGGAGAGTTCTTCCCGAAATAGTCCGTGAAGCCATAAAAACAAGACTCCGTACTGTGATCTTAGCTCCAACCAGGGTTGTCGCTGCTGAAATGGAGGAAGCCCTTAGAGGGCTTCCAGTGCGTTATATGACAACAGCAGTCAATGTCACCCATTCTGGGACAGAAATCGTTGACTTAATGTGCCATGCCACCTTCACTTCACGTCTACTACAGCCAATCAGAGTCCCCAACTATAATCTGTATATTATGGATGAGGCCCACTTCACAGATCCCTCAAGTATAGCAGCAAGAGGATACATTTCAACAAGGGTTGAGATGGGCGAGGCGGCTGCCATCTTCATGACTGCCACGCCACCAGGAACCCGTGACGCATTCCCGGACTCCAACTCACCAATTATGGACACCGAAGTGGAAGTCCCAGAGAGAGCCTGGAGCTCAGGCTTTGATTGGGTGACGGATCATTCTGGAAAAACAGTTTGGTTTGTTCCAAGCGTGAGGAACGGCAATGAGATCGCAGCTTGTCTGACAAAGGCTGGAAAACGGGTCATACAGCTCAGCAGAAAGACTTTTGAGACAGAGTTCCAGAAAACAAAACATCAAGAGTGGGACTTCGTCGTGACAACTGACATTTCAGAGATGGGCGCCAACTTTAAAGCTGACCGTGTCATAGATTCCAGGAGATGCCTAAAGCCGGTCATACTTGATGGCGAGAGAGTCATTCTGGCTGGACCCATGCCTGTCACACATGCCAGCGCTGCCCAGAGGAGGGGGCGCATAGGCAGGAATCCCAACAAACCTGGAGATGAGTATCTGTATGGAGGTGGGTGCGCAGAGACTGATGAAGACCATGCACACTGGCTTGAAGCAAGAATGCTTCTTGACAACATTTACCTCCAAGATGGCCTCATAGCCTCGCTCTATCGACCTGAGGCCGACAAAGTAGCAGCTATTGAGGGAGAGTTCAAGCTTAGGACGGAGCAAAGGAAGACCTTTGTGGAACTCATGAAAAGAGGAGATCTTCCTGTTTGGCTGGCCTATCAGGTTGCATCTGCCGGAATAACCTACACAGATAGAAGATGGTGCTTTGATGGCACGACCAACAACACCATAATGGAAGACAGTGTGCCGGCAGAGGTGTGGACCAGATACGGAGAGAAAAGAGTGCTCAAACCGAGGTGGATGGACGCCAGAGTTTGTTCAGATCATGCGGCCCTGAAGTCATTCAAAGAGTTTGCCGCTGGGAAAAGAGGAGCGGCCTTTGGAGTGATGGAAGCCCTGGGAACACTGCCAGGACACATGACAGAGAGATTCCAGGAGGCCATTGACAACCTCGCTGTGCTCATGCGGGCAGAGACTGGAAGCAGGCCCTACAAAGCCGCGGCGGCCCAATTGCCGGAGACCCTAGAGACCATCATGCTTTTGGGGTTGCTGGGAACAGTCTCGCTGGGAATCTTTTTCGTCTTGATGCGGAACAAGGGCATAGGGAAGATGGGCTTTGGAATGGTGACTCTTGGGGCCAGCGCATGGCTTATGTGGCTCTCGGAAATTGAGCCAGCCAGAATTGCATGTGTCCTCATTGTTGTGTTCCTATTGCTGGTGGTGCTCATACCTGAGCCAGAAAAGCAAAGATCTCCCCAGGACAACCAAATGGCAATCATCATCATGGTAGCAGTGGGTCTTCTGGGCTTGATTACCGCCAATGAACTCGGATGGTTGGAGAGAACAAAGAGTGACCTAAGCCATCTAATGGGAAGGAGAGAGGAGGGGGCAACCATAGGATTCTCAATGGACATTGACCTGCGGCCAGCCTCAGCTTGGGCTATCTATGCTGCTCTGACAACTTTCATTACCCCAGCCGTCCAACATGCAGTGACCACTTCATACAACAACTACTCCTTAATGGCGATGGCCACGCAAGCTGGAGTGTTGTTTGGTATGGGTAAAGGGATGCCATTCTACGCATGGGACTTTGGAGTCCCGCTGCTAATGATAGGTTGCTACTCACAATTAACACCCCTGACCCTAATAGTGGCCATCATTTTGCTCGTGGCGCACTACATGTACTTGATCCCAGGGCTGCAGGCAGCAGCTGCGCGTGCTGCTCAGAAGAGAACGGCAGCTGGCATCATGAAGAACCCTGTTGTGGATGGAATAGTGGTGACTGACATTGACACAATGACAATTGACCCCCAAGTGGAGAAAAAGATGGGACAGGTGCTACTCATAGCAGTAGCCGTCTCCAGCGCCATACTGTCGCGGACCGCCTGGGGGTGGGGGGAGGCTGGGGCCCTGATCACAGCTGCAACTTCCACTTTGTGGGAAGGCTCTCCGAACAAGTACTGGAACTCCTCCACAGCCACTTCACTGTGTAACATTTTTAGGGGAAGTTACTTGGCTGGAGCTTCTCTAATCTACACAGTAACAAGAAACGCTGGCTTGGTCAAGAGACGTGGGGGTGGAACGGGAGAGACCCTGGGAGAGAAGTGGAAGGCCCGCCTGAACCAGATGTCGGCCCTGGAGTTCTACTCCTACAAAAAGTCAGGCATCACCGAGGTGTGCAGAGAAGAGGCCCGCCGCGCCCTCAAGGACGGTGTGGCAACGGGAGGCCATGCTGTGTCCCGAGGAAGTGCAAAGCTGAGATGGTTGGTGGAGAGGGGATACCTGCAGCCCTATGGAAAGGTCATTGATCTTGGATGTGGCAGAGGGGGCTGGAGTTACTACGCCGCCACCATCCGCAAAGTTCAAGAAGTGAAAGGATACACAAAAGGAGGCCCTGGTCATGAGGAACCCATGTTGGTGCAAAGCTATGGGTGGAACATAGTCCGTCTTAAGAGTGGGGTGGACGTCTTTCATATGGCGGCTGAGCCGTGTGACACGTTGCTGTGTGATATAGGTGAGTCATCATCTAGTCCTGAAGTGGAAGAAGCACGGACGCTCAGAGTCCTCTCCATGGTGGGGGATTGGCTTGAAAAAAGACCAGGAGCCTTTTGTATAAAAGTGTTGTGCCCATACACCAGCACTATGATGGAAACCCTGGAGCGACTGCAGCGTAGGTATGGGGGAGGACTGGTCAGAGTGCCACTCTCCCGCAACTCTACACATGAGATGTACTGGGTCTCTGGAGCGAAAAGCAACACCATAAAAAGTGTGTCCACCACGAGCCAGCTCCTCTTGGGGCGCATGGACGGGCCCAGGAGGCCAGTGAAATATGAGGAGGATGTGAATCTCGGCTCTGGCACGCGGGCTGTGGTAAGCTGCGCTGAAGCTCCCAACATGAAGATCATTGGTAACCGCATTGAGAGGATCCGCAGTGAGCACGCGGAAACGTGGTTCTTTGACGAGAACCACCCATATAGGACATGGGCTTACCATGGAAGCTACGAGGCCCCCACACAAGGGTCAGCGTCCTCTCTAATAAACGGGGTTGTCAGGCTCCTGTCAAAACCCTGGGATGTGGTGACTGGAGTCACAGGAATAGCCATGACCGACACCACACCGTATGGTCAGCAAAGAGTTTTCAAGGAAAAAGTGGACACTAGGGTGCCAGACCCCCAAGAAGGCACTCGTCAGGTTATGAGCATGGTCTCTTCCTGGTTGTGGAAAGAGCTAGGCAAACACAAACGGCCACGAGTCTGTACCAAAGAAGAGTTCATCAACAAGGTTCGTAGCAATGCAGCATTAGGGGCAATATTTGAAGAGGAAAAAGAGTGGAAGACTGCAGTGGAAGCTGTGAACGATCCAAGGTTCTGGGCTCTAGTGGACAAGGAAAGAGAGCACCACCTGAGAGGAGAGTGCCAGAGCTGTGTGTACAACATGATGGGAAAAAGAGAAAAGAAACAAGGGGAATTTGGAAAGGCCAAGGGCAGCCGCGCCATCTGGTACATGTGGCTAGGGGCTAGATTTCTAGAGTTCGAAGCCCTTGGATTCTTGAACGAGGATCACTGGATGGGGAGAGAGAATTCACGAGGTGGTGTTGAAGGGCTGGGATTACAAAGACTCGGATATGTCTTAGAAGAGATGAGTCGCATACCAGGAGGAAGGATGTATGCAGATGACACTGCTGGCTGGGACACCCGCATCAGCAGGTTTGATCTGGAGAATGAAGCTCTAATCACCAACCAAATGGAGAAAGGGCACAGGGCCTTGGCATTGGCCATAATCAAGTACACATACCAAAACAAAGTGGTAAAGGTCCTTAGACCAGCTGAAAAAGGGAAGACAGTTATGGACATTATTTCAAGACAAGACCAAAGGGGGAGCGGACAAGTTGTCACTTACGCTCTTAATACATTTACCAACCTAGTGGTGCAGCTCATTCGGAATATGGAGGCTGAGGAAGTTCTAGAGATGCAAGACTTGTGGCTGCTGCGGAGGTCAGAGAAAGTGACCAACTGGTTGCAGAGCAATGGATGGGATAGGCTCAAACGAATGGCAGTCAGTGGAGATGATTGCGTTGTGAAACCAATTGATGATAGGTTTGCACATGCTCTCAGGTTCTTGAATGATATGGGAAAAGTTAGGAAGGACACACAAGAGTGGAAACCCTCAACTGGATGGGACAACTGGGAAGAAGTTCCGTTTTGCTCCCACCACTTCAATAAGCTCCATCTCAAGGACGGGAGGTCCATTGTGGTTCCCTGCCGCCACCAAGATGAACTGATTGGCCGAGCCCGCGTCTCACCAGGGGCGGGATGGAGCATCCGGGAGACTGCTTGCCTAGCAAAATCATATGCGCAAATGTGGCAGCTCCTTTATTTCCACAGAAGGGACCTCCGACTGATGGCCAATGCCATTTGTTCATCTGTGCCAGTTGACTGGGTTCCAACTGGGAGAACTACCTGGTCAATCCATGGAAAGGGAGAATGGATGACCACTGAAGACATGCTTGTGGTGTGGAACAGAGTGTGGATTGAGGAGAACGACCACATGGAAGACAAGACCCCAGTTACGAAATGGACAGACATTCCCTATTTGGGAAAAAGGGAAGACTTGTGGTGTGGGTCTCTCATAGGGCACAGACCGCGCACCACCTGGGCTGAGAACATTAAAAACACAGTCAACATGATGCGCAGGATCATAGGTGATGAAGAAAAGTACATGGACTACCTATCCACCCAAGTTCGCTACTTGGGTGAAGAAGGGTCCACACCTGGAGTGCTATAAGCACCAGTCTTAGTGTTGTCAGGCCTGCTAGTCAGCCACAGCTTGGGGAAAGCTGTGCAGCCTGTGACCCCCCCAGGAGAAGCTGGGAAACCAAGCCCATAGTCAGGCCGAGAACGCCATGGCACGGAAGAAGCCATGCTGCCTGTGAGCCCCTCAGAGGACACTGAGTCAAAAAACCCCACGCGCTTGGAGGCGCAGGATGGGAAAAGAAGGTGGCGACCTTCCCCACCCTTCAATCTGGGGCCTGAACTGGAGATCAGCTGTGGATCTCCAGAAGAGGGACTAGTGGTTAGAGGAGACCCCCCGGAAAACGCAAAACAGCATATTGACGCTGGGAAAGACCAGAGACTCCATGAGTTTCCACCACGCTGGCCGCCAGGCACAGATCGCCGAATAGCGGCGGCCGGTGTGGGGAAATCCATGGGTCT\n[SeqFeature(SimpleLocation(ExactPosition(0), ExactPosition(10807), strand=1), type='source', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(10379), strand=1), type='gene', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(10379), strand=1), type='CDS', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(473), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(419), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(473), ExactPosition(977), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(473), ExactPosition(752), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(752), ExactPosition(977), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(977), ExactPosition(2489), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(2489), ExactPosition(3545), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(3545), ExactPosition(4223), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(4223), ExactPosition(4613), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(4613), ExactPosition(6464), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(6464), ExactPosition(6845), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(6845), ExactPosition(6914), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(6914), ExactPosition(7667), strand=1), type='mat_peptide', qualifiers=...), SeqFeature(SimpleLocation(ExactPosition(7667), ExactPosition(10376), strand=1), type='mat_peptide', qualifiers=...)]\n\n\n\nprint(len(record.seq))\nlist(record.features)\n\n10807\n\n\n[SeqFeature(SimpleLocation(ExactPosition(0), ExactPosition(10807), strand=1), type='source', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(10379), strand=1), type='gene', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(10379), strand=1), type='CDS', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(473), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(107), ExactPosition(419), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(473), ExactPosition(977), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(473), ExactPosition(752), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(752), ExactPosition(977), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(977), ExactPosition(2489), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(2489), ExactPosition(3545), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(3545), ExactPosition(4223), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(4223), ExactPosition(4613), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(4613), ExactPosition(6464), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(6464), ExactPosition(6845), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(6845), ExactPosition(6914), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(6914), ExactPosition(7667), strand=1), type='mat_peptide', qualifiers=...),\n SeqFeature(SimpleLocation(ExactPosition(7667), ExactPosition(10376), strand=1), type='mat_peptide', qualifiers=...)]\n\n\n\n\n\nalt text\n\n\n\nSlicing\n\n\nprint(record.features[0])\nprint(record.features[1])\nprint(record.features[2])\n\ntype: source\nlocation: [0:10807](+)\nqualifiers:\n    Key: collection_date, Value: ['11-Aug-2006']\n    Key: country, Value: ['Thailand']\n    Key: db_xref, Value: ['taxon:64320']\n    Key: host, Value: ['Homo sapiens']\n    Key: isolate, Value: ['Zika virus/H.sapiens-tc/THA/2006/CVD_06-020']\n    Key: isolation_source, Value: ['serum']\n    Key: mol_type, Value: ['genomic RNA']\n    Key: note, Value: ['Passage history:Toxorhynchites splendens mosquito (1 passage); Vero, African green monkey kidney cell (2 passages); Aedes albopictus C6/36 cell (1 passage); genotype: Asian']\n    Key: organism, Value: ['Zika virus']\n\ntype: gene\nlocation: [107:10379](+)\nqualifiers:\n    Key: gene, Value: ['POLY']\n\ntype: CDS\nlocation: [107:10379](+)\nqualifiers:\n    Key: codon_start, Value: ['1']\n    Key: gene, Value: ['POLY']\n    Key: product, Value: ['polyprotein']\n    Key: protein_id, Value: ['QOF88708.1']\n    Key: translation, Value: ['MKNPKKKSGGFRIVNMLKRGVARVSPFGGLKRLPAGLLLGHGPIRMVLAILAFLRFTAIKPSLGLINRWGSVGKKEAMEIIKKFKKDLAAMLRIINARKEKKRRGTDTSVGIVGLLLTTAMAVEVTRRGSAYYMYLDRSDAGEAISFPTTLGMNKCYIQIMDLGHMCDATMSYECPMLDEGVEPDDVDCWCNTTSTWVVYGTCHHKKGEARRSRRAVTLPSHSTRKLQTRSQTWLESREYTKHLIRVENWIFRNPGFALAAAAIAWLLGSSTSQKVIYLVMILLIAPAYSIRCIGVSNRDFVEGMSGGTWVDVVLEHGGCVTVMAQDKPTVDIELVTTTVSNMAEVRSYCYEASISDMASDSRCPTQGEAYLDKQSDTQYVCKRTLVDRGWGNGCGLFGKGSLVTCAKFACSKKMTGKSIQPENLEYRIMLSVHGSQHSGMIVNDTGHETDENRAKVEITPNSPRAEATLGGFGSLGLDCEPRTGLDFSDLYYLTMNNKHWLVHKEWFHDIPLPWHAGADTGTPHWNNKEALVEFKDAHAKRQTAVVLGSQEGAVHTALAGALEAEMDGAKGRLSSGHLKCRLKMDKLRLKGVSYSLCTASFTFTKIPAETLHGTVTVEVQYAGTDGPCKVPAQMAVDMQTLTPVGRLITANPVITESTENSKMMLELDPPFGDSYIVIGVGEKKITHHWHRSGSTIGKAFEATVRGAKRMAVLGDTAWDFGSVGGALNSLGKGIHQIFGAAFKSLFGGMSWFSQILIGTLLVWLGLNTKNGSISLMCLALGGVLIFLSTAVSADVGCSVDFSKKETRCGTGVFVYNDVEAWRDRYKYHPDSPRRLAAAVKQAWEDGICGISSVSRMENIMWRSVEGELNAILEENGVQLTVVVGSVKNPMWRGPQRLPVPVNELPHGWKAWGKSYFVRAAKTNNSFVVDGDTLKECPLKHRAWNSFLVEDHGFGVFHTSVWLKVREDYSLECDPAVIGTAAKGKEAVHSDLGYWIESEKNDTWRLKRAHLIEIKTCEWPKSHTLWTDGIEESDLIIPKSLAGPLSHHNTREGYRTQMKGPWHSEELEIRFEECPGTKVHVEETCGTRGPSLRSTTASGRVIEEWCCRECTMPPLSFRAKDGCWYGMEIRPRKEPESNLVRSMVTAGSTDHMDHFSLGVLVILLMVQEGLKKRMTTKIIISTSMAVLVAMILGGFSMSDLAKLAILMGATFAEMNTGGDVAHLALIAAFKVRPALLVSFIFRANWTPRESMLLALASCLLQTAISALEGDLMVLINGFALAWLAIRAMVVPRTDNITLAILAALTPLARGTLLVAWRAGLATCGGFMLLSLKGRGSVKKNLPFVMALGLTAVRLVDPINVVGLLLLTRSGKRSWPPSEVLTAVGLICALAGGFAKADIEMAGPIAAVGLLIVSYVVSGKSVDMYIERAGDITWEKDAEVTGNSPRLDVALDESGDFSLVEDDGPPMREIILKVVLMAICGMNPIAIPFAAGAWYVYVKTGKRSGALWDVPAPKEVKKGETTDGVYRVMTRRLLGSTQVGVGVMQEGVFHTMWHVTKGSALRSGEGRLDPYWGDVKQDLVSYCGPWKLDAAWDGHSEVQLLAVPPGERARNIQTLPGIFKTKDGDIGAVALDYPAGTSGSPILDKCGRVIGLYGNGVVIKNGSYVSAITQGRREEETPVECFEPSMLKKKQLTVLDLHPGAGKTRRVLPEIVREAIKTRLRTVILAPTRVVAAEMEEALRGLPVRYMTTAVNVTHSGTEIVDLMCHATFTSRLLQPIRVPNYNLYIMDEAHFTDPSSIAARGYISTRVEMGEAAAIFMTATPPGTRDAFPDSNSPIMDTEVEVPERAWSSGFDWVTDHSGKTVWFVPSVRNGNEIAACLTKAGKRVIQLSRKTFETEFQKTKHQEWDFVVTTDISEMGANFKADRVIDSRRCLKPVILDGERVILAGPMPVTHASAAQRRGRIGRNPNKPGDEYLYGGGCAETDEDHAHWLEARMLLDNIYLQDGLIASLYRPEADKVAAIEGEFKLRTEQRKTFVELMKRGDLPVWLAYQVASAGITYTDRRWCFDGTTNNTIMEDSVPAEVWTRYGEKRVLKPRWMDARVCSDHAALKSFKEFAAGKRGAAFGVMEALGTLPGHMTERFQEAIDNLAVLMRAETGSRPYKAAAAQLPETLETIMLLGLLGTVSLGIFFVLMRNKGIGKMGFGMVTLGASAWLMWLSEIEPARIACVLIVVFLLLVVLIPEPEKQRSPQDNQMAIIIMVAVGLLGLITANELGWLERTKSDLSHLMGRREEGATIGFSMDIDLRPASAWAIYAALTTFITPAVQHAVTTSYNNYSLMAMATQAGVLFGMGKGMPFYAWDFGVPLLMIGCYSQLTPLTLIVAIILLVAHYMYLIPGLQAAAARAAQKRTAAGIMKNPVVDGIVVTDIDTMTIDPQVEKKMGQVLLIAVAVSSAILSRTAWGWGEAGALITAATSTLWEGSPNKYWNSSTATSLCNIFRGSYLAGASLIYTVTRNAGLVKRRGGGTGETLGEKWKARLNQMSALEFYSYKKSGITEVCREEARRALKDGVATGGHAVSRGSAKLRWLVERGYLQPYGKVIDLGCGRGGWSYYAATIRKVQEVKGYTKGGPGHEEPMLVQSYGWNIVRLKSGVDVFHMAAEPCDTLLCDIGESSSSPEVEEARTLRVLSMVGDWLEKRPGAFCIKVLCPYTSTMMETLERLQRRYGGGLVRVPLSRNSTHEMYWVSGAKSNTIKSVSTTSQLLLGRMDGPRRPVKYEEDVNLGSGTRAVVSCAEAPNMKIIGNRIERIRSEHAETWFFDENHPYRTWAYHGSYEAPTQGSASSLINGVVRLLSKPWDVVTGVTGIAMTDTTPYGQQRVFKEKVDTRVPDPQEGTRQVMSMVSSWLWKELGKHKRPRVCTKEEFINKVRSNAALGAIFEEEKEWKTAVEAVNDPRFWALVDKEREHHLRGECQSCVYNMMGKREKKQGEFGKAKGSRAIWYMWLGARFLEFEALGFLNEDHWMGRENSRGGVEGLGLQRLGYVLEEMSRIPGGRMYADDTAGWDTRISRFDLENEALITNQMEKGHRALALAIIKYTYQNKVVKVLRPAEKGKTVMDIISRQDQRGSGQVVTYALNTFTNLVVQLIRNMEAEEVLEMQDLWLLRRSEKVTNWLQSNGWDRLKRMAVSGDDCVVKPIDDRFAHALRFLNDMGKVRKDTQEWKPSTGWDNWEEVPFCSHHFNKLHLKDGRSIVVPCRHQDELIGRARVSPGAGWSIRETACLAKSYAQMWQLLYFHRRDLRLMANAICSSVPVDWVPTGRTTWSIHGKGEWMTTEDMLVVWNRVWIEENDHMEDKTPVTKWTDIPYLGKREDLWCGSLIGHRPRTTWAENIKNTVNMMRRIIGDEEKYMDYLSTQVRYLGEEGSTPGVL']\n\n\n\n\nextract sequence\n\n\nrecord.features[2].extract(record.seq)\n\nSeq('ATGAAAAACCCAAAGAAGAAATCCGGAGGATTCCGGATTGTCAATATGCTAAAA...TAA')\n\n\n\n위치 탐색 in 활용\n\n\nfor feature in record.features:\n    if 4350 in feature:\n        print(f\"type: {feature.type} start: {feature.location.start} end: {feature.location.end}\")\n\ntype: source start: 0 end: 10807\ntype: gene start: 107 end: 10379\ntype: CDS start: 107 end: 10379\ntype: mat_peptide start: 4223 end: 4613\n\n\n\n서열 위치로 직접 슬라이싱\n\n\nsub_record = record[3000:5000]\nprint(sub_record)\nprint(len(sub_record))\nprint(len(sub_record.features))\nprint(sub_record.features[0])\nprint(sub_record.features[1])\n\nID: MW015936.1\nName: MW015936\nDescription: Zika virus isolate Zika virus/H.sapiens-tc/THA/2006/CVD_06-020, complete genome\nNumber of features: 2\n/molecule_type=RNA\nSeq('TTAGAGAAGATTATTCATTAGAGTGTGATCCAGCCGTCATTGGAACAGCCGCTA...GAC')\n2000\n2\ntype: mat_peptide\nlocation: [545:1223](+)\nqualifiers:\n    Key: gene, Value: ['POLY']\n    Key: product, Value: ['nonstructural protein NS2A']\n\ntype: mat_peptide\nlocation: [1223:1613](+)\nqualifiers:\n    Key: gene, Value: ['POLY']\n    Key: product, Value: ['nonstructural protein NS2B']\n\n\n\n\n5.3.3.1 Example - find features and plot\n[User]\n I have a genbank file. I want extract all the features of “mat_peptide” type in the file and calculate their length. can you show me a python code? \n[ChatGPT]\nCertainly! You can use Biopython to read a GenBank file and extract features of a specific type, such as “mat_peptide”. Here’s how you can do it:\nPython Script\nHere is the Python script that extracts all “mat_peptide” features from a GenBank file and calculates their lengths:\nfrom Bio import SeqIO\n\n# Function to extract mat_peptide features and calculate their lengths\ndef extract_mat_peptide_features(file_path):\n    record = SeqIO.read(file_path, \"genbank\")\n    mat_peptides = []\n\n    for feature in record.features:\n        if feature.type == \"mat_peptide\":\n            start = feature.location.start.position\n            end = feature.location.end.position\n            length = end - start\n            mat_peptides.append({\n                \"ID\": feature.qualifiers.get(\"product\", [\"Unknown\"])[0],\n                \"Start\": start,\n                \"End\": end,\n                \"Length\": length\n            })\n    \n    return mat_peptides\n\n# Example usage\ngenbank_file = 'example.gb'  # Replace with your GenBank file path\nmat_peptide_features = extract_mat_peptide_features(genbank_file)\n\n# Print the results\nfor peptide in mat_peptide_features:\n    print(f\"ID: {peptide['ID']}, Start: {peptide['Start']}, End: {peptide['End']}, Length: {peptide['Length']} bp\")\nExplanation\n\nImport Libraries: Import the necessary modules from Biopython.\nextract_mat_peptide_features Function: This function reads the GenBank file, extracts features of type “mat_peptide”, calculates their start and end positions, and determines their lengths.\nExample Usage: Replace 'example.gb' with the path to your GenBank file. The script will read the file, extract the “mat_peptide” features, and print their IDs, start and end positions, and lengths.\n\nRunning the Script\n\nSave the script to a file, for example, extract_mat_peptides.py.\nEnsure you have the GenBank file (e.g., example.gb) in the same directory.\nRun the script from the command line:\npython extract_mat_peptides.py\n\nThis script will read the GenBank file, extract all “mat_peptide” features, calculate their lengths, and print the details. If you have any specific questions or need further assistance, feel free to ask!\n\nFind a specific feature\n\n\nfrom Bio import SeqIO\n\nrecords = SeqIO.parse(\"data/MW015936.gb\", \"genbank\")\nfor feature in record.features:\n    if feature.type == \"mat_peptide\":\n        print(feature.qualifiers[\"product\"])\n        print(feature.location.start, feature.location.end)\n\n['anchored capsid protein C']\n107 473\n['capsid protein C']\n107 419\n['membrane glycoprotein precursor M']\n473 977\n['protein pr']\n473 752\n['membrane glycoprotein M']\n752 977\n['envelope protein E']\n977 2489\n['nonstructural protein NS1']\n2489 3545\n['nonstructural protein NS2A']\n3545 4223\n['nonstructural protein NS2B']\n4223 4613\n['nonstructural protein NS3']\n4613 6464\n['nonstructural protein NS4A']\n6464 6845\n['protein 2K']\n6845 6914\n['nonstructural protein NS4B']\n6914 7667\n['RNA-dependent RNA polymerase NS5']\n7667 10376\n\n\n\nget length and plot\n\n\nfrom Bio import SeqIO\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nmat_peptides = []\nrecords = SeqIO.parse(\"data/MW015936.gb\", \"genbank\")\nfor feature in record.features:\n    if feature.type == \"mat_peptide\":\n        mat_peptides.append({\n            \"id\": feature.qualifiers[\"product\"],\n            \"start\": feature.location.start,\n            \"end\": feature.location.end,\n            \"length\": feature.location.end - feature.location.start\n        })\n\ndf = pd.DataFrame(mat_peptides)\n\nplt.figure(figsize = (10, 6))\n# df[\"length\"].hist()\nsns.histplot(df[\"length\"])\nplt.xticks(rotation = 90)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n5.3.4 Entrez\n\nProvides code to access NCBI over the WWW\n파일 읽기/쓰기 with 문 사용\n\n\nfrom Bio import Entrez\nEntrez.email = \"kimhaseong@gmail.com\"\n\n# Searching NCBI Nucleotide database\nhandle = Entrez.esearch(db=\"nucleotide\", term=\"Homo sapiens[Organism] AND BRCA1[Gene]\", retmax=5)\nrecord = Entrez.read(handle)\nprint(record[\"IdList\"])\n\n['262359905', '2703623457', '2703623455', '2703623453', '2703623451']\n\n\n\nfrom Bio import Entrez\nfrom Bio import SeqIO\nentid = record[\"IdList\"][0]\n\nwith Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=entid) as handle:\n    seq_record = SeqIO.read(handle, \"gb\")\nprint(f\"{seq_record.id} with {len(seq_record.features)} features\")\nprint(type(seq_record))\nSeqIO.write(seq_record, \"/content/drive/My Drive/2024-cnu-lecture/data/\"+seq_record.id+\".fa\", \"fasta\")\n#SeqIO.write(seq_record, seq_record.id+\".fa\", \"fasta\")\nprint(seq_record)\n\nNG_005905.2 with 130 features\n&lt;class 'Bio.SeqRecord.SeqRecord'&gt;\nID: NG_005905.2\nName: NG_005905\nDescription: Homo sapiens BRCA1 DNA repair associated (BRCA1), RefSeqGene (LRG_292) on chromosome 17\nNumber of features: 130\n/molecule_type=DNA\n/topology=linear\n/data_file_division=PRI\n/date=09-JUN-2024\n/accessions=['NG_005905']\n/sequence_version=2\n/keywords=['RefSeq', 'RefSeqGene']\n/source=Homo sapiens (human)\n/organism=Homo sapiens\n/taxonomy=['Eukaryota', 'Metazoa', 'Chordata', 'Craniata', 'Vertebrata', 'Euteleostomi', 'Mammalia', 'Eutheria', 'Euarchontoglires', 'Primates', 'Haplorrhini', 'Catarrhini', 'Hominidae', 'Homo']\n/references=[Reference(title='Emerging roles of BRCA1 alternative splicing', ...), Reference(title='Expression profiles of BRCA1 splice variants in asynchronous and in G1/S synchronized tumor cell lines', ...), Reference(title='BRCA1: a review of structure and putative functions', ...), Reference(title='Mutations and alternative splicing of the BRCA1 gene in UK breast/ovarian cancer families', ...), Reference(title='Differential subcellular localization, expression and biological toxicity of BRCA1 and the splice variant BRCA1-delta11b', ...), Reference(title='Localization of BRCA1 and a splice variant identifies the nuclear localization signal', ...), Reference(title='Characterization of functional messenger RNA splice variants of BRCA1 expressed in nonmalignant and tumor-derived breast cells', ...), Reference(title='Growth retardation and tumour inhibition by BRCA1', ...), Reference(title='Distinct transcription start sites generate two forms of BRCA1 mRNA', ...), Reference(title='A strong candidate for the breast and ovarian cancer susceptibility gene BRCA1', ...), Reference(title='Fanconi Anemia', ...), Reference(title='BRCA1- and BRCA2-Associated Hereditary Breast and Ovarian Cancer', ...)]\n/comment=REVIEWED REFSEQ: This record has been curated by NCBI staff in\ncollaboration with Andrew Devereau, Nazneen Rahman. The reference\nsequence was derived from AC109326.11, AC060780.18 and AC135721.4.\nThis sequence is a reference standard in the RefSeqGene project.\nOn Nov 4, 2009 this sequence version replaced NG_005905.1.\nSummary: This gene encodes a 190 kD nuclear phosphoprotein that\nplays a role in maintaining genomic stability, and it also acts as\na tumor suppressor. The BRCA1 gene contains 22 exons spanning about\n110 kb of DNA. The encoded protein combines with other tumor\nsuppressors, DNA damage sensors, and signal transducers to form a\nlarge multi-subunit protein complex known as the BRCA1-associated\ngenome surveillance complex (BASC). This gene product associates\nwith RNA polymerase II, and through the C-terminal domain, also\ninteracts with histone deacetylase complexes. This protein thus\nplays a role in transcription, DNA repair of double-stranded\nbreaks, and recombination. Mutations in this gene are responsible\nfor approximately 40% of inherited breast cancers and more than 80%\nof inherited breast and ovarian cancers. Alternative splicing plays\na role in modulating the subcellular localization and physiological\nfunction of this gene. Many alternatively spliced transcript\nvariants, some of which are disease-associated mutations, have been\ndescribed for this gene, but the full-length natures of only some\nof these variants has been described. A related pseudogene, which\nis also located on chromosome 17, has been identified. [provided by\nRefSeq, May 2020].\nSeq('TGTGTGTATGAAGTTAACTTCAAAGCAAGCTTCCTGTGCTGAGGGGGTGGGAGG...GGC')\n\n\n\n여러개 record에 대해서는 parse 함수를 사용\n\n\nfrom Bio import SeqIO\n\nentids = record[\"IdList\"]\n\nwith Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=entids) as handle:\n    for seq_record in SeqIO.parse(handle, \"gb\"):\n        print(f\"{seq_record.id} {seq_record.description[:50]}\")\n        print(f\"Sequence length {len(seq_record)}, {len(seq_record.features)} \\\n              features, from {seq_record.annotations['source']}\")\n        print(\"\\n\")\n        SeqIO.write(seq_record, \"/content/drive/My Drive/2024-cnu-lecture/data/\"+seq_record.id+\".gb\", \"gb\")\n\nNG_005905.2 Homo sapiens BRCA1 DNA repair associated (BRCA1), \nSequence length 193689, 130               features, from Homo sapiens (human)\n\n\nPP465840.1 Homo sapiens isolate TWH-3503-0-1 breast and ovari\nSequence length 5592, 3               features, from Homo sapiens (human)\n\n\nPP465839.1 Homo sapiens isolate TWH-3747-0-1 truncated breast\nSequence length 891, 3               features, from Homo sapiens (human)\n\n\nPP465838.1 Homo sapiens isolate TWH-3713-0-1 truncated breast\nSequence length 3462, 3               features, from Homo sapiens (human)\n\n\nPP465837.1 Homo sapiens isolate OV-0673-0-1 truncated breast \nSequence length 4167, 3               features, from Homo sapiens (human)\n\n\n\n\n\n\n5.3.5 Pairwise sequence alignment\n\nfrom Bio import Align\n\naligner = Align.PairwiseAligner()\naligner.mode = \"global\"\naligner.mismatch_score = -10\nalignments = aligner.align(\"AAACAAA\", \"ACGAAAGAAA\")\nprint(aligner)\nprint(len(alignments))\nprint(alignments.score)\n\nprint(alignments[0])\nprint(alignments[1])\nprint(alignments[2])\n\nPairwise sequence aligner with parameters\n  wildcard: None\n  match_score: 1.000000\n  mismatch_score: -10.000000\n  target_internal_open_gap_score: 0.000000\n  target_internal_extend_gap_score: 0.000000\n  target_left_open_gap_score: 0.000000\n  target_left_extend_gap_score: 0.000000\n  target_right_open_gap_score: 0.000000\n  target_right_extend_gap_score: 0.000000\n  query_internal_open_gap_score: 0.000000\n  query_internal_extend_gap_score: 0.000000\n  query_left_open_gap_score: 0.000000\n  query_left_extend_gap_score: 0.000000\n  query_right_open_gap_score: 0.000000\n  query_right_extend_gap_score: 0.000000\n  mode: global\n\n12\n6.0\ntarget            0 A--AACA-AA-  7\n                  0 |--||-|-||- 11\nquery             0 ACGAA-AGAAA 10\n\ntarget            0 A--AACA-A-A  7\n                  0 |--||-|-|-| 11\nquery             0 ACGAA-AGAAA 10\n\ntarget            0 A--AACA--AA  7\n                  0 |--||-|--|| 11\nquery             0 ACGAA-AGAAA 10\n\n\n\n\naligner = Align.PairwiseAligner(mismatch_score=-10, mode=\"local\")\nalignments = aligner.align(\"AAACAAA\", \"ACGAAAGAAA\")\nprint(len(alignments))\nprint(alignments.score)\n\nprint(alignments[0])\nprint(alignments[1])\nprint(alignments[2])\n\n12\n6.0\ntarget            0 A--AACA-AA  7\n                  0 |--||-|-|| 10\nquery             0 ACGAA-AGAA  9\n\ntarget            0 A--AACA-A-A  7\n                  0 |--||-|-|-| 11\nquery             0 ACGAA-AGAAA 10\n\ntarget            0 A--AACA--AA  7\n                  0 |--||-|--|| 11\nquery             0 ACGAA-AGAAA 10\n\n\n\n\n5.3.5.1 Alignment objects\n\n\nprint(alignments[0])\nprint(type(alignments[0]))\nprint(alignments[0].shape)\nprint(alignments[0].indices)\n\nprint(alignments[0].counts())\ndisplay(alignments[0].frequencies)\n\ntarget            0 A--AACA-AA  7\n                  0 |--||-|-|| 10\nquery             0 ACGAA-AGAA  9\n\n&lt;class 'Bio.Align.Alignment'&gt;\n(2, 10)\n[[ 0 -1 -1  1  2  3  4 -1  5  6]\n [ 0  1  2  3  4 -1  5  6  7  8]]\nAlignmentCounts(gaps=4, identities=6, mismatches=0)\n\n\n{'A': array([2., 0., 0., 2., 2., 0., 2., 0., 2., 2.]),\n '-': array([0., 1., 1., 0., 0., 1., 0., 1., 0., 0.]),\n 'C': array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0.]),\n 'G': array([0., 0., 1., 0., 0., 0., 0., 1., 0., 0.])}\n\n\n\n\n5.3.5.2 [User] biopython을 사용해서 NCBI에서 egfp 와 sfgfp 서열을 다운로드 받고 서열을 비교하는 코드를 알려줘\n\n\n5.3.5.3 [ChatGPT]\nfrom Bio import Entrez, SeqIO\nfrom Bio.Seq import Seq\nfrom Bio.SeqRecord import SeqRecord\nfrom Bio import pairwise2\nfrom Bio.pairwise2 import format_alignment\n\n# Always provide your email when using NCBI's Entrez\nEntrez.email = \"your.email@example.com\"  # Replace with your email address\n\ndef download_sequence(accession):\n    \"\"\"Download a sequence by its accession number from NCBI.\"\"\"\n    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"gb\", retmode=\"text\")\n    seq_record = SeqIO.read(handle, \"genbank\")\n    handle.close()\n    return seq_record\n\ndef compare_sequences(seq1, seq2):\n    \"\"\"Perform a simple sequence alignment between two sequences.\"\"\"\n    alignments = pairwise2.align.globalxx(seq1.seq, seq2.seq)\n    return alignments[0]  # Return the first alignment\n\n# Accession numbers for EGFP and sfGFP from NCBI\negfp_accession = \"U55762\"  # Example accession, update as necessary\nsfgfp_accession = \"EU304438\"  # Example accession, update as necessary\n\n# Download sequences\negfp_seq = download_sequence(egfp_accession)\nsfgfp_seq = download_sequence(sfgfp_accession)\n\n# Compare sequences\nalignment = compare_sequences(egfp_seq, sfgfp_seq)\n\n# Print alignment\nprint(format_alignment(*alignment))\n\n\n5.3.5.4 [User] 출력을 좀 더 보기 좋게 해줘\n\n\n5.3.5.5 [ChatGTP]\nfrom Bio import Entrez, SeqIO\nfrom Bio import pairwise2\nfrom Bio.pairwise2 import format_alignment\n\n# Always provide your email when using NCBI's Entrez\nEntrez.email = \"your.email@example.com\"  # Replace with your email address\n\ndef download_sequence(accession):\n    \"\"\"Download a sequence by its accession number from NCBI.\"\"\"\n    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"gb\", retmode=\"text\")\n    seq_record = SeqIO.read(handle, \"genbank\")\n    handle.close()\n    return seq_record\n\ndef compare_sequences(seq1, seq2):\n    \"\"\"Perform a sequence alignment between two sequences and format the output.\"\"\"\n    # Using a simple scoring: 1 point for match, -1 for mismatch, -2 for opening a gap, -0.5 for extending it\n    alignments = pairwise2.align.globalms(seq1.seq, seq2.seq, 2, -1, -2, -0.5, one_alignment_only=True)\n    best_alignment = alignments[0]\n    return best_alignment\n\ndef print_alignment(alignment):\n    \"\"\"Print formatted alignment.\"\"\"\n    aligned_seq1, aligned_seq2, score, start, end = alignment\n    match_line = []  # To store the match symbols ('|', ' ', '*')\n\n    for base1, base2 in zip(aligned_seq1, aligned_seq2):\n        if base1 == base2:\n            match_line.append('|')  # Match\n        else:\n            match_line.append(' ')  # Mismatch\n\n    # Print the results\n    print(\"Alignment:\")\n    print(\"Score:\", score)\n    print(aligned_seq1[start:end])\n    print(''.join(match_line[start:end]))\n    print(aligned_seq2[start:end])\n\n# Accession numbers for EGFP and sfGFP\negfp_accession = \"U55762\"  # Example accession, update as necessary\nsfgfp_accession = \"EU304438\"  # Example accession, update as necessary\n\n# Download sequences\negfp_seq = download_sequence(egfp_accession)\nsfgfp_seq = download_sequence(sfgfp_accession)\n\n# Compare sequences\nalignment = compare_sequences(egfp_seq, sfgfp_seq)\n\n# Print formatted alignment\nprint_alignment(alignment)\n\n\n5.3.5.6 [User] 위 코드의 서열 비교 출력을 지정된 base pair 길이만큼 끊어서 보여주는 코드를 만들어줘\n\n\n5.3.5.7 [ChatGPT]\nfrom Bio import Entrez, SeqIO\nfrom Bio import pairwise2\nfrom Bio.pairwise2 import format_alignment\n\n# Always provide your email when using NCBI's Entrez\nEntrez.email = \"your.email@example.com\"  # Replace with your email address\n\ndef download_sequence(accession):\n    \"\"\"Download a sequence by its accession number from NCBI.\"\"\"\n    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"gb\", retmode=\"text\")\n    seq_record = SeqIO.read(handle, \"genbank\")\n    handle.close()\n    return seq_record\n\ndef compare_sequences(seq1, seq2):\n    \"\"\"Perform a sequence alignment between two sequences and format the output.\"\"\"\n    alignments = pairwise2.align.globalms(seq1.seq, seq2.seq, 2, -1, -2, -0.5, one_alignment_only=True)\n    return alignments[0]  # Return the first alignment\n\ndef print_alignment(alignment, chunk_size=60):\n    \"\"\"Print formatted alignment in chunks.\"\"\"\n    aligned_seq1, aligned_seq2, score, start, end = alignment\n    alignment_length = end - start\n    print(\"Alignment Score:\", score)\n    \n    for i in range(0, alignment_length, chunk_size):\n        subseq1 = aligned_seq1[start+i:start+i+chunk_size]\n        subseq2 = aligned_seq2[start+i:start+i+chunk_size]\n        \n        # Generate a matching line\n        match_line = ''.join('|' if b1 == b2 else ' ' for b1, b2 in zip(subseq1, subseq2))\n        \n        # Print the alignment in chunks\n        print(\"\\nAlignment chunk from position\", start+i+1, \"to\", min(start+i+chunk_size, alignment_length))\n        print(subseq1)\n        print(match_line)\n        print(subseq2)\n\n# Accession numbers for EGFP and sfGFP\negfp_accession = \"U55762\"  # Example accession, update as necessary\nsfgfp_accession = \"EU304438\"  # Example accession, update as necessary\n\n# Download sequences\negfp_seq = download_sequence(egfp_accession)\nsfgfp_seq = download_sequence(sfgfp_accession)\n\n# Compare sequences\nalignment = compare_sequences(egfp_seq, sfgfp_seq)\n\n# Print formatted alignment\nprint_alignment(alignment, chunk_size=60)  # You can adjust the chunk size as needed\n\n\n\n5.3.5.8 [User] 출력 서열 앞쪽에 각 서열의 accession number를 붙여주고 마지막에는 총 길이와 다른 서열의 개수 등 통계를 출력해줘\n\n\n5.3.5.9 [ChatGPT]\nfrom Bio import Entrez, SeqIO\nfrom Bio import pairwise2\nfrom Bio.pairwise2 import format_alignment\n\n# Always provide your email when using NCBI's Entrez\nEntrez.email = \"your.email@example.com\"  # Replace with your email address\n\ndef download_sequence(accession):\n    \"\"\"Download a sequence by its accession number from NCBI.\"\"\"\n    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"gb\", retmode=\"text\")\n    seq_record = SeqIO.read(handle, \"genbank\")\n    handle.close()\n    return seq_record\n\ndef compare_sequences(seq1, seq2):\n    \"\"\"Perform a sequence alignment between two sequences and format the output.\"\"\"\n    alignments = pairwise2.align.globalms(seq1.seq, seq2.seq, 2, -1, -2, -0.5, one_alignment_only=True)\n    return alignments[0]  # Return the first alignment\n\ndef print_alignment(alignment, seq1_acc, seq2_acc, chunk_size=60):\n    \"\"\"Print formatted alignment in chunks, including accession numbers and statistics.\"\"\"\n    aligned_seq1, aligned_seq2, score, start, end = alignment\n    alignment_length = end - start\n    total_mismatches = sum(1 for b1, b2 in zip(aligned_seq1, aligned_seq2) if b1 != b2)\n    \n    print(f\"Alignment Score: {score}\")\n    print(f\"Total Length: {alignment_length}\")\n    print(f\"Mismatches: {total_mismatches}\")\n    \n    for i in range(0, alignment_length, chunk_size):\n        subseq1 = aligned_seq1[start+i:start+i+chunk_size]\n        subseq2 = aligned_seq2[start+i:start+i+chunk_size]\n        \n        # Generate a matching line\n        match_line = ''.join('|' if b1 == b2 else ' ' for b1, b2 in zip(subseq1, subseq2))\n        \n        # Print the alignment in chunks\n        print(f\"\\n{seq1_acc} (position {start+i+1} to {min(start+i+chunk_size, alignment_length)})\")\n        print(subseq1)\n        print(match_line)\n        print(f\"{seq2_acc} (position {start+i+1} to {min(start+i+chunk_size, alignment_length)})\")\n        print(subseq2)\n\n# Accession numbers for EGFP and sfGFP\negfp_accession = \"U55762\"  # Example accession, update as necessary\nsfgfp_accession = \"EU304438\"  # Example accession, update as necessary\n\n# Download sequences\negfp_seq = download_sequence(egfp_accession)\nsfgfp_seq = download_sequence(sfgfp_accession)\n\n# Compare sequences\nalignment = compare_sequences(egfp_seq, sfgfp_seq)\n\n# Print formatted alignment\nprint_alignment(alignment, egfp_accession, sfgfp_accession, chunk_size=60)  # You can adjust the chunk size as needed\n\n!pip install matplotlib\n\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy&gt;=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: python-dateutil&gt;=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0)\n\n\n\n\n5.3.5.10 [User] 위 비교 결과를 한 줄로 표현되는 그래프로 그려주는 코드를 알려줘\n\n\n5.3.5.11 [ChatGPT]\nfrom Bio import Entrez, SeqIO\nfrom Bio import pairwise2\nimport matplotlib.pyplot as plt\n\n# Always provide your email when using NCBI's Entrez\nEntrez.email = \"your.email@example.com\"  # Replace with your email address\n\ndef download_sequence(accession):\n    \"\"\"Download a sequence by its accession number from NCBI.\"\"\"\n    handle = Entrez.efetch(db=\"nucleotide\", id=accession, rettype=\"gb\", retmode=\"text\")\n    seq_record = SeqIO.read(handle, \"genbank\")\n    handle.close()\n    return seq_record\n\ndef compare_sequences(seq1, seq2):\n    \"\"\"Perform a sequence alignment between two sequences and format the output.\"\"\"\n    alignments = pairwise2.align.globalms(seq1.seq, seq2.seq, 2, -1, -2, -0.5, one_alignment_only=True)\n    return alignments[0]  # Return the first alignment\n\ndef plot_alignment(alignment):\n    \"\"\"Plot alignment as a line graph.\"\"\"\n    aligned_seq1, aligned_seq2, score, start, end = alignment\n    \n    # Create match scores: 1 for match, 0 for mismatch\n    match_scores = [1 if b1 == b2 else 0 for b1, b2 in zip(aligned_seq1, aligned_seq2)]\n    \n    # Plot the results\n    plt.figure(figsize=(10, 2))\n    plt.plot(match_scores, color='blue', linestyle='-', linewidth=1)\n    plt.title(\"Sequence Alignment\")\n    plt.xlabel(\"Position\")\n    plt.ylabel(\"Match (1) / Mismatch (0)\")\n    plt.ylim(-0.1, 1.1)  # Keep the y-axis tight to match/mismatch values\n    plt.show()\n\n# Accession numbers for EGFP and sfGFP\negfp_accession = \"U55762\"\nsfgfp_accession = \"EU304438\"\n\n# Download sequences\negfp_seq = download_sequence(egfp_accession)\nsfgfp_seq = download_sequence(sfgfp_accession)\n\n# Compare sequences\nalignment = compare_sequences(egfp_seq, sfgfp_seq)\n\n# Plot the alignment graphically\nplot_alignment(alignment)\n\n\n\n5.3.6 Multiple sequence alignment objects\n\nhttp://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc70\n\nBio.AlignIO.read() returns a single MultipleSeqAlignment object\n\nBio.AlignIO.parse() returns MultipleSeqAlignment objects\n\n\nfrom Bio import Entrez\nEntrez.email = \"kimhaseong@gmail.com\"\n\n# Searching NCBI Nucleotide database\nhandle = Entrez.esearch(db=\"nucleotide\", term=\"esterase[All Fields] AND \\\"Escherichia coli\\\"[Primary Organism] AND (\\\"580\\\"[SLEN] : \\\"600\\\"[SLEN])\", idtype=\"acc\")\nrecord = Entrez.read(handle)\nprint(record[\"IdList\"])\n\n['NZ_CANUGE010000080.1', 'NZ_CANUHA010000080.1', 'NZ_CANUFW010000086.1', 'NZ_JAINSC010000053.1', 'NZ_JAUOTQ010000344.1', 'NZ_RQOE01000407.1', 'RQOE01000407.1', 'QFSK01000273.1', 'PTNY01001592.1', 'NSEG01000063.1', 'KP965724.1', 'AZLZ01000386.1']\n\n\n\nfrom Bio import SeqIO\n\nmyidx = [0, 4, 5]\nentids = [record[\"IdList\"][x] for x in myidx]\nentids\n\nstream = Entrez.efetch(db=\"nucleotide\", rettype=\"fasta\", retmode=\"text\", id=entids)\n\n#write to an output file\nwith open(\"data/esterase.fasta\", \"w\") as output:\n    output.write(stream.read())\n\nstream.close()\n\n\nAlignment tools\nClustalw를 이용한 서열 정렬 (cactus family Opuntia(선인장))\n\n\n!sudo apt-get update\n!sudo apt-get install -y clustalw\n\n0% [Working]            Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [53.5 kB]\nGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\nGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [917 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\nHit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\nGet:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\nGet:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,885 kB]\nGet:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,160 kB]\nHit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nGet:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\nGet:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [47.9 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,389 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.5 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [31.8 kB]\nGet:20 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,439 kB]\nGet:21 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,088 kB]\nFetched 10.5 MB in 14s (773 kB/s)\nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nSuggested packages:\n  clustalx seaview\nThe following NEW packages will be installed:\n  clustalw\n0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\nNeed to get 275 kB of archives.\nAfter this operation, 818 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 clustalw amd64 2.1+lgpl-7 [275 kB]\nFetched 275 kB in 1s (257 kB/s)\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, &lt;&gt; line 1.)\ndebconf: falling back to frontend: Readline\ndebconf: unable to initialize frontend: Readline\ndebconf: (This frontend requires a controlling tty.)\ndebconf: falling back to frontend: Teletype\ndpkg-preconfigure: unable to re-open stdin: \nSelecting previously unselected package clustalw.\n(Reading database ... 121913 files and directories currently installed.)\nPreparing to unpack .../clustalw_2.1+lgpl-7_amd64.deb ...\nUnpacking clustalw (2.1+lgpl-7) ...\nSetting up clustalw (2.1+lgpl-7) ...\nProcessing triggers for man-db (2.10.2-1) ...\n\n\n\n!clustalw -help\n\n\n\n\n CLUSTAL 2.1 Multiple Sequence Alignments\n\n\n                DATA (sequences)\n\n-INFILE=file.ext                             :input sequences.\n-PROFILE1=file.ext  and  -PROFILE2=file.ext  :profiles (old alignment).\n\n\n                VERBS (do things)\n\n-OPTIONS            :list the command line parameters\n-HELP  or -CHECK    :outline the command line params.\n-FULLHELP           :output full help content.\n-ALIGN              :do full multiple alignment.\n-TREE               :calculate NJ tree.\n-PIM                :output percent identity matrix (while calculating the tree)\n-BOOTSTRAP(=n)      :bootstrap a NJ tree (n= number of bootstraps; def. = 1000).\n-CONVERT            :output the input sequences in a different file format.\n\n\n                PARAMETERS (set things)\n\n***General settings:****\n-INTERACTIVE :read command line, then enter normal interactive menus\n-QUICKTREE   :use FAST algorithm for the alignment guide tree\n-TYPE=       :PROTEIN or DNA sequences\n-NEGATIVE    :protein alignment with negative values in matrix\n-OUTFILE=    :sequence alignment file name\n-OUTPUT=     :CLUSTAL(default), GCG, GDE, PHYLIP, PIR, NEXUS and FASTA\n-OUTORDER=   :INPUT or ALIGNED\n-CASE        :LOWER or UPPER (for GDE output only)\n-SEQNOS=     :OFF or ON (for Clustal output only)\n-SEQNO_RANGE=:OFF or ON (NEW: for all output formats)\n-RANGE=m,n   :sequence range to write starting m to m+n\n-MAXSEQLEN=n :maximum allowed input sequence length\n-QUIET       :Reduce console output to minimum\n-STATS=      :Log some alignents statistics to file\n\n***Fast Pairwise Alignments:***\n-KTUPLE=n    :word size\n-TOPDIAGS=n  :number of best diags.\n-WINDOW=n    :window around best diags.\n-PAIRGAP=n   :gap penalty\n-SCORE       :PERCENT or ABSOLUTE\n\n\n***Slow Pairwise Alignments:***\n-PWMATRIX=    :Protein weight matrix=BLOSUM, PAM, GONNET, ID or filename\n-PWDNAMATRIX= :DNA weight matrix=IUB, CLUSTALW or filename\n-PWGAPOPEN=f  :gap opening penalty        \n-PWGAPEXT=f   :gap opening penalty\n\n\n***Multiple Alignments:***\n-NEWTREE=      :file for new guide tree\n-USETREE=      :file for old guide tree\n-MATRIX=       :Protein weight matrix=BLOSUM, PAM, GONNET, ID or filename\n-DNAMATRIX=    :DNA weight matrix=IUB, CLUSTALW or filename\n-GAPOPEN=f     :gap opening penalty        \n-GAPEXT=f      :gap extension penalty\n-ENDGAPS       :no end gap separation pen. \n-GAPDIST=n     :gap separation pen. range\n-NOPGAP        :residue-specific gaps off  \n-NOHGAP        :hydrophilic gaps off\n-HGAPRESIDUES= :list hydrophilic res.    \n-MAXDIV=n      :% ident. for delay\n-TYPE=         :PROTEIN or DNA\n-TRANSWEIGHT=f :transitions weighting\n-ITERATION=    :NONE or TREE or ALIGNMENT\n-NUMITER=n     :maximum number of iterations to perform\n-NOWEIGHTS     :disable sequence weighting\n\n\n***Profile Alignments:***\n-PROFILE      :Merge two alignments by profile alignment\n-NEWTREE1=    :file for new guide tree for profile1\n-NEWTREE2=    :file for new guide tree for profile2\n-USETREE1=    :file for old guide tree for profile1\n-USETREE2=    :file for old guide tree for profile2\n\n\n***Sequence to Profile Alignments:***\n-SEQUENCES   :Sequentially add profile2 sequences to profile1 alignment\n-NEWTREE=    :file for new guide tree\n-USETREE=    :file for old guide tree\n\n\n***Structure Alignments:***\n-NOSECSTR1     :do not use secondary structure-gap penalty mask for profile 1 \n-NOSECSTR2     :do not use secondary structure-gap penalty mask for profile 2\n-SECSTROUT=STRUCTURE or MASK or BOTH or NONE   :output in alignment file\n-HELIXGAP=n    :gap penalty for helix core residues \n-STRANDGAP=n   :gap penalty for strand core residues\n-LOOPGAP=n     :gap penalty for loop regions\n-TERMINALGAP=n :gap penalty for structure termini\n-HELIXENDIN=n  :number of residues inside helix to be treated as terminal\n-HELIXENDOUT=n :number of residues outside helix to be treated as terminal\n-STRANDENDIN=n :number of residues inside strand to be treated as terminal\n-STRANDENDOUT=n:number of residues outside strand to be treated as terminal \n\n\n***Trees:***\n-OUTPUTTREE=nj OR phylip OR dist OR nexus\n-SEED=n        :seed number for bootstraps.\n-KIMURA        :use Kimura's correction.   \n-TOSSGAPS      :ignore positions with gaps.\n-BOOTLABELS=node OR branch :position of bootstrap values in tree display\n-CLUSTERING=   :NJ or UPGMA\n\n\n\n!cat data/esterase.fasta\n\n&gt;NZ_CANUGE010000080.1 Escherichia coli strain ROAR-416 / O18:H7 / fimH15 / 95 (ST Warwick) isolate Faeces NODE_80_length_585_cov_58.954717, whole genome shotgun sequence\nGGCGGCCTCTATACCCGCTTATGGCATGACAGCGTCAGCAGTACTGCGCTCCATCGCCAGCACAACATGA\nAGGAGGAAACCCCGGGATAGTTACTGGACACGTAATGTATTAAAAACACAGTCAGAAGCGGCGGTACCGT\nGAATAGCCGCTTTAATTATTTATACTGACATCCTTAATTTTTAAAGAGTATGAATGCTGAACATGCAACA\nACATCCCTCTGCTATCGCCAGCCTGCGCAACCAACTGGCAGCGGGCCACATTGCTAACCTTACTGACTTC\nTGGCGCGAAGCTGAGTCGCTGAATGTTCCTCTTGTGACGCCAGTCGAAGGAGCGGAAGATGAGCGAGAAG\nTGACCTTTCTGTGGCGCGCCCGACATCCTCTGCAGGGCGTTTATCTGCGTCTGAACCGGGTGACGGATAA\nAGAGCACGTAGAAAAAGGAATGATGAGCGCCCTTCCCGAAACGGATATCTGGACACTGACACTGCGTTTA\nCCCGCAAGTTACTGCGGCTCCTATTCGCTGCTGGAAATCCCCCCCGGCACTACGGCTGAGACGATTGCAC\nTGTCCGGAGGCCGTTTTGCCACCCT\n\n&gt;NZ_JAUOTQ010000344.1 Escherichia coli strain SCL2922 NODE_344_length_581_cov_2.811508, whole genome shotgun sequence\nGAATGGAACGGCGGCTTCCACACCGGACAACTGCTTACCTCCATGCGCATTATCGCCGGGAAATCTCGCC\nAGGTTCGGCTCTATATTCCGGACGTTGATATTTCTCAGCCCCTCGGGCTGGTCGTGCTGCCCGATGGTGA\nAACCTGGTTTGATCACCTTGGCGTATGCGCGGCAATTGACGCCGCCATAAATAACAGGCGCATCGTGCCC\nGTGGCTGTACTGGGCATTGACAACATTAATGAACATGAACGCACTGAGATACTCGGCGGGCGCAGCAAGC\nTGATAAAGGATATCGCAGGACATCTGCTGCCGATGATCCGCGCTGAACAACCGCAGCGTCAGTGGGCAGA\nCCGTTCGCGCACAGTGCTGGCCGGGCAGAGCCTCGGCGGGATCAGTGCACTAATGGGGGCTCGTTACGCA\nCCGGAAACGTTCGGTCTGGTGCTCAGCCACTCTCCTTCAATGTGGTGGACGCCAGAAAGAACCAGTCTAC\nCAGGCTTGTTCAGCGAAACCGATACCTCATGGGTGAGTGAGCATCTGCTTTCTGCCCCACCGCAGGGCGT\nGCGTATCAGCCTGTGCGTGGG\n\n&gt;NZ_RQOE01000407.1 Escherichia coli strain S366 NODE_408_length_581_cov_1.19604, whole genome shotgun sequence\nACTGAATATCGCTCGGCAACGCCGCGGCTTATGGGGGCACTCCTACGGCGGCCTCTTCGTGCTGGATTCC\nTGGCTGTCCTCCTCTTACTTCCGGTCGTACTACAGCGCCAGCCCGTCGTTGGGCAGAGGTTATGATGCTT\nTGCTAAGCCGCGTTACGGCGGTTGAGCCTCTGCAATTCTGCGCCAAACACCTGGCGATAATGGAAGGCTC\nGGCGACACAGGGTGATAACCGGGAAACGCATGCTGTCGGGGTGCTGTCGAAAATTCATACCACCCTCACT\nATACTGAAAGATAAAGGCGTCAATGCCGTATTTTGGGATTTCCCCAACCTAGGACACGGGCCGATGTTCA\nATGCCTCCTTTCGCCAGGCACTGTTAGATATCAGTGGTGAAAACGCAAATTACACAGCAGGTTGTCATGA\nGTTAAGCCACTAAACACTGCCCGCTTTTACGCGGGCAGTACGCCTGAAACACTACGATCAGAATGATGCG\nGTAACTCCGGCATAGTAAGCCCGGCCTGGCTCGTTATAGGTATTCGCCCCTTCAGAAGATCGGAAGATCT\nGTTTATTGAGGATATTACTGA\n\n\n\n\n!clustalw -infile=data/esterase.fasta -outfile=data/esterase.aln\n\n\n\n\n CLUSTAL 2.1 Multiple Sequence Alignments\n\n\nSequence format is Pearson\nSequence 1: NZ_CANUGE010000080.1   585 bp\nSequence 2: NZ_JAUOTQ010000344.1   581 bp\nSequence 3: NZ_RQOE01000407.1      581 bp\nStart of Pairwise alignments\nAligning...\n\nSequences (1:2) Aligned. Score:  4\nSequences (1:3) Aligned. Score:  4\nSequences (2:3) Aligned. Score:  3\nGuide tree file created:   [data/esterase.dnd]\n\nThere are 2 groups\nStart of Multiple Alignment\n\nAligning...\nGroup 1:                     Delayed\nGroup 2:                     Delayed\nAlignment Score 3099\n\nCLUSTAL-Alignment file created  [data/esterase.aln]\n\n\n\n\nfrom Bio import AlignIO\nalign = AlignIO.read(\"data/esterase.aln\", \"clustal\")\nprint(align)\n\nAlignment with 3 rows and 641 columns\n--------------GGCGGCCTCTATACCCGCTTATGGCATGAC...CCT NZ_CANUGE010000080.1\n-----GAATGGAACGGCGGCTTCCACACCGGACAACTGCTTACC...--- NZ_JAUOTQ010000344.1\nACTGAATATCGCTCGGCAACG-CCGCGGCTTATGGGGGCACTCC...--- NZ_RQOE01000407.1\n\n\n\nalign.substitutions\n\n\nfrom Bio import Phylo\ntree = Phylo.read(\"data/esterase.dnd\", \"newick\")\nPhylo.draw_ascii(tree)\n\n  ______________________________________________________ NZ_CANUGE010000080.1\n |\n_|_______________________________________________________ NZ_JAUOTQ010000344.1\n |\n |________________________________________________________ NZ_RQOE01000407.1\n\n\n\n\n5.3.6.1 Position specific scoring matrix (PSSM) matrix\n\nfrom Bio import AlignIO\nfrom Bio.Align import AlignInfo\n\n\nPfam은 단백질 페밀리 database, 각 서열 그룹을 align 한 파일이 제공됨\nFamily: Sigma54_activ_2 (PF14532) https://www.ebi.ac.uk/interpro/entry/pfam/PF14532/\n\n\nalign = AlignIO.read(\"/content/drive/MyDrive/2024-cnu-lecture/data/PF14532_full.txt\", \"stockholm\")\nprint(align)\nprint(len(align))\n\nAlignment with 1240 rows and 765 columns\n--------------------------------------------...--- A0A1F7TK17_9BACT/134-279\n--------------------------------------------...--- A0A1H8MG25_9RHOB/297-456\n--------------------------------------------...--- A0A0P1IVG1_9RHOB/141-283\n--------------------------------------------...--- V7EPJ0_9RHOB/141-283\n--------------------------------------------...--- B1ZTM1_OPITP/145-296\n--------------------------------------------...--- W3ANH6_9FIRM/219-355\n--------------------------------------------...--- Q6LNI3_PHOPR/144-289\n--------------------------------------------...--- A0A1G8U4Y5_9RHOB/145-284\n--------------------------------------------...--- W1HPT9_KLEPN/143-283\n--------------------------------------------...--- A0A0D6TAT1_9RHOB/146-292\n--------------------------------------------...--- A0A1M4UVA9_9CLOT/309-454\n--------------------------------------------...--- A0A252BQ85_9PROT/8-137\n--------------------------------------------...--- A0A0P1G5P1_9RHOB/143-285\n--------------------------------------------...--- A0A1M6RYM0_PSETH/338-463\n--------------------------------------------...--- A0A0P7EE64_9GAMM/139-307\n--------------------------------------------...--- A0A1I6GDU4_9RHOB/146-282\n--------------------------------------------...--- A0A1G0NB92_9PROT/137-274\n--------------------------------------------...--- A0A0C5W5C5_9GAMM/145-290\n...\n--------------------------------------------...--- A0A2A4B1F3_9SPHN/145-294\n1240\n\n\n\nslicing alignment\n\n\nprint(align[3:8,100:200])\n\nAlignment with 5 rows and 100 columns\n--V---A---R---V---M--------N---T----D-------...K-- V7EPJ0_9RHOB/141-283\n--V---K---K---L---A--------A---V----R-------...E-- B1ZTM1_OPITP/145-296\n--A---E---K---L---S--------R---T----D-------...N-- W3ANH6_9FIRM/219-355\n--I---A---N---I---A--------L---T----N-------...K-- Q6LNI3_PHOPR/144-289\n--V---R---L---V---A--------R---A----G-------...E-- A0A1G8U4Y5_9RHOB/145-284\n\n\n\nTurn the alignment object into an array of letters\n\n\nimport numpy as np\nfrom Bio import AlignIO\nalign = AlignIO.read(\"/content/drive/MyDrive/2024-cnu-lecture/data/esterase.aln\", \"clustal\")\n\n# convert to character array\nalign_array = np.array([list(rec) for rec in align], 'U')\nprint(align_array)\n\n[['-' '-' '-' ... 'C' 'C' 'T']\n ['-' '-' '-' ... '-' '-' '-']\n ['A' 'C' 'T' ... '-' '-' '-']]\n(3, 641)\n\n\nNote that this leaves the original Biopython alignment object and the NumPy array in memory as separate objects - editing one will not update the other!\n\nalign_array.shape\n\n(3, 641)\n\n\n\nSummaryInfo 클래스\nconsensus sequence, position specific score matrix 계산\ninformation content와 substitution 정보 계산 가능\n\n\nsummary_align = AlignInfo.SummaryInfo(align)\nconsensus = summary_align.dumb_consensus()\nprint(consensus)\nmy_pssm = summary_align.pos_specific_score_matrix(consensus, chars_to_ignore = ['N', '-'])\n#print(my_pssm)\n# your_pssm[sequence_number][residue_count_name]\n[s for s in my_pssm][:20]\n\nACTGAXXATXGXXCGGCXXCXTCXXXXXCXXXXXXXXGCXXXXCXXCXXXXGCXXXXXXGXXXXGXXXXXXXGXCXGXXXXXXXXXXAXXXXXXGXXXXXXXAXAXXXCXXXXXXXXXCGGXXTGGXCXXXXXXXXXXXTXXTGXXXCXXXGXXXXXXXACXXXGGXXXXXXCXXXGCAATXGXXGCXXXXAXXAXXXXXXXXXXXATXGXXXXXXXXXXXXXAXXGXGXXXXXAXCGGXXXXXXXATGCXXXXXXXXXXCXXTCGXXXATXXXXXXCXXXCXCAXXXXXCTGXXAXXXXXXXXCXXXXXXXXXXTXXTXXXGGAXXXXXXXXXCXXAXXAXXCGXXXXGXXXXTXXXXXXCXCCXXTXGXXXXXXXXXXXXXXXXXXCXGXXXXXXXXXXXXAAXTXAXXXXXCXXXXXXXXXXXXGXXAXXCXXXXXAXXXXXXXXXXCTXXXXCXXXXXCXXGTXXCXXXXXAXXXXCACGXXXXXXXXXGAAXGATGAXCXXXXXXXCXGXXXXXXXXAXCXXGXXACXGXXXCXXXXTXXXXXXGXXXGXXXXXGCXXXTXXXXXXXXXXGXXXGXXXTXXXXXXXXXXXXTXXXXXTGXGACGATTGCACTGTCCGGAGGCCGTTTTGCCACCCT\n\n\n[{'A': 1.0, 'C': 0, 'G': 0, 'T': 0},\n {'A': 0, 'C': 1.0, 'G': 0, 'T': 0},\n {'A': 0, 'C': 0, 'G': 0, 'T': 1.0},\n {'A': 0, 'C': 0, 'G': 1.0, 'T': 0},\n {'A': 1.0, 'C': 0, 'G': 0, 'T': 0},\n {'A': 1.0, 'C': 0, 'G': 1.0, 'T': 0},\n {'A': 1.0, 'C': 0, 'G': 0, 'T': 1.0},\n {'A': 2.0, 'C': 0, 'G': 0, 'T': 0},\n {'A': 0, 'C': 0, 'G': 0, 'T': 2.0},\n {'A': 0, 'C': 1.0, 'G': 1.0, 'T': 0},\n {'A': 0, 'C': 0, 'G': 2.0, 'T': 0},\n {'A': 1.0, 'C': 1.0, 'G': 0, 'T': 0},\n {'A': 1.0, 'C': 0, 'G': 0, 'T': 1.0},\n {'A': 0, 'C': 2.0, 'G': 0, 'T': 0},\n {'A': 0, 'C': 0, 'G': 3.0, 'T': 0},\n {'A': 0, 'C': 0, 'G': 3.0, 'T': 0},\n {'A': 0, 'C': 3.0, 'G': 0, 'T': 0},\n {'A': 1.0, 'C': 0, 'G': 2.0, 'T': 0},\n {'A': 1.0, 'C': 0, 'G': 2.0, 'T': 0},\n {'A': 0, 'C': 3.0, 'G': 0, 'T': 0}]\n\n\n\ninstances = [al.seq for al in align[:10]]\nprint(instances)\n\n[Seq('--------------GGCGGCCTCTATACCCGCTTATGGCATGACAGCGTCAGCA...CCT'), Seq('-----GAATGGAACGGCGGCTTCCACACCGGACAACTGCTTACCTCCATGCGCA...---'), Seq('ACTGAATATCGCTCGGCAACG-CCGCGGCTTATGGGGGCACTCCTACGGCGGCC...---')]\n\n\n\n\n5.3.6.2 Motif\n\nBio.motifs package included in Biopython 1.61\n\n\nfrom Bio import motifs\nfrom Bio.Seq import Seq\n\n\ninstances = [Seq(\"TACAA\"),\n            Seq(\"TACGA\"),\n            Seq(\"TACAA\"),\n            Seq(\"TAGAA\"),\n            Seq(\"TACAA\"),\n            Seq(\"AACGA\"),\n           ]\n\n\nm = motifs.create(instances)\nprint(m)\n\nTACAA\nTACGA\nTACAA\nTAGAA\nTACAA\nAACGA\n\n\n\nm.counts\n\n{'A': [1.0, 6.0, 0.0, 4.0, 6.0],\n 'C': [0.0, 0.0, 5.0, 0.0, 0.0],\n 'G': [0.0, 0.0, 1.0, 2.0, 0.0],\n 'T': [5.0, 0.0, 0.0, 0.0, 0.0]}\n\n\n\nm.counts[\"A\", 1]\nr = m.reverse_complement()\nprint(r.consensus)\nr.weblogo(\"data/mymotif.png\")\n\nTTGTA\n\n\n\nfrom IPython.display import Image, display\ndisplay(Image(filename=\"/content/drive/MyDrive/2024-cnu-lecture/data/mymotif.png\"))\n\n\n\n\n\n\n\n\n\nPosition-weight matrices 계산\n.counts 특성 사용\n\n\npwm = m.counts.normalize(pseudocounts=0.5)\nprint(pwm)\n\n        0      1      2      3      4\nA:   0.19   0.81   0.06   0.56   0.81\nC:   0.06   0.06   0.69   0.06   0.06\nG:   0.06   0.06   0.19   0.31   0.06\nT:   0.69   0.06   0.06   0.06   0.06\n\n\n\n\npssm = pwm.log_odds()\nprint(pssm)\n\n        0      1      2      3      4\nA:  -0.42   1.70  -2.00   1.17   1.70\nC:  -2.00  -2.00   1.46  -2.00  -2.00\nG:  -2.00  -2.00  -0.42   0.32  -2.00\nT:   1.46  -2.00  -2.00  -2.00  -2.00\n\n\n\n\nbackground = {\"A\":0.3,\"C\":0.2,\"G\":0.2,\"T\":0.3}\npssm = pwm.log_odds(background)\nprint(pssm)\n\n        0      1      2      3      4\nA:  -0.68   1.44  -2.26   0.91   1.44\nC:  -1.68  -1.68   1.78  -1.68  -1.68\nG:  -1.68  -1.68  -0.09   0.64  -1.68\nT:   1.20  -2.26  -2.26  -2.26  -2.26\n\n\n\n\nUsing the PSSM score\n\n\nfor pos, score in pssm.search(test_seq, threshold=3.0):\n    print(\"%d, %f \" % (pos, score))\nprint(pssm.calculate(test_seq))\n\n0, 3.643981 \n10, 6.759458 \n[  3.643981    -8.560285    -2.4004133   -5.6533937   -4.2748823\n  -0.05645879 -10.145247    -3.3293302   -5.9753222   -3.5703382\n   6.759458    -5.3903594   -5.8598447   -0.81545067  -0.81545067\n   0.7695118   -6.3903594   -3.5379167    0.4255574   -1.9309279\n -10.145247    -3.3293302 ]\n\n\n\n\nm.pseudocounts = 0.1\nprint(m.counts)\nprint(m.pwm)\nprint(m.pssm)\n\n        0      1      2      3      4\nA:   1.00   6.00   0.00   4.00   6.00\nC:   0.00   0.00   5.00   0.00   0.00\nG:   0.00   0.00   1.00   2.00   0.00\nT:   5.00   0.00   0.00   0.00   0.00\n\n        0      1      2      3      4\nA:   0.17   0.95   0.02   0.64   0.95\nC:   0.02   0.02   0.80   0.02   0.02\nG:   0.02   0.02   0.17   0.33   0.02\nT:   0.80   0.02   0.02   0.02   0.02\n\n        0      1      2      3      4\nA:  -0.54   1.93  -4.00   1.36   1.93\nC:  -4.00  -4.00   1.67  -4.00  -4.00\nG:  -4.00  -4.00  -0.54   0.39  -4.00\nT:   1.67  -4.00  -4.00  -4.00  -4.00\n\n\n\n\n\n\n5.3.7 scikit-bio\nscikit-bio is another library focused on bioinformatics, providing functionalities for sequence analysis, alignment, phylogenetics, and more.\n\n5.3.7.1 Installation\npip install scikit-bio\n\n\n5.3.7.2 Basic Usage Examples\nReading and Writing Sequence Files:\nimport skbio\n\n# Reading a FASTA file\nfor seq in skbio.io.read(\"example.fasta\", format=\"fasta\"):\n    print(seq.metadata['id'])\n    print(seq)\n\n# Writing to a FASTA file\nsequences = [seq for seq in skbio.io.read(\"example.fasta\", format=\"fasta\")]\nskbio.io.write(sequences, \"output.fasta\", format=\"fasta\")\nSequence Analysis:\nfrom skbio import DNA, RNA, Protein\n\n# Creating sequences\ndna_seq = DNA(\"AGTACACTGGT\")\nrna_seq = dna_seq.transcribe()\nprotein_seq = dna_seq.translate()\n\nprint(\"DNA: \", dna_seq)\nprint(\"RNA: \", rna_seq)\nprint(\"Protein: \", protein_seq)\nAlignment:\nfrom skbio import DNA\nfrom skbio.alignment import local_pairwise_align_ssw\n\nseq1 = DNA(\"ACTGCTAGCTAG\")\nseq2 = DNA(\"GCTAGCTAGGTA\")\n\nalignment, score, start_end_positions = local_pairwise_align_ssw(seq1, seq2)\n\nprint(\"Alignment:\\n\", alignment)\nprint(\"Score:\", score)\nprint(\"Start-End Positions:\", start_end_positions)\nPhylogenetic Tree Construction:\nfrom skbio import DistanceMatrix\nfrom skbio.tree import nj\n\n# Example distance matrix\ndm = DistanceMatrix([[0.0, 0.2, 0.4],\n                     [0.2, 0.0, 0.6],\n                     [0.4, 0.6, 0.0]],\n                    ['A', 'B', 'C'])\n\n# Constructing a phylogenetic tree using Neighbor-Joining\ntree = nj(dm)\nprint(tree.ascii_art())\n\n\n\n5.3.8 Example: Analyzing a Protein Sequence\nLet’s put together an example that reads a protein sequence from a GenBank file, performs some basic analysis using Biopython, and aligns it using scikit-bio.\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\nfrom skbio import Protein\nfrom skbio.alignment import global_pairwise_align_protein\n\n# Read a protein sequence from a GenBank file\nrecord = SeqIO.read(\"example.gb\", \"genbank\")\nprotein_seq = record.seq.translate()\n\nprint(\"Protein Sequence:\", protein_seq)\n\n# Perform reverse translation to get the DNA sequence\ndna_seq = protein_seq.reverse_translate(table=11)\nprint(\"Reverse Translated DNA Sequence:\", dna_seq)\n\n# Perform alignment with another protein sequence\nseq1 = Protein(str(protein_seq))\nseq2 = Protein(\"MKVLYNLKDG\")\n\nalignment, score, start_end_positions = global_pairwise_align_protein(seq1, seq2)\n\nprint(\"Alignment:\\n\", alignment)\nprint(\"Score:\", score)\nprint(\"Start-End Positions:\", start_end_positions)\n\n\n5.3.9 Explanation:\n\nReading Sequence: We use Biopython to read a protein sequence from a GenBank file.\nSequence Analysis: We perform basic sequence operations like translation and reverse translation.\nAlignment: We use scikit-bio to perform a global pairwise alignment between two protein sequences.\n\nBy mastering these bioinformatics libraries, you will be well-equipped to handle a wide range of bioinformatics tasks and analyses in your research. If you have specific questions or need further examples, feel free to ask!",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bioinformatics</span>"
    ]
  },
  {
    "objectID": "cnu_machine_learning.html",
    "href": "cnu_machine_learning.html",
    "title": "6  Machine Learning and Deep Learning",
    "section": "",
    "text": "6.1 K-Nearest Neighbor (KNN)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\n\nimport seaborn as sns\nbreast_cancer = load_breast_cancer()\ndir(breast_cancer)\nprint(breast_cancer.DESCR)\n\n.. _breast_cancer_dataset:\n\nBreast cancer wisconsin (diagnostic) dataset\n--------------------------------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 569\n\n    :Number of Attributes: 30 numeric, predictive attributes and the class\n\n    :Attribute Information:\n        - radius (mean of distances from center to points on the perimeter)\n        - texture (standard deviation of gray-scale values)\n        - perimeter\n        - area\n        - smoothness (local variation in radius lengths)\n        - compactness (perimeter^2 / area - 1.0)\n        - concavity (severity of concave portions of the contour)\n        - concave points (number of concave portions of the contour)\n        - symmetry\n        - fractal dimension (\"coastline approximation\" - 1)\n\n        The mean, standard error, and \"worst\" or largest (mean of the three\n        worst/largest values) of these features were computed for each image,\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n        10 is Radius SE, field 20 is Worst Radius.\n\n        - class:\n                - WDBC-Malignant\n                - WDBC-Benign\n\n    :Summary Statistics:\n\n    ===================================== ====== ======\n                                           Min    Max\n    ===================================== ====== ======\n    radius (mean):                        6.981  28.11\n    texture (mean):                       9.71   39.28\n    perimeter (mean):                     43.79  188.5\n    area (mean):                          143.5  2501.0\n    smoothness (mean):                    0.053  0.163\n    compactness (mean):                   0.019  0.345\n    concavity (mean):                     0.0    0.427\n    concave points (mean):                0.0    0.201\n    symmetry (mean):                      0.106  0.304\n    fractal dimension (mean):             0.05   0.097\n    radius (standard error):              0.112  2.873\n    texture (standard error):             0.36   4.885\n    perimeter (standard error):           0.757  21.98\n    area (standard error):                6.802  542.2\n    smoothness (standard error):          0.002  0.031\n    compactness (standard error):         0.002  0.135\n    concavity (standard error):           0.0    0.396\n    concave points (standard error):      0.0    0.053\n    symmetry (standard error):            0.008  0.079\n    fractal dimension (standard error):   0.001  0.03\n    radius (worst):                       7.93   36.04\n    texture (worst):                      12.02  49.54\n    perimeter (worst):                    50.41  251.2\n    area (worst):                         185.2  4254.0\n    smoothness (worst):                   0.071  0.223\n    compactness (worst):                  0.027  1.058\n    concavity (worst):                    0.0    1.252\n    concave points (worst):               0.0    0.291\n    symmetry (worst):                     0.156  0.664\n    fractal dimension (worst):            0.055  0.208\n    ===================================== ====== ======\n\n    :Missing Attribute Values: None\n\n    :Class Distribution: 212 - Malignant, 357 - Benign\n\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n\n    :Donor: Nick Street\n\n    :Date: November, 1995\n\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\nhttps://goo.gl/U2Uwz2\n\nFeatures are computed from a digitized image of a fine needle\naspirate (FNA) of a breast mass.  They describe\ncharacteristics of the cell nuclei present in the image.\n\nSeparating plane described above was obtained using\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\nConstruction Via Linear Programming.\" Proceedings of the 4th\nMidwest Artificial Intelligence and Cognitive Science Society,\npp. 97-101, 1992], a classification method which uses linear\nprogramming to construct a decision tree.  Relevant features\nwere selected using an exhaustive search in the space of 1-4\nfeatures and 1-3 separating planes.\n\nThe actual linear program used to obtain the separating plane\nin the 3-dimensional space is that described in:\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\nProgramming Discrimination of Two Linearly Inseparable Sets\",\nOptimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server:\n\nftp ftp.cs.wisc.edu\ncd math-prog/cpo-dataset/machine-learn/WDBC/\n\n.. topic:: References\n\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n     San Jose, CA, 1993.\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n     July-August 1995.\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n     163-171.\nprint(breast_cancer.data.shape)\nX = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\nX.head()\n\n(569, 30)\n\n\n\n\n  \n    \n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst radius\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\n\n\n\n\n0\n17.99\n10.38\n122.80\n1001.0\n0.11840\n0.27760\n0.3001\n0.14710\n0.2419\n0.07871\n...\n25.38\n17.33\n184.60\n2019.0\n0.1622\n0.6656\n0.7119\n0.2654\n0.4601\n0.11890\n\n\n1\n20.57\n17.77\n132.90\n1326.0\n0.08474\n0.07864\n0.0869\n0.07017\n0.1812\n0.05667\n...\n24.99\n23.41\n158.80\n1956.0\n0.1238\n0.1866\n0.2416\n0.1860\n0.2750\n0.08902\n\n\n2\n19.69\n21.25\n130.00\n1203.0\n0.10960\n0.15990\n0.1974\n0.12790\n0.2069\n0.05999\n...\n23.57\n25.53\n152.50\n1709.0\n0.1444\n0.4245\n0.4504\n0.2430\n0.3613\n0.08758\n\n\n3\n11.42\n20.38\n77.58\n386.1\n0.14250\n0.28390\n0.2414\n0.10520\n0.2597\n0.09744\n...\n14.91\n26.50\n98.87\n567.7\n0.2098\n0.8663\n0.6869\n0.2575\n0.6638\n0.17300\n\n\n4\n20.29\n14.34\n135.10\n1297.0\n0.10030\n0.13280\n0.1980\n0.10430\n0.1809\n0.05883\n...\n22.54\n16.67\n152.20\n1575.0\n0.1374\n0.2050\n0.4000\n0.1625\n0.2364\n0.07678\n\n\n\n\n5 rows × 30 columns\ny = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\ny = pd.get_dummies(y, drop_first=True)\ny\n\n\n\n  \n    \n\n\n\n\n\n\nbenign\n\n\n\n\n0\nFalse\n\n\n1\nFalse\n\n\n2\nFalse\n\n\n3\nFalse\n\n\n4\nFalse\n\n\n...\n...\n\n\n564\nFalse\n\n\n565\nFalse\n\n\n566\nFalse\n\n\n567\nFalse\n\n\n568\nTrue\n\n\n\n\n569 rows × 1 columns\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nknn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\nknn.fit(X_train, y_train)\ny_pred = knn.predict(X_test)\nsns.scatterplot(\n    x='mean area',\n    y='mean compactness',\n    hue='benign',\n    data=X_test.join(y_test, how='outer')\n)\n\n/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  return self._fit(X, y)\nresults = pd.DataFrame([y_test[\"benign\"].values, y_pred], index=(\"test\", \"predict\")).T\nprint(results)\n\n      test  predict\n0    False    False\n1     True     True\n2    False    False\n3    False    False\n4     True     True\n..     ...      ...\n138  False    False\n139  False    False\n140   True     True\n141   True     True\n142  False     True\n\n[143 rows x 2 columns]\nfrom sklearn import metrics\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n\nAccuracy: 0.8951048951048951\nfrom sklearn.inspection import permutation_importance\n\n# Compute permutation feature importance\nresults = permutation_importance(knn, X_test, y_test, n_repeats=5, random_state=40)\n\n# Get importance scores\nfeature_importance = results.importances_mean\n\n# Plot feature importance\nplt.bar(range(X.shape[1]), feature_importance, tick_label=breast_cancer.feature_names)\nplt.xlabel('Features')\nplt.ylabel('Importance')\nplt.title('Feature Importance Using Permutation on Model')\nplt.xticks(rotation=90)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Machine Learning and Deep Learning</span>"
    ]
  },
  {
    "objectID": "cnu_machine_learning.html#k-nearest-neighbor-knn",
    "href": "cnu_machine_learning.html#k-nearest-neighbor-knn",
    "title": "6  Machine Learning and Deep Learning",
    "section": "",
    "text": "https://github.com/HongleiXie/MLFromScratch\n각종 ML 모형 (python, tensorflow 프레임워크)\n\n\n\n\n\ndummy y 변수 생성\n\n\n\n데이터셋 준비 (훈련/테스트셋)\n\n\n\n모형 훈련 및 그래프\n\n\n\n\n\n변수 중요도 탐색",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Machine Learning and Deep Learning</span>"
    ]
  },
  {
    "objectID": "cnu_machine_learning.html#cnn-with-sequence",
    "href": "cnu_machine_learning.html#cnn-with-sequence",
    "title": "6  Machine Learning and Deep Learning",
    "section": "6.2 CNN with sequence",
    "text": "6.2 CNN with sequence\n\n딥러닝 기반 DNA 서열 분석 가이드\nhttp://www.btnews.or.kr/bbs/board.php?bo_table=bt_news&wr_id=342\n\n\n6.2.1 목표\n\n임의의 활성을 갖는 서열을 분류하는 CNN 모형 개발 (시뮬레이션)\n예시) 임의의 전사인자가 결합하는 특정 DNA 모티프 찾는 모형 개발. 즉, 모형 개발 후 임의의 DNA 서열을 모형에 넣었을 때 해당 전사인자가 입력 DNA 서열에 붙으면 1 붙지 않으면 0 이라고 예측하는 모형 개발\n\n\n\n6.2.2 데이터\n딥러닝을 위해서는 라벨링 데이터가 필요함 (최근 self-supervised learning에서는 필수는 아님). 서열분석의 경우에는 DNA 서열과 함께 해당 서열의 표현형이 라벨이 될 수 있음 (Genotype-phenotype 짝 데이터). 예를 들어 특정 전사인자가 결합하는 DNA 서열을 예측하는 딥러닝 모형을 학습하고자 할 경우 전사인자의 서열 데이터와 해당 전사인자가 DNA에 실제로 붙는지를 나타내는 True 또는 False 라벨이 붙은 데이터가 필요함.\n일반적으로 통계적 분석을 위한 데이터는 샘플의 개수와 (행) 변수의 개수로 (열) 구분되어 2차원 배열 형태로 표현. 딥러닝에서도 같은 방식으로 데이터를 표현하며 필요한 샘플의 수는 학습할 모형의 복잡도에 따라서 달라질 수 있지만 최소 수천 개 이상이 필요하며 수 만개 이상의 가능한 많은 데이터를 사용 권장.\n딥러닝을 위해서 수집된 데이터 세트는 모형 학습을 위한 Training 데이터와 Test 데이터로 나누어 사용되며 Training 데이터는 또다시 Training 데이터와 Validation 데이터로 나누어 구분.\n\n!pip install biopython\n\nRequirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.83)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.25.2)\n\n\n\n\n6.2.3 One-hot encoding\n딥러닝을 위해서 데이터는 숫자(기계가 인식 가능한)로 표현 필요. One-hot encoding은 딥러닝에서 가장 널리 사용되는 방법 중 하나이며 4 종류의 염기를 갖는 DNA의 경우 “A”는 [1,0,0,0], “T”는 [0,0,0,1], “G”는 [0,0,1,0], 그리고 “C”는 [0,1,0,0] 으로 인코딩 할 수 있음\n\nimport numpy as np\n\nmy_string=\"ATACAA\"\nmy_array=np.array(list(my_string))\nprint(my_array)\n\n['A' 'T' 'A' 'C' 'A' 'A']\n\n\n\nlist(my_string)\n\n['A', 'T', 'A', 'C', 'A', 'A']\n\n\n\ndisplay(np.zeros(5))\n\ndisplay(np.zeros((7,5)))\n\narray([0., 0., 0., 0., 0.])\n\n\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n\n\n\nbox = np.zeros((3, 7, 5))\ntype(box)\n\nnumpy.ndarray\n\n\n\n\n\nimage.png\n\n\n\nonehot_encode = np.zeros((len(my_array),4), dtype=int)\nbase_dict = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\nfor i in range(len(my_array)):\n    onehot_encode[i, base_dict[my_array[i]]] = 1\n\nprint(onehot_encode)\nprint(onehot_encode.shape)\n\n[[1 0 0 0]\n [0 0 0 1]\n [1 0 0 0]\n [0 1 0 0]\n [1 0 0 0]\n [1 0 0 0]]\n(6, 4)\n\n\n\n\n\nimage.png\n\n\n\n\n6.2.4 모티프 설정\nPFM (Position Frequency Matrix)와 PWM (Position Weight Matrix) 개념 이해 필요. Alignment가 수행된 몇 개의 서열들을 가정하면 PFM은 이 서열들의 특정 위치에 A, T, G, C 각 염기들의 빈도수를 나타내며 PWM은 각 염기의 비율을 나타냄.\n\nfrom Bio import motifs\nfrom Bio.Seq import Seq\n\ninstances = [Seq(\"TACAA\"), Seq(\"TACGA\"), Seq(\"TACAA\")]\nm = motifs.create(instances)\npfm = m.counts\nprint(pfm)\npwm = m.counts.normalize(pseudocounts=0.5)\nprint (pwm)\n\n        0      1      2      3      4\nA:   0.00   3.00   0.00   2.00   3.00\nC:   0.00   0.00   3.00   0.00   0.00\nG:   0.00   0.00   0.00   1.00   0.00\nT:   3.00   0.00   0.00   0.00   0.00\n\n        0      1      2      3      4\nA:   0.10   0.70   0.10   0.50   0.70\nC:   0.10   0.10   0.70   0.10   0.10\nG:   0.10   0.10   0.10   0.30   0.10\nT:   0.70   0.10   0.10   0.10   0.10\n\n\n\npseudocounts는 계산시 NULL이나 0으로 나누어지는 경우 방지. 특정 서열 모티프의 PWM은 새로운 서열이 One-hot encoding 방식으로 주어져 있을 경우 서열 처음 위치부터 마지막까지 Sliding window 방식으로 해당 모티프가 있는 위치를 탐색할 수 있음.\n앞서 “ATACAA” 서열에서 위 PWM 모티프가 존재하는지 탐색. “ATACAA” 는 길이 5인 슬라이딩 윈도우를 사용하면 “ATACA”와 “TACAA” 두 개의 서열로 나눌 수 있음. 이 두 서열을 One-hot encoding으로 전환 후 위 PWM과 원소들끼리 곱하면 One-hot encoding에서 0이 아닌 위치와 동일 위치의 PWM 값들만 남게 되므로 0이 아닌 값들을 모두 곱한 후 log를 취해 주면 해당 서열이 모티프와 얼마나 비슷한지를 나타내는 스칼라 값이 구해짐. 이론적으로 이 값이 0이면 동일한 서열임.\n\npwm_arr = np.array(list(pwm.values())).transpose()\nprint(pwm_arr.shape)\n\nprint(onehot_encode.shape)\nprint(onehot_encode[0:5,].shape)\nprint(onehot_encode[1:6,].shape)\n\ns1 = np.multiply(onehot_encode[0:5,], pwm_arr)\ns2 = np.multiply(onehot_encode[1:6,], pwm_arr)\nprint(s1)\nprint(s2)\n\nprint(np.sum(s1, axis=1))\nprint(np.prod(np.sum(s1, axis=1)))\n\nprint(np.log(np.prod(np.sum(s1, axis=1)))) #s1 score\nprint(np.log(np.prod(np.sum(s2, axis=1)))) #s2 score\n\n(5, 4)\n(6, 4)\n(5, 4)\n(5, 4)\n[[0.1 0.  0.  0. ]\n [0.  0.  0.  0.1]\n [0.1 0.  0.  0. ]\n [0.  0.1 0.  0. ]\n [0.7 0.  0.  0. ]]\n[[0.  0.  0.  0.7]\n [0.7 0.  0.  0. ]\n [0.  0.7 0.  0. ]\n [0.5 0.  0.  0. ]\n [0.7 0.  0.  0. ]]\n[0.1 0.1 0.1 0.1 0.7]\n7.000000000000002e-05\n-9.567015315914915\n-2.119846956314875\n\n\n\n\n\nimage.png",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Machine Learning and Deep Learning</span>"
    ]
  },
  {
    "objectID": "cnu_machine_learning.html#모의-서열-데이터-생성",
    "href": "cnu_machine_learning.html#모의-서열-데이터-생성",
    "title": "6  Machine Learning and Deep Learning",
    "section": "6.3 모의 서열 데이터 생성",
    "text": "6.3 모의 서열 데이터 생성\n\nimport numpy as np\nseq_length = 20\nnum_sample = 1000\n#motif CCGGAA\nmotif_pwm = np.array([[10.41, 22.86, 1.92, 1.55, 98.60, 86.66],\n            [68.20, 65.25, 0.50, 0.35, 0.25, 2.57],\n            [17.27, 8.30, 94.77, 97.32, 0.87, 0.00],\n            [4.13, 3.59, 2.81, 0.78, 0.28, 10.77]])\npwm = np.hstack([np.ones((4, 7)), motif_pwm, np.ones((4, 7))])\npos = np.array([np.random.choice( ['A', 'C', 'G', 'T'], num_sample,\n                                  p=pwm[:,i]/sum(pwm[:,i])) for i in range(seq_length)]).transpose()\nneg = np.array([np.random.choice( ['A', 'C', 'G', 'T'], num_sample,\n                                  p=np.array([1,1,1,1])/4) for i in range(seq_length)]).transpose()\n\nprint(pos.shape)\ndisplay([''.join(x) for x in pos[1:5,]])\nprint()\ndisplay([''.join(x) for x in neg[1:5,]])\n\n(1000, 20)\n\n\n\n['GGATCCGCCGGAACTCCAGT',\n 'GGTCTGGAAGGAATTCTATT',\n 'TTTAAGCGCTGAACCCGCTA',\n 'GGTGGGTCGGGAAATAGTGT']\n\n\n['TCGAAGTTAACTAACGTAGT',\n 'AGACACCCCAAAGGACACCC',\n 'CTACACCGCCAGATTAGAGT',\n 'TTGTAGCTAAAACTTGTGCC']\n\n\n\n6.3.1 DNA 서열 데이터 전처리\n\nbase_dict = {'A':0, 'C':1, 'G':2, 'T':3}\n\n# response variable for pos\nonehot_encode_pos = np.zeros((num_sample, seq_length, 4))\nonehot_encode_pos_label = np.zeros((num_sample, 2), dtype=int)\nonehot_encode_pos_label[:,0] = 1\nprint(onehot_encode_pos_label)\n\n# response variable for pos\nonehot_encode_neg = np.zeros((num_sample, seq_length, 4))\nonehot_encode_neg_label = np.zeros((num_sample, 2), dtype=int)\nonehot_encode_neg_label[:,1] = 1\nprint(onehot_encode_neg_label)\n\n# convert sequence to onehot\nfor i in range(num_sample):\n    for j in range(seq_length):\n        onehot_encode_pos[i,j,base_dict[pos[i,j]]] = 1\n        onehot_encode_neg[i,j,base_dict[neg[i,j]]] = 1\n\n# concatenation\nX = np.vstack((onehot_encode_pos, onehot_encode_neg))\ny = np.vstack((onehot_encode_pos_label, onehot_encode_neg_label))\n\nprint(X.shape, y.shape)\n# (2000, 20, 4) (2000, 2)\n\n[[1 0]\n [1 0]\n [1 0]\n ...\n [1 0]\n [1 0]\n [1 0]]\n[[0 1]\n [0 1]\n [0 1]\n ...\n [0 1]\n [0 1]\n [0 1]]\n(2000, 20, 4) (2000, 2)\n\n\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\n# 데이터를 훈련 세트와 테스트 세트로 나눔\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=125)\nprint(X_train.shape, y_train.shape)\n\n# NumPy 배열을 PyTorch 텐서로 변환\n# PyTorch Conv1d는 입력 데이터가 [batch_size, channels, length]의 형식이므로 transpose(1,2) 적용\nX_train = torch.tensor(X_train, dtype=torch.float32).transpose(1,2)\nX_test = torch.tensor(X_test, dtype=torch.float32).transpose(1,2)\ny_train = torch.tensor(y_train, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.float32)\nprint(y_test.dtype)\n\n# DataLoader 설정\ntrain_dataset = TensorDataset(X_train, y_train)\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nprint(train_loader.dataset.tensors[0].shape)\nprint(train_loader.dataset.tensors[1].shape)\ntest_dataset = TensorDataset(X_test, y_test)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n\n(1600, 20, 4) (1600, 2)\ntorch.float32\ntorch.Size([1600, 4, 20])\ntorch.Size([1600, 2])\n\n\n\nimport torch\n\nX_torch = torch.tensor(X_train, dtype=torch.float32)\nprint(X_torch.shape)\n\ntorch.Size([1600, 4, 20])\n\n\nUserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  X_torch = torch.tensor(X_train, dtype=torch.float32)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Machine Learning and Deep Learning</span>"
    ]
  },
  {
    "objectID": "cnu_machine_learning.html#모델-정의",
    "href": "cnu_machine_learning.html#모델-정의",
    "title": "6  Machine Learning and Deep Learning",
    "section": "6.4 모델 정의",
    "text": "6.4 모델 정의\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass DNA_CNN(nn.Module):\n    def __init__(self):\n        super(DNA_CNN, self).__init__()\n        self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n        self.relu = nn.ReLU()\n        self.maxpool = nn.MaxPool1d(kernel_size=2)\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(160, 64)  # Adjust the input features according to your pooling and conv1d output\n        self.fc2 = nn.Linear(64, 2)  # Adjust according to your problem's needs (e.g., number of classes)\n        #self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        #x = self.softmax(x)\n        return x\n\nmodel = DNA_CNN()\nif torch.cuda.is_available():\n    model.cuda()\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nfrom torchsummary import summary\nsummary(model, input_size=(4, 20))  # (Channels, Length)\n\n----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv1d-1               [-1, 16, 20]             208\n              ReLU-2               [-1, 16, 20]               0\n         MaxPool1d-3               [-1, 16, 10]               0\n           Flatten-4                  [-1, 160]               0\n            Linear-5                   [-1, 64]          10,304\n            Linear-6                    [-1, 2]             130\n================================================================\nTotal params: 10,642\nTrainable params: 10,642\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.04\nEstimated Total Size (MB): 0.05\n----------------------------------------------------------------",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Machine Learning and Deep Learning</span>"
    ]
  },
  {
    "objectID": "cnu_machine_learning.html#훈련",
    "href": "cnu_machine_learning.html#훈련",
    "title": "6  Machine Learning and Deep Learning",
    "section": "6.5 훈련",
    "text": "6.5 훈련\n\n# 훈련 루프\nnum_epochs = 30\nfor epoch in range(num_epochs):\n    for inputs, labels in train_loader:\n        if torch.cuda.is_available():\n            inputs, labels = inputs.cuda(), labels.cuda()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n\nEpoch [1/30], Loss: 0.1160\nEpoch [2/30], Loss: 0.0569\nEpoch [3/30], Loss: 0.0187\nEpoch [4/30], Loss: 0.0166\nEpoch [5/30], Loss: 0.0234\nEpoch [6/30], Loss: 0.0076\nEpoch [7/30], Loss: 0.0254\nEpoch [8/30], Loss: 0.0183\nEpoch [9/30], Loss: 0.0072\nEpoch [10/30], Loss: 0.0288\nEpoch [11/30], Loss: 0.0038\nEpoch [12/30], Loss: 0.0034\nEpoch [13/30], Loss: 0.0458\nEpoch [14/30], Loss: 0.0205\nEpoch [15/30], Loss: 0.0239\nEpoch [16/30], Loss: 0.0199\nEpoch [17/30], Loss: 0.0065\nEpoch [18/30], Loss: 0.0030\nEpoch [19/30], Loss: 0.0073\nEpoch [20/30], Loss: 0.0170\nEpoch [21/30], Loss: 0.0053\nEpoch [22/30], Loss: 0.0029\nEpoch [23/30], Loss: 0.0061\nEpoch [24/30], Loss: 0.0134\nEpoch [25/30], Loss: 0.0137\nEpoch [26/30], Loss: 0.0040\nEpoch [27/30], Loss: 0.0060\nEpoch [28/30], Loss: 0.0024\nEpoch [29/30], Loss: 0.0011\nEpoch [30/30], Loss: 0.0060\n\n\n\n# 모델 평가\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for inputs, labels in test_loader:\n        if torch.cuda.is_available():\n            inputs, labels = inputs.cuda(), labels.cuda()\n        outputs = model(inputs)\n        #print(outputs.data)\n        _, predicted = torch.max(outputs.data, 1)\n        #print(predicted)\n        total += labels.size(0)\n        labels_max = torch.max(labels, 1)[1]\n        #print(labels_max)\n        correct += (predicted == labels_max).sum().item()\n\n    print(f'Accuracy of the model on the test images: {100 * correct / total} %')\n\ntensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n        0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0])\ntensor([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n        0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0])\ntensor([1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n        0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\ntensor([1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n        1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n        0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0])\ntensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n        1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n        0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\ntensor([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n        1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n        0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])\ntensor([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0])\ntensor([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n        0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1])\ntensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n        0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0])\ntensor([0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n        0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0])\ntensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n        1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n        1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1])\ntensor([0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n        1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1])\ntensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1])\ntensor([0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1])\nAccuracy of the model on the test images: 96.5 %\n\n\n\n검증을 위한 데이터 저장, 훈련, 예측 동시 수행\n\n\nimport matplotlib.pyplot as plt\n\n# 데이터 저장을 위한 리스트 초기화\ntrain_losses = []\nval_accuracies = []\n\nnum_epochs = 200\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        if torch.cuda.is_available():\n            inputs, labels = inputs.cuda(), labels.cuda()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * inputs.size(0)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    train_losses.append(epoch_loss)\n\n    # 모델 평가\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            if torch.cuda.is_available():\n                inputs, labels = inputs.cuda(), labels.cuda()\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            labels_max = torch.max(labels, 1)[1]\n            correct += (predicted == labels_max).sum().item()\n\n    epoch_accuracy = 100 * correct / total\n    val_accuracies.append(epoch_accuracy)\n\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n\n# 그래프 그리기\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(train_losses, label='Training Loss')\nplt.title('Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(val_accuracies, label='Validation Accuracy')\nplt.title('Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy (%)')\nplt.legend()\n\nplt.show()\n\nEpoch [1/200], Loss: 0.0022, Accuracy: 96.50%\nEpoch [2/200], Loss: 0.0019, Accuracy: 96.50%\nEpoch [3/200], Loss: 0.0018, Accuracy: 96.50%\nEpoch [4/200], Loss: 0.0017, Accuracy: 96.50%\nEpoch [5/200], Loss: 0.0017, Accuracy: 96.50%\nEpoch [6/200], Loss: 0.0017, Accuracy: 96.75%\nEpoch [7/200], Loss: 0.0018, Accuracy: 96.25%\nEpoch [8/200], Loss: 0.0021, Accuracy: 96.75%\nEpoch [9/200], Loss: 0.0014, Accuracy: 96.75%\nEpoch [10/200], Loss: 0.0015, Accuracy: 96.75%\nEpoch [11/200], Loss: 0.0013, Accuracy: 96.50%\nEpoch [12/200], Loss: 0.0014, Accuracy: 96.75%\nEpoch [13/200], Loss: 0.0014, Accuracy: 96.25%\nEpoch [14/200], Loss: 0.0014, Accuracy: 96.75%\nEpoch [15/200], Loss: 0.0011, Accuracy: 96.50%\nEpoch [16/200], Loss: 0.0011, Accuracy: 96.50%\nEpoch [17/200], Loss: 0.0010, Accuracy: 96.50%\nEpoch [18/200], Loss: 0.0010, Accuracy: 96.75%\nEpoch [19/200], Loss: 0.0010, Accuracy: 96.50%\nEpoch [20/200], Loss: 0.0010, Accuracy: 96.75%\nEpoch [21/200], Loss: 0.0011, Accuracy: 96.75%\nEpoch [22/200], Loss: 0.0010, Accuracy: 96.75%\nEpoch [23/200], Loss: 0.0010, Accuracy: 96.50%\nEpoch [24/200], Loss: 0.0010, Accuracy: 96.50%\nEpoch [25/200], Loss: 0.0010, Accuracy: 96.25%\nEpoch [26/200], Loss: 0.0008, Accuracy: 96.75%\nEpoch [27/200], Loss: 0.0007, Accuracy: 96.75%\nEpoch [28/200], Loss: 0.0007, Accuracy: 96.75%\nEpoch [29/200], Loss: 0.0007, Accuracy: 96.75%\nEpoch [30/200], Loss: 0.0007, Accuracy: 96.75%\nEpoch [31/200], Loss: 0.0007, Accuracy: 96.50%\nEpoch [32/200], Loss: 0.0007, Accuracy: 96.75%\nEpoch [33/200], Loss: 0.0006, Accuracy: 96.75%\nEpoch [34/200], Loss: 0.0006, Accuracy: 96.75%\nEpoch [35/200], Loss: 0.0006, Accuracy: 96.50%\nEpoch [36/200], Loss: 0.0006, Accuracy: 96.50%\nEpoch [37/200], Loss: 0.0006, Accuracy: 96.50%\nEpoch [38/200], Loss: 0.0005, Accuracy: 96.75%\nEpoch [39/200], Loss: 0.0005, Accuracy: 96.50%\nEpoch [40/200], Loss: 0.0005, Accuracy: 96.50%\nEpoch [41/200], Loss: 0.0005, Accuracy: 96.50%\nEpoch [42/200], Loss: 0.0005, Accuracy: 96.50%\nEpoch [43/200], Loss: 0.0005, Accuracy: 96.50%\nEpoch [44/200], Loss: 0.0005, Accuracy: 96.50%\nEpoch [45/200], Loss: 0.0004, Accuracy: 96.75%\nEpoch [46/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [47/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [48/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [49/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [50/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [51/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [52/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [53/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [54/200], Loss: 0.0004, Accuracy: 96.75%\nEpoch [55/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [56/200], Loss: 0.0004, Accuracy: 96.50%\nEpoch [57/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [58/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [59/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [60/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [61/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [62/200], Loss: 0.0003, Accuracy: 96.75%\nEpoch [63/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [64/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [65/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [66/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [67/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [68/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [69/200], Loss: 0.0003, Accuracy: 96.50%\nEpoch [70/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [71/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [72/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [73/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [74/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [75/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [76/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [77/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [78/200], Loss: 0.0002, Accuracy: 96.75%\nEpoch [79/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [80/200], Loss: 0.0002, Accuracy: 96.75%\nEpoch [81/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [82/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [83/200], Loss: 0.0002, Accuracy: 96.75%\nEpoch [84/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [85/200], Loss: 0.0002, Accuracy: 96.75%\nEpoch [86/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [87/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [88/200], Loss: 0.0002, Accuracy: 96.75%\nEpoch [89/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [90/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [91/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [92/200], Loss: 0.0002, Accuracy: 96.50%\nEpoch [93/200], Loss: 0.0001, Accuracy: 96.50%\nEpoch [94/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [95/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [96/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [97/200], Loss: 0.0001, Accuracy: 96.50%\nEpoch [98/200], Loss: 0.0001, Accuracy: 96.50%\nEpoch [99/200], Loss: 0.0001, Accuracy: 96.50%\nEpoch [100/200], Loss: 0.0001, Accuracy: 96.50%\nEpoch [101/200], Loss: 0.0001, Accuracy: 96.50%\nEpoch [102/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [103/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [104/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [105/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [106/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [107/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [108/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [109/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [110/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [111/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [112/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [113/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [114/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [115/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [116/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [117/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [118/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [119/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [120/200], Loss: 0.0001, Accuracy: 97.00%\nEpoch [121/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [122/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [123/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [124/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [125/200], Loss: 0.0001, Accuracy: 96.50%\nEpoch [126/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [127/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [128/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [129/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [130/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [131/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [132/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [133/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [134/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [135/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [136/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [137/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [138/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [139/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [140/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [141/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [142/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [143/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [144/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [145/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [146/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [147/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [148/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [149/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [150/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [151/200], Loss: 0.0001, Accuracy: 96.75%\nEpoch [152/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [153/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [154/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [155/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [156/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [157/200], Loss: 0.0000, Accuracy: 97.00%\nEpoch [158/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [159/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [160/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [161/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [162/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [163/200], Loss: 0.0000, Accuracy: 96.50%\nEpoch [164/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [165/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [166/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [167/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [168/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [169/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [170/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [171/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [172/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [173/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [174/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [175/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [176/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [177/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [178/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [179/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [180/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [181/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [182/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [183/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [184/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [185/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [186/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [187/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [188/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [189/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [190/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [191/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [192/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [193/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [194/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [195/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [196/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [197/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [198/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [199/200], Loss: 0.0000, Accuracy: 96.75%\nEpoch [200/200], Loss: 0.0000, Accuracy: 96.75%",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Machine Learning and Deep Learning</span>"
    ]
  }
]