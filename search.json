[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CNU Deep Learning",
    "section": "",
    "text": "0.1 Welcome",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "CNU Deep Learning",
    "section": "",
    "text": "2024.5 충남대학교, 기계학습 기반 서열 분석 강의 노트\nChatGTP로 기본 contents를 만들고 검토, 보완하며 작성된 노트\n[User] 태그가 붙은 파란색 텍스트가 프롬프트이며 이 후 [ChatGTP] 태그가 GTP (4.0) 답변\nGPT에 질의한 프롬프트는 초안 수준으로 프롬프트를 정교하게 보강해서 질의할 경우 더 높은 수준의 답변을 얻을 수 있음",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "index.html#환경",
    "href": "index.html#환경",
    "title": "CNU Deep Learning",
    "section": "0.2 환경",
    "text": "0.2 환경\n\n실습 환경은 colab을 활용하며 파일 저장 등은 구글 드라이브를 활용함\n본 github repository에서 ipynb 파일을 다운로드 해서 구글 드라이브 임의의 디렉토리에 (2024-cnu-lecture) 복사 후 활용",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Home</span>"
    ]
  },
  {
    "objectID": "cnu_introduction.html",
    "href": "cnu_introduction.html",
    "title": "2  Introduction",
    "section": "",
    "text": "Learn python for biological data analysis with chatGPT\nTask specific practice\n다음 코드는 colab의 default working directory에 개인의 google drive를 연결해 주는 기능을 수행\n\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n\n2.0.1 [User]\n I want to learn python and use it for molecular biology research such as design of library sequence, design of experiments, read high-throughput sequencing file, apply deep learning algorithm. What topics do i need to learn? \n\n\n2.0.2 [ChatGPT]\nLearning Python for molecular biology research involves a blend of general programming skills and domain-specific knowledge. Here’s a structured guide on the topics you need to cover:\n\n\n2.0.3 Table of Contents\n\n2.0.3.1 1. Basic Python Programming\n\nPython Syntax and Semantics: Learn basic syntax, data types (strings, lists, dictionaries), control structures (if statements, loops), functions, and error handling.\nModules and Packages: Understand how to import and use standard libraries and third-party packages.\nFile I/O: Learn how to read from and write to files.\n\n\n\n2.0.3.2 2. Data Handling and Analysis\n\nNumPy: For numerical operations and handling arrays.\nPandas: For data manipulation and analysis, essential for handling tabular data, such as gene expression matrices.\nMatplotlib/Seaborn: For data visualization to generate plots and graphs.\n\n\n\n2.0.3.3 3. Bioinformatics Libraries\n\nBiopython: Essential for biological computation. Learn how to read/write sequence files, perform sequence analysis, and interact with biological databases.\nScikit-bio: For biological analysis including sequence alignment, biodiversity analysis, etc.\n\n\n\n2.0.3.4 4. Sequence Analysis\n\nFASTA/FASTQ Parsing: Learn how to parse sequence files.\nSequence Alignment: Understand the basics of sequence alignment (global and local), and tools like BLAST.\nMotif Finding: Learn how to identify sequence motifs.\n\n\n\n2.0.3.5 5. High-Throughput Sequencing Data\n\nHTSeq: For reading and analyzing high-throughput sequencing data.\nPySAM: For reading and manipulating SAM/BAM files (aligned sequencing reads).\nSeqIO: Part of Biopython for input/output of sequence data.\n\n\n\n2.0.3.6 6. Experimental Design\n\nPrimer Design: Understand the principles of primer design and tools available (like Primer3) and their Python interfaces.\nGolden Gate Assembly and Gibson Assembly: Learn the principles and how to design experiments programmatically.\n\n\n\n2.0.3.7 7. Statistical Analysis\n\nSciPy: For scientific and technical computing.\nStatsmodels: For statistical modeling.\nR Integration: Learn how to use R from Python (via rpy2) if you need to use specific R packages for statistical analysis.\n\n\n\n2.0.3.8 8. Machine Learning and Deep Learning\n\nScikit-learn: For machine learning algorithms.\nTensorFlow/Keras or PyTorch: For deep learning.\nBioinformatics-specific models: Learn about models specific to bioinformatics, such as predicting protein structures or gene expression levels.\n\n\n\n2.0.3.9 9. Workflow Automation\n\nSnakemake: For workflow management.\nNextflow: Another workflow management tool, useful for reproducible research.\n\n\n\n2.0.3.10 10. Advanced Topics\n\nData Integration: Integrating different types of biological data (genomic, transcriptomic, proteomic).\nNetwork Biology: Understanding biological networks (e.g., protein-protein interaction networks).\nStructural Bioinformatics: Analyzing protein structures using tools like PyMOL.\n\n\n\n2.0.3.11 Learning Resources\n\nBooks\n\n“Python for Biologists” by Martin Jones\n“Bioinformatics Programming Using Python” by Mitchell L. Model\n\nOnline Courses\n\nCoursera: “Python for Genomic Data Science” by Johns Hopkins University\nedX: “Python for Data Science” by Microsoft\nBiostars: Online forum for bioinformatics questions and tutorials.\n\nTutorials and Documentation\n\nBiopython Tutorial and Cookbook: Comprehensive guide to using Biopython.\nNumPy and Pandas documentation: Essential for data manipulation.\nScikit-learn and TensorFlow/Keras documentation: For machine learning and deep learning.\n\n\nBy following this structured guide, you’ll be able to leverage Python effectively for molecular biology research.\n\n\n\n2.0.4 [User]\n I’ll learn it using google colab. can you let me know how to setup the colab environment for this learning \n\n\n2.0.5 [ChatGPT]\nCertainly! Google Colab is an excellent platform for learning and running Python code, especially for bioinformatics. It provides a cloud-based Jupyter notebook environment that comes pre-configured with many scientific libraries. Here’s how to set up and use Google Colab for learning bioinformatics with Python:\n\n\n2.0.6 Step-by-Step Guide to Setting Up Google Colab\n\n2.0.6.1 1. Access Google Colab\n\nGo to Google Colab in your web browser.\nSign in with your Google account.\n\n\n\n2.0.6.2 2. Create a New Notebook\n\nClick on File -&gt; New Notebook to create a new notebook.\n\n\n\n2.0.6.3 3. Install Required Libraries\nGoogle Colab comes with many libraries pre-installed, but you might need to install some additional ones, such as biopython and scikit-bio. You can do this using the !pip install command directly in a cell.\n\n!pip install biopython scikit-bio\n\n\n\n2.0.6.4 4. Import Libraries and Verify Installation\nIn a new code cell, import the libraries to ensure they are installed correctly.\n\n# Importing necessary libraries\nimport Bio\nimport skbio\n\nprint(\"Biopython version:\", Bio.__version__)\nprint(\"scikit-bio version:\", skbio.__version__)\n\nBiopython version: 1.83\nscikit-bio version: 0.6.0\n\n\n\n\n2.0.6.5 5. Upload Files to Colab\n\n구글 드라이브에 2024-cnu-lecture 폴더를 만들기\n다운로드 하거나 공유된 (ipynb) 파일을 2024-cnu-lecture 폴더에 복사후 colab으로 open\n분석을 위한 ganbank 파일 ncbi에서 다운로드\n구글 드라이브의 위 디렉토리에 genbank 파일 복사 또는 다음 코드로 로컬 파일을 업로드 가능\n현재 작업 디렉토리 확인\n\n\n!pwd\n\n\n현재 작업 디렉토리를 위 생성한 디렉토리로 변경\n\n\nimport os\nos.chdir('drive/MyDrive/2024-cnu-lecture')\n\n\n!pwd\n\n\n분석을 위한 genbank 등의 파일을 ncbi에서 다운로드 후 위 폴더에 복사\n또는 아래 코드를 이용해서 현재 작업 디렉토리에 업로드\n\n\nfrom google.colab import files\n\nuploaded = files.upload()\n\n# Listing the uploaded files\nfor filename in uploaded.keys():\n    print(filename)\n\n\n\n\nimage.png\n\n\n\n\n2.0.6.6 6. Example: Reading a GenBank File and Analyzing Sequences\n\nHere’s an example workflow that reads a GenBank file, performs sequence analysis with Biopython, and aligns sequences with scikit-bio:\n위에서 다운로드 받은 genbank 파일을 egfp.gb 이름으로 변경 후 업로드\n아래 예시 코드는 단백질 서열을 읽고 비교하는 코드임\n\n\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\nfrom skbio import Protein\nfrom skbio.alignment import global_pairwise_align_protein\n\n# Assuming the uploaded GenBank file is named 'example.gb'\ngenbank_file = 'data/egfp.gb'\n\n# Read a protein sequence from a GenBank file\nrecord = SeqIO.read(genbank_file, \"genbank\")\nprint(len(record.seq))\n\nprotein_seq = record.seq.translate()\nprint(protein_seq)\n\n# Perform alignment with another protein sequence\nseq1 = Protein(str(protein_seq))\nseq2 = Protein(\"MKVLYNLKDG\")\n\nalignment, score, start_end_positions = global_pairwise_align_protein(seq1, seq2)\n\nprint(\"Alignment:\\n\", alignment)\nprint(\"Score:\", score)\nprint(\"Start-End Positions:\", start_end_positions)\n\n1150\nMSRVSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLTYGVQCFSRYPDHMKQHDFFKSAMPEGYVQEVDLCILLS*EVELFPFCVLQLQMEIHRDTRGFCLVLSFVLVVN*KFIHLQEINSLLFKSKGLTYVSVKHWIPKNSKMR*GIFNLVWTSNRLG*PPVKLQQDCLLTQCLRSDVQ*LVLFHFALDFLFANELCF*WFSLFWCVENHLLQGRRQLQDPRRGEVRGRHPGEPHRAEGHRLQGGRQHPGAQAGVQLQQPQRLYHGRQAEERHQGELQDPPQHRGRQRAARRPLPAEHPHRRRPRAAARQPLPEHPVRPEQRPQREARSHGPAGVRDRRRDHSRHGRAVQV\nAlignment:\n TabularMSA[Protein]\n-----------------------------------------------------------------------\nStats:\n    sequence count: 2\n    position count: 384\n-----------------------------------------------------------------------\nMSRVSKGEELFTGVVPILVEL-DGDVNGHKFSV ... PEQRPQREARSHGPAGVRDRRRDHSRHGRAVQV\n--------------MKVLYNLKDG--------- ... ---------------------------------\nScore: 18.0\nStart-End Positions: [(0, 382), (0, 9)]\n\n\n/home/haseong/anaconda3/envs/biopy/lib/python3.11/site-packages/Bio/Seq.py:2880: BiopythonWarning: Partial codon, len(sequence) not a multiple of three. Explicitly trim the sequence or add trailing N before translation. This may become an error in future.\n  warnings.warn(\n/home/haseong/anaconda3/envs/biopy/lib/python3.11/site-packages/skbio/alignment/_pairwise.py:538: EfficiencyWarning: You're using skbio's python implementation of Needleman-Wunsch alignment. This is known to be very slow (e.g., thousands of times slower than a native C implementation). We'll be adding a faster version soon (see https://github.com/scikit-bio/scikit-bio/issues/254 to track progress on this).\n  warn(\n\n\n\n\n2.0.6.7 7. Saving Your Work\nYou can save your notebook to Google Drive:\n\nClick on File -&gt; Save a copy in Drive.\n\n\n\n2.0.6.8 8. Sharing Your Notebook\nYou can share your notebook with others by clicking on the Share button in the top right corner and setting the appropriate sharing permissions.\n\n\n2.0.6.9 9. Example Colab Notebook\nHere’s a more comprehensive example notebook that includes reading files, sequence analysis, and visualization: (다음 코드 참고)\nThis notebook covers: - Installing and importing bioinformatics libraries. - Uploading and reading files. - Performing sequence analysis. - Visualizing data.\nBy following these steps and examples, you’ll be well-prepared to use Google Colab for your bioinformatics learning and research.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Example data for visualization\ndata = {\n    'Sequence': ['Seq1', 'Seq2', 'Seq3'],\n    'GC_Content': [50, 55, 45],\n    'Length': [20, 22, 18]\n}\n\n# Visualize using Seaborn\ndf = pd.DataFrame(data)\nsns.histplot(df['GC_Content'], kde=True)\nplt.title('GC Content Distribution')\nplt.xlabel('GC Content (%)')\nplt.show()\n\nsns.boxplot(x=df['Length'])\nplt.title('Sequence Length Distribution')\nplt.xlabel('Length (bp)')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html",
    "href": "cnu_basic.html",
    "title": "3  Python Basics",
    "section": "",
    "text": "3.0.0.1 구글 드라이브 연결\n!pwd\nfrom google.colab import drive\nimport os\n\ndrive.mount('/content/drive')\nos.chdir('drive/MyDrive/2024-cnu-lecture')\n!pwd",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#파이썬-함수-모듈-클래스",
    "href": "cnu_basic.html#파이썬-함수-모듈-클래스",
    "title": "3  Python Basics",
    "section": "3.1 파이썬 함수, 모듈, 클래스",
    "text": "3.1 파이썬 함수, 모듈, 클래스\n\n3.1.1 함수\n\n리스트 값 평균 리턴하는 함수\n\n\ndef average(input):\n    if len(input) == 0:\n        return None\n    return sum(input) / len(input)\n\nx = [1,2,3,4,5,6,7,8,9,10]\nprint(average(x))\n\n5.5\n\n\n\n\n3.1.2 모듈\n\n위 average 함수를 mystat.py 라는 이름의 파일로 저장, 모듈로 활용\n\n\n#import mystat\n#x = list(range(10))\n#print(mystat.average(x))\n\n\n모듈 직접 실행시 모듈 내 test 코드 실행 (name == main, True)\n\n\n#%run mystat\n\n\n모듈 임포트\n\n\nimport os\nos.getcwd()\n\n'/home/haseong/lecture/cnu-deeplearning-2024'\n\n\n\nfrom os import getcwd\ngetcwd()\n\n'/home/haseong/lecture/cnu-deeplearning-2024'\n\n\n\n\n3.1.3 클래스\n\nGene, Strain class 생성 연습\nGene attribute: name, chromosomal location, length\n\nStrain attribute (변수): name, length of chromosome\n\nStrain method (함수): compute average length of the genes\n\n\nimport statistics\nclass ORF:\n    def __init__(self, location, length, seq):\n        self.location = location\n        self.length = length\n        self.sequence = seq\n\nclass Strain:\n    def __init__(self, name, chrlength):\n        self.name = name\n        self.chr_length = chrlength\n        self.orfs = []\n    def add_orf(self, location, length, seq):\n        self.orfs.append(ORF(location, length, seq))\n    def orf_length_average(self):\n        return statistics.mean([s.length for s in self.orfs])\n\n\necoli = Strain(\"ecoli\", 5000000)\necoli.add_orf(1, 1000, \"ATG\")\necoli.add_orf(1001, 2000, \"CCT\")\necoli.add_orf(2001, 3000, \"ATC\")\n\n\nprint([g.location for g in ecoli.orfs])\nprint([g.sequence for g in ecoli.orfs])\necoli.orf_length_average()\n\n[1, 1001, 2001]\n['ATG', 'CCT', 'ATC']\n\n\n2000\n\n\n\n상속\n\n\nclass Gene(ORF):\n    def add_protein(self, prot_name, prot_seq):\n        self.prot_name = prot_name\n        self.prot_sequence = prot_seq\n        \n\n\ngene1 = Gene(1, 1000, \"ATG\")\nprint(gene1.location)\ngene1.add_protein(\"myprotein\", \"M\")\nprint(gene1.prot_name)\n\n1\nmyprotein",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_basic.html#example-synonymous-mutant-library-generation",
    "href": "cnu_basic.html#example-synonymous-mutant-library-generation",
    "title": "3  Python Basics",
    "section": "3.2 Example: Synonymous Mutant Library Generation",
    "text": "3.2 Example: Synonymous Mutant Library Generation\n\n3.2.1 [User]\n I want to generate mutant library of a protein. I have a nucleotide genbank file for the target protein. I wan to generate all the mutants by changing synonymous codons for each residue. can you give me the python code?\n\n\n\n3.2.2 [ChatGPT]\nCertainly! To generate a mutant library by changing synonymous codons for each residue of a protein, we’ll need to:\n\nRead the nucleotide sequence from a GenBank file.\nTranslate the nucleotide sequence to a protein sequence.\nIdentify synonymous codons for each amino acid.\nGenerate all possible synonymous mutants for the target protein.\n\nHere is the Python code that accomplishes these tasks:\n\n이 예제는 위 프롬프트로 ChatGPT가 만든 코드입니다\n\n\n3.2.2.1 Install Necessary Libraries\nMake sure you have Biopython installed:\n\n!pip install biopython\n\n\n\n3.2.2.2 Python Script to Generate Synonymous Mutant Library\n\nfrom Bio import SeqIO\nfrom Bio.Seq import Seq\nfrom itertools import product\n\n# Synonymous codon table\nsynonymous_codons = {\n    'F': ['TTT', 'TTC'],\n    'L': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'],\n    'I': ['ATT', 'ATC', 'ATA'],\n    'M': ['ATG'],\n    'V': ['GTT', 'GTC', 'GTA', 'GTG'],\n    'S': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'],\n    'P': ['CCT', 'CCC', 'CCA', 'CCG'],\n    'T': ['ACT', 'ACC', 'ACA', 'ACG'],\n    'A': ['GCT', 'GCC', 'GCA', 'GCG'],\n    'Y': ['TAT', 'TAC'],\n    'H': ['CAT', 'CAC'],\n    'Q': ['CAA', 'CAG'],\n    'N': ['AAT', 'AAC'],\n    'K': ['AAA', 'AAG'],\n    'D': ['GAT', 'GAC'],\n    'E': ['GAA', 'GAG'],\n    'C': ['TGT', 'TGC'],\n    'W': ['TGG'],\n    'R': ['CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'],\n    'G': ['GGT', 'GGC', 'GGA', 'GGG'],\n    '*': ['TAA', 'TAG', 'TGA']\n}\n\n# Function to read the GenBank file and extract the coding sequence\ndef read_cds_from_genbank(file_path):\n    record = SeqIO.read(file_path, \"genbank\")\n    for feature in record.features:\n        if feature.type == \"CDS\":\n            return feature.location.extract(record).seq\n    raise ValueError(\"No CDS found in the GenBank file.\")\n\n# Function to generate synonymous mutants\ndef generate_synonymous_mutants(cds_seq):\n    protein_seq = cds_seq.translate()\n    codon_options = []\n\n    for aa in protein_seq[:5]:\n        codons = synonymous_codons.get(aa, [])\n        if not codons:\n            raise ValueError(f\"Unknown amino acid {aa} encountered.\")\n        codon_options.append(codons)\n\n    # Generate all combinations of synonymous codons\n    all_mutants = list(product(*codon_options))\n    return [''.join(mutant) for mutant in all_mutants]\n\n# Main function\ndef main(genbank_file, output_file):\n    cds_seq = read_cds_from_genbank(genbank_file)\n    mutants = generate_synonymous_mutants(cds_seq)\n\n    # Write the mutants to a FASTA file\n    with open(output_file, 'w') as f:\n        for i, mutant in enumerate(mutants):\n            f.write(f\"&gt;Mutant_{i+1}\\n{mutant}\\n\")\n\n# Example usage\ngenbank_file = 'data/egfp.gb'  # Replace with your GenBank file path\noutput_file = 'mutant_library.fasta'\nmain(genbank_file, output_file)\n\n\n위 코드를 두 개의 파일로 나누어 (함수모음 파일, 실행 파일) 모듈 실습 가능",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Python Basics</span>"
    ]
  },
  {
    "objectID": "cnu_data_handling.html",
    "href": "cnu_data_handling.html",
    "title": "4  Data handling",
    "section": "",
    "text": "구글 드라이브 연결\n\n!pwd\n\n/home/haseong/lecture/cnu-deeplearning-2024\n\n\n\nfrom google.colab import drive\nimport os\n\ndrive.mount('/content/drive')\nos.chdir('drive/MyDrive/2024-cnu-lecture')\n\n\n!pwd\n\n\n4.0.1 [User]\n I want to learn “2. Data Handling and Analysis”. can you explain me a brief explanation and examples? \n\n\n4.0.2 [ChatGPT]\nSure! Data handling and analysis are essential skills in Python, especially for tasks like manipulating datasets, performing statistical analyses, and creating visualizations. We’ll focus on the key libraries used for these purposes: NumPy, Pandas, and Matplotlib/Seaborn.\n\n\n4.0.3 1. NumPy\nNumPy is a powerful library for numerical operations and handling arrays.\n\n4.0.3.1 Basics of NumPy\nInstallation:\n!pip install numpy\n\nimport numpy as np\n\n\n# Creating a 1D array\narr1 = np.array([1, 2, 3, 4, 5])\n\n# Creating a 2D array\narr2 = np.array([[1, 2, 3], [4, 5, 6]])\n\nprint(arr1)\nprint(arr2)\n\n\n# Element-wise operations\narr3 = arr1 * 2\nprint(arr3)\n\n# Mathematical functions\nprint(np.sqrt(arr1))\n\n[1 2 3 4 5]\n[[1 2 3]\n [4 5 6]]\n[ 2  4  6  8 10]\n[1.         1.41421356 1.73205081 2.         2.23606798]\n\n\n\n\n4.0.3.2 Numpy 자료구조 ndarray\n\n행렬이나 다차원 배열 처리용 파이썬 라이브러리\n같은 타입의 데이터만 허용\n리스트에 비해 20배 이상 빠른 속도\n\n\n\n\nfrom https://www.oreilly.com/library/view/elegant-scipy/9781491922927/ch01.html\n\n\n\nnumpy 객체 만들기\n\n\nimport numpy as np\n\narr = [1, 2, 3]\nprint(arr)\nprint(type(arr))\n\na = np.array([1,2,3])\nprint(a)\nprint(a.dtype)\nprint(a.shape)\nprint(type(a))\n\n[1, 2, 3]\n&lt;class 'list'&gt;\n[1 2 3]\nint64\n(3,)\n&lt;class 'numpy.ndarray'&gt;\n\n\n\narr2 = np.array([[1,2,3], [4,5,6]])\nprint(arr2)\nprint(type(arr2))\nprint(arr2.shape)\nprint(arr2.dtype)\n\n[[1 2 3]\n [4 5 6]]\n&lt;class 'numpy.ndarray'&gt;\n(2, 3)\nint64\n\n\n\nnumpy 자료형\n\n부호가 있는 정수 int(8, 16, 32, 64)\n부호가 없는 정수 uint(8 ,16, 32, 54)\n실수 float(16, 32, 64, 128)\n복소수 complex(64, 128, 256)\n불리언 bool\n문자열 string_\n파이썬 오프젝트 object\n유니코드 unicode_\n\nnp.zeros(), np.ones(), np.arange()\n행렬 연산 지원\n\n\na = np.arange(1, 10).reshape(3,3) # [1, 10)\nprint(a)\na = np.ones((3,4), dtype=np.int16)\nb = np.ones((3,4), dtype=np.int16)\nprint(a)\nprint(b)\nprint(a+b)\nprint(a-b)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n[[1 1 1 1]\n [1 1 1 1]\n [1 1 1 1]]\n[[1 1 1 1]\n [1 1 1 1]\n [1 1 1 1]]\n[[2 2 2 2]\n [2 2 2 2]\n [2 2 2 2]]\n[[0 0 0 0]\n [0 0 0 0]\n [0 0 0 0]]\n\n\n\nnumpy 함수\n\nnp.sqrt()\nnp.log()\nnp.square()\nnp.log()\nnp.ceil()\nnp.floor()\nnp.isnan()\nnp.sum()\nnp.mean()\nnp.std()\nnp.min()\n\n\n\ndir(np)\n\n\n\n\n4.0.4 2. Pandas\nPandas is a powerful library for data manipulation and analysis. It provides data structures like DataFrame, which is similar to tables in databases or spreadsheets.\n\n4.0.4.1 Installation\npip install pandas\n\nPandas의 Series는 1차원, DataFrame은 2차원 데이터를 다루는 자료구조\nDataFrames are the primary data structure in pandas, representing tabular data with rows and columns.\nindex, column, values 로 이루어짐\n리스트와 딕셔너리로부터 생성 가능\n숫자형, 문자형, 범주형 등의 다양한 데이터 입력 가능\n\n\n\n\nalt text\n\n\n\nfrom pandas import Series, DataFrame\n\n\ngenes = Series([0.1, 0.2, 1.4, 0.6, 1.1])\nprint(genes)\n\n0    0.1\n1    0.2\n2    1.4\n3    0.6\n4    1.1\ndtype: float64\n\n\n\ngenes = Series([0.1, 0.2, 1.4, 0.6, 1.1], index=['A', 'B', 'C', 'D', 'E'])\nprint(genes)\n\nA    0.1\nB    0.2\nC    1.4\nD    0.6\nE    1.1\ndtype: float64\n\n\n\n\n4.0.4.2 Make a DataFrame\n\nCreate from a list\n\n\nimport pandas as pd\n\ndf = pd.DataFrame([[0, 4, 5], [0, 6, 7], [20, 30, 40]],\n                  index=[1, 2, 3], columns=['P', 'Q', 'R'])\n\nprint(df)\n\n    P   Q   R\n1   0   4   5\n2   0   6   7\n3  20  30  40\n\n\n\nCreate dataframe from a dictionary\n\n\n\n\nalt text\n\n\n\nimport pandas as pd\n\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie'],\n    'Age': [25, 30, 35],\n    'Height': [5.5, 6.0, 5.8]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\nCreate from a list of dictionary\n\n\n\n\nalt text\n\n\n\ndata = [\n    {'Name': 'Alice', 'Age': 25, 'Height': 5.5},\n    {'Name': 'Bob', 'Age': 30, 'Height': 6.0},\n    {'Name': 'Charlie', 'Age': 35, 'Height': 5.8}\n]\n\ndf = pd.DataFrame(data)\nprint(df)\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\nCreate from Series\n\n\ngenes = {'A': [0.5, 0.1, 0.3],\n         'B': [0.8, 0.9, 0.4]}\nprint(genes)\ngenes_df = DataFrame(genes)\nprint(genes_df)\nprint(genes_df['A'])\nprint(type(genes_df['A']))\n\n\ngenes_df = DataFrame(genes, columns=['B', 'A'], index=['day1', 'day2', 'day3'])\nprint(genes_df)\n\n{'A': [0.5, 0.1, 0.3], 'B': [0.8, 0.9, 0.4]}\n     A    B\n0  0.5  0.8\n1  0.1  0.9\n2  0.3  0.4\n0    0.5\n1    0.1\n2    0.3\nName: A, dtype: float64\n&lt;class 'pandas.core.series.Series'&gt;\n        B    A\nday1  0.8  0.5\nday2  0.9  0.1\nday3  0.4  0.3\n\n\n\n\n4.0.4.3 Dataframe operations\n\ndata = [\n    {'Name': 'Alice', 'Age': 25, 'Height': 5.5},\n    {'Name': 'Bob', 'Age': 30, 'Height': 6.0},\n    {'Name': 'Charlie', 'Age': 35, 'Height': 5.8}\n]\n\ndf = pd.DataFrame(data)\nprint(df)\n\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\n# Selecting columns\nages = df['Age']\nprint(ages)\n\n# Filtering rows\nadults = df[df['Age'] &gt; 18]\nprint(adults)\n\n# Adding a new column\ndf['Weight'] = [65, 70, 75]\nprint(df)\n\n# Grouping and Aggregating\ngrouped = df.groupby('Name').mean()\nprint(grouped)\n\n0    25\n1    30\n2    35\nName: Age, dtype: int64\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n      Name  Age  Height  Weight\n0    Alice   25     5.5      65\n1      Bob   30     6.0      70\n2  Charlie   35     5.8      75\n          Age  Height  Weight\nName                         \nAlice    25.0     5.5    65.0\nBob      30.0     6.0    70.0\nCharlie  35.0     5.8    75.0\n\n\n\n인덱스 자동 정렬, 행렬 연산\n\n\ngenes1 = Series([0.1, 0.2, 1.4, 0.6, 1.1], index=['A', 'B', 'C', 'D', 'E'])\ngenes2 = Series([0.1, 0.2, 1.4, 0.6, 1.1], index=['B', 'C', 'D', 'E', 'A'])\ngenes1 + genes2\n\nA    1.2\nB    0.3\nC    1.6\nD    2.0\nE    1.7\ndtype: float64\n\n\n\nprint(genes2.sort_values())\nprint(genes2.sort_index())\n\nB    0.1\nC    0.2\nE    0.6\nA    1.1\nD    1.4\ndtype: float64\nA    1.1\nB    0.1\nC    0.2\nD    1.4\nE    0.6\ndtype: float64\n\n\n\ngenes = {'A': [0.5, 0.1, 0.3],\n         'B': [0.8, 0.9, 0.4]}\n\ngenes_df = DataFrame(genes, columns=['B', 'A'], index=['day1', 'day2', 'day3'])\nprint(genes)\nprint(genes_df)\n\n{'A': [0.5, 0.1, 0.3], 'B': [0.8, 0.9, 0.4]}\n        B    A\nday1  0.8  0.5\nday2  0.9  0.1\nday3  0.4  0.3\n\n\n\nprint(genes_df['A'])\nprint(genes_df.loc['day1'])\nprint(genes_df.index)\nprint(list(genes_df.columns))\n\nday1    0.5\nday2    0.1\nday3    0.3\nName: A, dtype: float64\nB    0.8\nA    0.5\nName: day1, dtype: float64\nIndex(['day1', 'day2', 'day3'], dtype='object')\n['B', 'A']\n\n\n\n\n\n4.0.5 3. Matplotlib/Seaborn\nMatplotlib is a plotting library for creating static, animated, and interactive visualizations. Seaborn is built on top of Matplotlib and provides a high-level interface for drawing attractive statistical graphics.\nInstallation:\npip install matplotlib seaborn\n\nimport matplotlib.pyplot as plt\n\n# Line plot\nplt.plot([1, 2, 3, 4], [1, 4, 9, 16])\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.title('Line Plot')\nplt.show()\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndata = [\n    {'Name': 'Alice', 'Age': 25, 'Height': 5.5},\n    {'Name': 'Bob', 'Age': 30, 'Height': 6.0},\n    {'Name': 'Charlie', 'Age': 35, 'Height': 5.8}\n]\n\ndf = pd.DataFrame(data)\nprint(df)\n\n# Scatter plot with Seaborn\nsns.scatterplot(x='Age', y='Height', data=df)\nplt.title('Age vs Height')\nplt.show()\n\n      Name  Age  Height\n0    Alice   25     5.5\n1      Bob   30     6.0\n2  Charlie   35     5.8\n\n\n\n\n\n\n\n\n\n\ndir(sns)\n\n\n\n4.0.6 Example: Analyzing and Visualizing DNA Sequence Data\n\n\n\nalt text\n\n\n\n\n\nalt text\n\n\n\n4.0.6.1 [User]\n I have downloaded a fasta file containing 800 esterase nucleotide sequences. the file is saved at “data/esterase.fa”. can you provide a python code that can read the sequences and compute their length and GC contents ratio? \n\n\n4.0.6.2 [ChatGPT]\nCertainly! To read a FASTA file containing 800 esterase nucleotide sequences and compute their lengths and GC content ratios, you can use the Biopython library. Here is a Python script that accomplishes this:\nInstallation\nFirst, make sure you have Biopython installed:\npip install biopython\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Function to compute sequence length and GC content\ndef compute_sequence_stats(seq):\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    return length, gc_content\n\n# Read the FASTA file and process each sequence\ndef process_fasta_file(file_path):\n    records = SeqIO.parse(file_path, \"fasta\")\n    esterase_stats = []\n\n    for record in records:\n        length, gc_content = compute_sequence_stats(record.seq)\n        esterase_stats.append({\n            \"ID\": record.id,\n            \"Length\": length,\n            \"GC_Content\": gc_content\n        })\n\n    return esterase_stats\n\n# Example usage\nfasta_file = 'data/esterases.fasta'  # Replace with your FASTA file path\nesterase_stats = process_fasta_file(fasta_file)\n\n# Print the results\nfor esterase in esterase_stats:\n    print(f\"ID: {esterase['ID']}, Length: {esterase['Length']} bp, GC Content: {esterase['GC_Content']:.2f}%\")\n\n\n\n4.0.6.3 [User]\n I want to store the result above in a file with json csv format. Than I need a code to read the file and convert the data in a DataFrame format. \n\n\n4.0.6.4 [ChatGPT]\nSure! Let’s modify the script to store the results in both JSON and CSV formats. Then, we’ll write a separate script to read these files and convert the data into a Pandas DataFrame.\n\nimport json\nimport csv\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Function to compute sequence length and GC content\ndef compute_sequence_stats(seq):\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    return length, gc_content\n\n# Read the FASTA file and process each sequence\ndef process_fasta_file(file_path):\n    records = SeqIO.parse(file_path, \"fasta\")\n    esterase_stats = []\n\n    for record in records:\n        length, gc_content = compute_sequence_stats(record.seq)\n        esterase_stats.append({\n            \"ID\": record.id,\n            \"Length\": length,\n            \"GC_Content\": gc_content\n        })\n\n    return esterase_stats\n\n# Save results to JSON and CSV\ndef save_results(esterase_stats, json_file, csv_file):\n    # Save to JSON\n    with open(json_file, 'w') as jf:\n        json.dump(esterase_stats, jf, indent=4)\n\n    # Save to CSV\n    with open(csv_file, 'w', newline='') as cf:\n        writer = csv.DictWriter(cf, fieldnames=['ID', 'Length', 'GC_Content'])\n        writer.writeheader()\n        for esterase in esterase_stats:\n            writer.writerow(esterase)\n\n# Example usage\nfasta_file = 'data/esterases.fasta'  # Replace with your FASTA file path\njson_file = 'data/esterase_stats.json'\ncsv_file = 'data/esterase_stats.csv'\n\nesterase_stats = process_fasta_file(fasta_file)\nsave_results(esterase_stats, json_file, csv_file)\n\nprint(f\"Results saved to {json_file} and {csv_file}\")\n\nResults saved to data/esterase_stats.json and data/esterase_stats.csv\n\n\n\nimport pandas as pd\nimport json\n\n# Load data from JSON file\nwith open('data/esterase_stats.json', 'r') as jf:\n    esterase_stats_json = json.load(jf)\n\n# Convert to DataFrame\ndf_json = pd.DataFrame(esterase_stats_json)\nprint(\"DataFrame from JSON file:\")\nprint(df_json.head())\n\n# Load data from CSV file\ndf_csv = pd.read_csv('data/esterase_stats.csv')\nprint(\"DataFrame from CSV file:\")\nprint(df_csv.head())\n\nDataFrame from JSON file:\n                     ID  Length  GC_Content\n0            EU240725.1     240   50.833333\n1  NZ_JBBEZD010000544.1     387   48.062016\n2  NZ_JADOYP010000246.1     234   55.982906\n3  NZ_JAJAQZ010000712.1     252   52.777778\n4  NZ_JABFYM010000640.1     769   52.405722\nDataFrame from CSV file:\n                     ID  Length  GC_Content\n0            EU240725.1     240   50.833333\n1  NZ_JBBEZD010000544.1     387   48.062016\n2  NZ_JADOYP010000246.1     234   55.982906\n3  NZ_JAJAQZ010000712.1     252   52.777778\n4  NZ_JABFYM010000640.1     769   52.405722\n\n\n\n\n4.0.6.5 [User]\n I want a python code that display the statistics of the GC distribution and boxplot of the length. \n\n\n4.0.6.6 [ChatGPT]\nSure! Let’s create a Python script that reads the data from the previously saved JSON or CSV file, computes statistics for the GC content distribution, and generates a boxplot for the sequence lengths using Pandas and Matplotlib.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load data from CSV file\ndf = pd.read_csv('data/esterase_stats.csv')\n\n# Compute statistics for GC content distribution\ngc_stats = df['GC_Content'].describe()\nprint(\"GC Content Distribution Statistics:\")\nprint(gc_stats)\n\n# Generate a histogram for GC content distribution\nplt.figure(figsize=(10, 6))\nsns.histplot(df['GC_Content'], bins=30, kde=True)\nplt.title('GC Content Distribution')\nplt.xlabel('GC Content (%)')\nplt.ylabel('Frequency')\nplt.show()\n\n# Generate a boxplot for sequence lengths\nplt.figure(figsize=(10, 6))\nsns.boxplot(x=df['Length'])\nplt.title('Boxplot of Sequence Lengths')\nplt.xlabel('Sequence Length (bp)')\nplt.show()\n\nGC Content Distribution Statistics:\ncount    355.000000\nmean      51.362399\nstd        5.551809\nmin       29.739777\n25%       50.052780\n50%       51.901566\n75%       54.322222\nmax       75.683891\nName: GC_Content, dtype: float64\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScript\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\n\nfor record in results:\n    print(record.id)\n    print(record.seq)\n    print(gc_fraction(record.seq))\n\nprint(results)\n\n\nCalculate\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\n\nfor record in results:\n    seq = record.seq\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    print(f\"ID: {record.id}, Length: {length} bp, GC Content: {gc_content:.2f}%\")\n    \n\n\nstore in a list\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\nimport pandas as pd\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\nesterase_stats = []\n\nfor record in results:\n    seq = record.seq\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    esterase_stats.append({\n        \"ID\": record.id,\n        \"Length\": length,\n        \"GC_Content\": gc_content\n    })\n\nprint(esterase_stats) \npd.DataFrame(esterase_stats)\n\n\nmake a function\n\n\nfrom Bio import SeqIO\nfrom Bio.SeqUtils import gc_fraction\nimport pandas as pd\n\n# Read a FASTA file\nfasta_file = 'data/esterases.fasta'\nresults = SeqIO.parse(fasta_file, 'fasta')\nesterase_stats = []\n\n# Function to compute sequence length and GC content\ndef compute_sequence_stats(seq):\n    length = len(seq)\n    gc_content = gc_fraction(seq) * 100  # Convert to percentage\n    return length, gc_content\n\n\nfor record in results:\n    seq = record.seq\n    length, gc_content = compute_sequence_stats(seq)\n    esterase_stats.append({\n        \"ID\": record.id,\n        \"Length\": length,\n        \"GC_Content\": gc_content\n    })\n\nprint(esterase_stats) \npd.DataFrame(esterase_stats)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data handling</span>"
    ]
  }
]