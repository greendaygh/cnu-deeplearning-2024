{"cells":[{"cell_type":"markdown","metadata":{"id":"eTxnC0miCqp8"},"source":["# Deep Learning"]},{"cell_type":"code","execution_count":128,"metadata":{"executionInfo":{"elapsed":591,"status":"ok","timestamp":1718610653246,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"x_X31eCn6brR"},"outputs":[],"source":["import os\n","\n","os.chdir('drive/MyDrive/2024-cnu-lecture')"]},{"cell_type":"markdown","metadata":{"id":"XaaWabJA9LG5"},"source":["## Convolutional Neual Network "]},{"cell_type":"markdown","metadata":{"id":"-GCLngU-9xg1"},"source":["- 딥러닝 기반 DNA 서열 분석 가이드\n","- http://www.btnews.or.kr/bbs/board.php?bo_table=bt_news&wr_id=342"]},{"cell_type":"markdown","metadata":{"id":"ZpXtbI5kBkOr"},"source":["### 목표\n","\n","- 임의의 활성을 갖는 서열을 분류하는 CNN 모형 개발 (시뮬레이션)\n","- 예시) 임의의 전사인자가 결합하는 특정 DNA 모티프 찾는 모형 개발. 즉, 모형 개발 후 임의의 DNA 서열을 모형에 넣었을 때 해당 전사인자가 입력 DNA 서열에 붙으면 1 붙지 않으면 0 이라고 예측하는 모형 개발"]},{"cell_type":"markdown","metadata":{"id":"2M0_b-DM_xnq"},"source":["\n","### 데이터\n","\n","딥러닝을 위해서는 라벨링 데이터가 필요함 (최근 self-supervised learning에서는 필수는 아님). 서열분석의 경우에는 DNA 서열과 함께 해당 서열의 표현형이 라벨이 될 수 있음 (Genotype-phenotype 짝 데이터). 예를 들어 특정 전사인자가 결합하는 DNA 서열을 예측하는 딥러닝 모형을 학습하고자 할 경우 전사인자의 서열 데이터와 해당 전사인자가 DNA에 실제로 붙는지를 나타내는 True 또는 False 라벨이 붙은 데이터가 필요함.\n","\n","\n","일반적으로 통계적 분석을 위한 데이터는 샘플의 개수와 (행) 변수의 개수로 (열) 구분되어 2차원 배열 형태로 표현. 딥러닝에서도 같은 방식으로 데이터를 표현하며 필요한 샘플의 수는 학습할 모형의 복잡도에 따라서 달라질 수 있지만 최소 수천 개 이상이 필요하며 수 만개 이상의 가능한 많은 데이터를 사용 권장.\n","\n","\n","딥러닝을 위해서 수집된 데이터 세트는 모형 학습을 위한 Training 데이터와 Test 데이터로 나누어 사용되며 Training 데이터는 또다시 Training 데이터와 Validation 데이터로 나누어 구분."]},{"cell_type":"markdown","metadata":{"id":"-YGDLROF-Dzl"},"source":["### One-hot encoding\n","\n","딥러닝을 위해서 데이터는 숫자(기계가 인식 가능한)로 표현 필요. One-hot encoding은 딥러닝에서 가장 널리 사용되는 방법 중 하나이며 4 종류의 염기를 갖는 DNA의 경우 “A”는 [1,0,0,0], “T”는 [0,0,0,1], “G”는 [0,0,1,0], 그리고 “C”는 [0,1,0,0] 으로 인코딩 할 수 있음"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":364,"status":"ok","timestamp":1718611149169,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"isvqkRHO-B0I","outputId":"ba81a254-f3b1-4363-a80b-6fe80bd66b07"},"outputs":[{"name":"stdout","output_type":"stream","text":["['A' 'T' 'A' 'C' 'A' 'A']\n"]}],"source":["import numpy as np\n","\n","my_string=\"ATACAA\"\n","my_array=np.array(list(my_string))\n","print(my_array)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":620,"status":"ok","timestamp":1718590631032,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"SU0BhAF2-4Wu","outputId":"9bca6e54-ca39-4ab6-bfc7-71c6e06850cd"},"outputs":[{"data":{"text/plain":["['A', 'T', 'A', 'C', 'A', 'A']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["list(my_string)"]},{"cell_type":"markdown","metadata":{},"source":["- Numpy Dimension 관련 내용은 앞서 강의 numpy 부분 참고"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"executionInfo":{"elapsed":477,"status":"ok","timestamp":1718612057122,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"VPXw4xGZ_ACy","outputId":"d6631d4c-97df-49fc-f73f-8782082280b5"},"outputs":[{"data":{"text/plain":["array([0., 0., 0., 0., 0.])"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["array([[0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.]])"]},"metadata":{},"output_type":"display_data"}],"source":["display(np.zeros(5))\n","display(np.zeros((7,5)))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":627,"status":"ok","timestamp":1718612507345,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"BKSRQ4AmNVGD","outputId":"ef64187d-d85b-41ba-e89d-08eeb191ad11"},"outputs":[{"data":{"text/plain":["numpy.ndarray"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["box = np.zeros((3, 7, 5))\n","type(box)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":644,"status":"ok","timestamp":1718613208155,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"OzX1nU6m-1fE","outputId":"c7c8132e-a663-4d72-92cc-99c1c35daae9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[1 0 0 0]\n"," [0 0 0 1]\n"," [1 0 0 0]\n"," [0 1 0 0]\n"," [1 0 0 0]\n"," [1 0 0 0]]\n","(6, 4)\n"]}],"source":["onehot_encode = np.zeros((len(my_array),4), dtype=int)\n","base_dict = {\"A\":0, \"C\":1, \"G\":2, \"T\":3}\n","for i in range(len(my_array)):\n","    onehot_encode[i, base_dict[my_array[i]]] = 1\n","\n","print(onehot_encode)\n","print(onehot_encode.shape)"]},{"cell_type":"markdown","metadata":{},"source":["- one-hot 방식으로 변환한 서열 데이터"]},{"cell_type":"markdown","metadata":{},"source":["![alt text](images/64dm.png)"]},{"cell_type":"markdown","metadata":{"id":"P5vnHIXbBPTj"},"source":["### 모티프 설정\n","\n","PFM (Position Frequency Matrix)와 PWM (Position Weight Matrix) 개념 이해 필요. Alignment가 수행된 몇 개의 서열들을 가정하면 PFM은 이 서열들의 특정 위치에 A, T, G, C 각 염기들의 빈도수를 나타내며 PWM은 각 염기의 비율을 나타냄."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1718614750161,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"bHWovtkJ_qxL","outputId":"449e3397-7aed-4272-8737-9896233f5e45"},"outputs":[{"name":"stdout","output_type":"stream","text":["        0      1      2      3      4\n","A:   0.00   3.00   0.00   2.00   3.00\n","C:   0.00   0.00   3.00   0.00   0.00\n","G:   0.00   0.00   0.00   1.00   0.00\n","T:   3.00   0.00   0.00   0.00   0.00\n","\n","        0      1      2      3      4\n","A:   0.10   0.70   0.10   0.50   0.70\n","C:   0.10   0.10   0.70   0.10   0.10\n","G:   0.10   0.10   0.10   0.30   0.10\n","T:   0.70   0.10   0.10   0.10   0.10\n","\n"]}],"source":["from Bio import motifs\n","from Bio.Seq import Seq\n","\n","instances = [Seq(\"TACAA\"), Seq(\"TACGA\"), Seq(\"TACAA\")]\n","m = motifs.create(instances)\n","pfm = m.counts\n","print(pfm)\n","pwm = m.counts.normalize(pseudocounts=0.5)\n","print (pwm)"]},{"cell_type":"markdown","metadata":{"id":"t_ALRfQsD_Gi"},"source":["pseudocounts는 계산시 NULL이나 0으로 나누어지는 경우 방지. 특정 서열 모티프의 PWM은 새로운 서열이 One-hot encoding 방식으로 주어져 있을 경우 서열 처음 위치부터 마지막까지 Sliding window 방식으로 해당 모티프가 있는 위치를 탐색할 수 있음. 다음은 위 주어진 pwm모티프를 0, 1로만 가정하여 해당 모티프의 존재 유무를 계산하는 방법을 보여줌.\n"]},{"cell_type":"markdown","metadata":{},"source":["![alt text](images/sliding_window.png)\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["위와 같이 길이3 배열에 1이 있을 경우 타깃 서열에 모티프와 같은 서열이 있음을 알 수 있음"]},{"cell_type":"markdown","metadata":{},"source":["앞서 \"ATACAA\" 서열에서 위 PWM 모티프가 존재하는지 탐색. \"ATACAA\" 는 길이 5인 슬라이딩 윈도우를 사용하면 \"ATACA\"와 \"TACAA\" 두 개의 서열로 나눌 수 있음. 이 두 서열을 One-hot encoding으로 전환 후 위 PWM과 원소들끼리 곱하면 One-hot encoding에서 0이 아닌 위치와 동일 위치의 PWM 값들만 남게 되므로 0이 아닌 값들을 모두 곱한 후 log를 취해 주면 해당 서열이 모티프와 얼마나 비슷한지를 나타내는 스칼라 값이 구해짐. 이론적으로 이 값이 0이면 동일한 서열임."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1718615793292,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"XQYZQfcECkuT","outputId":"b174a1d2-8526-44f7-d48a-e536955392b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5, 4)\n","(6, 4)\n","(5, 4)\n","(5, 4)\n","[[0.1 0.  0.  0. ]\n"," [0.  0.  0.  0.1]\n"," [0.1 0.  0.  0. ]\n"," [0.  0.1 0.  0. ]\n"," [0.7 0.  0.  0. ]]\n","[[0.  0.  0.  0.7]\n"," [0.7 0.  0.  0. ]\n"," [0.  0.7 0.  0. ]\n"," [0.5 0.  0.  0. ]\n"," [0.7 0.  0.  0. ]]\n","[0.1 0.1 0.1 0.1 0.7]\n","7.000000000000002e-05\n","-9.567015315914915\n","-2.119846956314875\n"]}],"source":["pwm_arr = np.array(list(pwm.values())).transpose()\n","print(pwm_arr.shape)\n","\n","print(onehot_encode.shape)\n","print(onehot_encode[0:5,].shape)\n","print(onehot_encode[1:6,].shape)\n","\n","s1 = np.multiply(onehot_encode[0:5,], pwm_arr)\n","s2 = np.multiply(onehot_encode[1:6,], pwm_arr)\n","print(s1)\n","print(s2)\n","\n","print(np.sum(s1, axis=1))\n","print(np.prod(np.sum(s1, axis=1)))\n","\n","print(np.log(np.prod(np.sum(s1, axis=1)))) #s1 score\n","print(np.log(np.prod(np.sum(s2, axis=1)))) #s2 score\n"]},{"cell_type":"markdown","metadata":{},"source":["- 딥러닝 스타일로 배열을 가시화 할 경우 다음과 같이 표현 가능"]},{"cell_type":"markdown","metadata":{},"source":["![alt text](images/deeplearning_dim.png)"]},{"cell_type":"markdown","metadata":{"id":"j3XK9LAjGJpm"},"source":["### 모의 서열 데이터 생성"]},{"cell_type":"markdown","metadata":{},"source":["서열 중간 motif를 넣어서 임의의 시뮬레이션 positive 데이터를 1000개 생성하고 랜덤한 서열을 넣어 negative 데이터를 1000개 생성함"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1718616329999,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"SXLlovgLDbu1","outputId":"5308cbe2-4126-4bbe-fb35-fced89858523"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1000, 20)\n"]},{"data":{"text/plain":["['AGCGTAGGCGGAACATAATA',\n"," 'GGATCGTCAGGATCACCGCC',\n"," 'CCGAGTCACGGAATTAACTG',\n"," 'AACATCAGCGGAAGCTTTGT']"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"data":{"text/plain":["['TTCCAATTACCGACCTGGAT',\n"," 'ATTGATTTCCTGCCAAGATC',\n"," 'AGTGAGCTGCTTTAGGTCCC',\n"," 'TGTGAGGGCTTAGATGAATG']"]},"metadata":{},"output_type":"display_data"}],"source":["import numpy as np\n","seq_length = 20\n","num_sample = 1000\n","#motif CCGGAA\n","motif_pwm = np.array([[10.41, 22.86, 1.92, 1.55, 98.60, 86.66],\n","            [68.20, 65.25, 0.50, 0.35, 0.25, 2.57],\n","            [17.27, 8.30, 94.77, 97.32, 0.87, 0.00],\n","            [4.13, 3.59, 2.81, 0.78, 0.28, 10.77]])\n","pwm = np.hstack([np.ones((4, 7)), motif_pwm, np.ones((4, 7))])\n","pos = np.array([np.random.choice( ['A', 'C', 'G', 'T'], num_sample,\n","                                  p=pwm[:,i]/sum(pwm[:,i])) for i in range(seq_length)]).transpose()\n","neg = np.array([np.random.choice( ['A', 'C', 'G', 'T'], num_sample,\n","                                  p=np.array([1,1,1,1])/4) for i in range(seq_length)]).transpose()\n","\n","print(pos.shape)\n","display([''.join(x) for x in pos[1:5,]])\n","print()\n","display([''.join(x) for x in neg[1:5,]])"]},{"cell_type":"markdown","metadata":{"id":"21DUbOCjHSxX"},"source":["### DNA 서열 데이터 전처리"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":571,"status":"ok","timestamp":1718616340829,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"V6m6Sc2vHU1e","outputId":"1b21955b-952e-492e-ac35-2005af2426fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2000, 20, 4) (2000, 2)\n"]}],"source":["base_dict = {'A':0, 'C':1, 'G':2, 'T':3}\n","\n","# response variable for pos\n","onehot_encode_pos = np.zeros((num_sample, seq_length, 4))\n","onehot_encode_pos_label = np.zeros((num_sample, 2), dtype=int)\n","onehot_encode_pos_label[:,0] = 1\n","# print(onehot_encode_pos_label)\n","\n","# response variable for pos\n","onehot_encode_neg = np.zeros((num_sample, seq_length, 4))\n","onehot_encode_neg_label = np.zeros((num_sample, 2), dtype=int)\n","onehot_encode_neg_label[:,1] = 1\n","# print(onehot_encode_neg_label)\n","\n","# convert sequence to onehot\n","for i in range(num_sample):\n","    for j in range(seq_length):\n","        onehot_encode_pos[i,j,base_dict[pos[i,j]]] = 1\n","        onehot_encode_neg[i,j,base_dict[neg[i,j]]] = 1\n","\n","# concatenation\n","X = np.vstack((onehot_encode_pos, onehot_encode_neg))\n","y = np.vstack((onehot_encode_pos_label, onehot_encode_neg_label))\n","\n","print(X.shape, y.shape)\n","# (2000, 20, 4) (2000, 2)"]},{"cell_type":"markdown","metadata":{},"source":["- PyTorch Conv1d는 입력 데이터가 [batch_size, channels, length]의 형식이므로 transpose(1,2) 적용"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":548,"status":"ok","timestamp":1718616362356,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"q9gHKkkbHaEF","outputId":"0481cce5-7585-4ba5-a715-728681c165a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1600, 20, 4) (1600, 2)\n","torch.float32\n","torch.Size([1600, 4, 20])\n","torch.Size([1600, 2])\n"]}],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","# 데이터를 훈련 세트와 테스트 세트로 나눔\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=125)\n","print(X_train.shape, y_train.shape)\n","\n","# NumPy 배열을 PyTorch 텐서로 변환\n","X_train = torch.tensor(X_train, dtype=torch.float32).transpose(1,2)\n","X_test = torch.tensor(X_test, dtype=torch.float32).transpose(1,2)\n","y_train = torch.tensor(y_train, dtype=torch.float32)\n","y_test = torch.tensor(y_test, dtype=torch.float32)\n","print(y_test.dtype)\n","\n","# DataLoader 설정\n","train_dataset = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","print(train_loader.dataset.tensors[0].shape)\n","print(train_loader.dataset.tensors[1].shape)\n","test_dataset = TensorDataset(X_test, y_test)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":610,"status":"ok","timestamp":1718616374501,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"mThrgCyGSsfq","outputId":"4ba6d7d9-42d0-42ac-e404-39002de8e4a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1600, 4, 20])\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_341094/3124571761.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  X_torch = torch.tensor(X_train, dtype=torch.float32)\n"]}],"source":["import torch\n","\n","X_torch = torch.tensor(X_train, dtype=torch.float32)\n","print(X_torch.shape)"]},{"cell_type":"markdown","metadata":{"id":"aROVZUbXWwg1"},"source":["### 모델 정의"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":391,"status":"ok","timestamp":1718616387856,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"GewjG62iUvYk","outputId":"8394d97a-bb14-4e7b-c02c-976f8835f870"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv1d-1               [-1, 16, 20]             208\n","              ReLU-2               [-1, 16, 20]               0\n","         MaxPool1d-3               [-1, 16, 10]               0\n","           Flatten-4                  [-1, 160]               0\n","            Linear-5                   [-1, 64]          10,304\n","            Linear-6                    [-1, 2]             130\n","================================================================\n","Total params: 10,642\n","Trainable params: 10,642\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.04\n","Estimated Total Size (MB): 0.05\n","----------------------------------------------------------------\n"]}],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class DNA_CNN(nn.Module):\n","    def __init__(self):\n","        super(DNA_CNN, self).__init__()\n","        self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=3, padding=1)\n","        self.relu = nn.ReLU()\n","        self.maxpool = nn.MaxPool1d(kernel_size=2)\n","        self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(160, 64)  # Adjust the input features according to your pooling and conv1d output\n","        self.fc2 = nn.Linear(64, 2)  # Adjust according to your problem's needs (e.g., number of classes)\n","        #self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        #x = self.softmax(x)\n","        return x\n","\n","model = DNA_CNN()\n","if torch.cuda.is_available():\n","    model.cuda()\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","from torchsummary import summary\n","summary(model, input_size=(4, 20))  # (Channels, Length)\n"]},{"cell_type":"markdown","metadata":{"id":"218_FeCtW0kZ"},"source":["### 훈련"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2915,"status":"ok","timestamp":1718617108099,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"2DxWgtlAW0Jy","outputId":"96aea657-d7d9-4569-881a-e3c256d7cd94"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/20], Loss: 0.4758\n","Epoch [2/20], Loss: 0.1928\n","Epoch [3/20], Loss: 0.0787\n","Epoch [4/20], Loss: 0.0622\n","Epoch [5/20], Loss: 0.0541\n","Epoch [6/20], Loss: 0.0364\n","Epoch [7/20], Loss: 0.0975\n","Epoch [8/20], Loss: 0.0732\n","Epoch [9/20], Loss: 0.0431\n","Epoch [10/20], Loss: 0.0285\n","Epoch [11/20], Loss: 0.0258\n","Epoch [12/20], Loss: 0.1933\n","Epoch [13/20], Loss: 0.0316\n","Epoch [14/20], Loss: 0.0399\n","Epoch [15/20], Loss: 0.0546\n","Epoch [16/20], Loss: 0.0661\n","Epoch [17/20], Loss: 0.0291\n","Epoch [18/20], Loss: 0.0105\n","Epoch [19/20], Loss: 0.0390\n","Epoch [20/20], Loss: 0.0536\n"]}],"source":["# 훈련 루프\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    for inputs, labels in train_loader:\n","        if torch.cuda.is_available():\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":365,"status":"ok","timestamp":1718617327293,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"07_QpQsBo-SR","outputId":"66c7ede7-5ece-4860-b705-3f3466044a52"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the model on the test images: 97.75 %\n"]}],"source":["# 모델 평가\n","model.eval()\n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for inputs, labels in test_loader:\n","        if torch.cuda.is_available():\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","        outputs = model(inputs)\n","        #print(outputs.data)\n","        _, predicted = torch.max(outputs.data, 1)\n","        #print(predicted)\n","        total += labels.size(0)\n","        labels_max = torch.max(labels, 1)[1]\n","        #print(labels_max)\n","        correct += (predicted == labels_max).sum().item()\n","\n","    print(f'Accuracy of the model on the test images: {100 * correct / total} %')\n"]},{"cell_type":"markdown","metadata":{"id":"xcJPfqdylWXm"},"source":["- 검증을 위한 데이터 저장, 훈련, 예측 동시 수행"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":25207,"status":"ok","timestamp":1718617527334,"user":{"displayName":"haseong kim","userId":"15555769759698200025"},"user_tz":-540},"id":"UjEkmdVRlJm4","outputId":"73928f73-3d07-43b9-dbc9-bcded72386d8"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# 데이터 저장을 위한 리스트 초기화\n","train_losses = []\n","val_accuracies = []\n","\n","num_epochs = 200\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        if torch.cuda.is_available():\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    train_losses.append(epoch_loss)\n","\n","    # 모델 평가\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            if torch.cuda.is_available():\n","                inputs, labels = inputs.cuda(), labels.cuda()\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            labels_max = torch.max(labels, 1)[1]\n","            correct += (predicted == labels_max).sum().item()\n","\n","    epoch_accuracy = 100 * correct / total\n","    val_accuracies.append(epoch_accuracy)\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n","\n","# 그래프 그리기\n","plt.figure(figsize=(12, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses, label='Training Loss')\n","plt.title('Training Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(val_accuracies, label='Validation Accuracy')\n","plt.title('Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.legend()\n","\n","plt.show()\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO2AgYT1PZj0OXviRPDdbV1","mount_file_id":"1E8yPlQgPbwnW3d2P1XeUD22Zz7rl3cZr","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
